feed,title,long_url,short_url
ArXiv,Reinforcement Learning -based Adaptation and Scheduling Methods for Multi-source DASH,https://arxiv.org/abs/2308.11621v1,
ArXiv,Accelerating Exact Combinatorial Optimization via RL-based Initialization -- A Case Study in Scheduling,https://arxiv.org/abs/2308.11652v1,
ArXiv,${\rm E}(3)$-Equivariant Actor-Critic Methods for Cooperative Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2308.11842v1,
ArXiv,Prompt-Based Length Controlled Generation with Reinforcement Learning,https://arxiv.org/abs/2308.12030v1,
ArXiv,Aligning Language Models with Offline Reinforcement Learning from Human Feedback,https://arxiv.org/abs/2308.12050v1,
ArXiv,Identifying Reaction-Aware Driving Styles of Stochastic Model Predictive Controlled Vehicles by Inverse Reinforcement Learning,https://arxiv.org/abs/2308.12069v1,
ArXiv,Language Reward Modulation for Pretraining Reinforcement Learning,https://arxiv.org/abs/2308.12270v1,
ArXiv,Towards Interactive Reinforcement Learning with Intrinsic Feedback,https://arxiv.org/abs/2112.01575v3,
ArXiv,MARLlib: A Scalable and Efficient Multi-agent Reinforcement Learning Library,https://arxiv.org/abs/2210.13708v3,
ArXiv,Regret-Based Optimization for Robust Reinforcement Learning,https://arxiv.org/abs/2302.06912v3,
ArXiv,Conformal Predictive Safety Filter for RL Controllers in Dynamic Environments,https://arxiv.org/abs/2306.02551v2,
