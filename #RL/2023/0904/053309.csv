feed,title,long_url,short_url
gNews,Do You Really Need Reinforcement Learning (RL) in RLHF? A New Stanford Research Proposes DPO (Direct Preference Optimization): A Simple Training Paradigm For Training Language Models From Preferences Without RL - MarkTechPost,https://news.google.com/rss/articles/CBMi6gFodHRwczovL3d3dy5tYXJrdGVjaHBvc3QuY29tLzIwMjMvMDcvMjEvZG8teW91LXJlYWxseS1uZWVkLXJlaW5mb3JjZW1lbnQtbGVhcm5pbmctcmwtaW4tcmxoZi1hLW5ldy1zdGFuZm9yZC1yZXNlYXJjaC1wcm9wb3Nlcy1kcG8tZGlyZWN0LXByZWZlcmVuY2Utb3B0aW1pemF0aW9uLWEtc2ltcGxlLXRyYWluaW5nLXBhcmFkaWdtLWZvci10cmFpbmluZy1sYW5ndWFnZS1tb2RlbHMtZnJvbS1wcmVmZXJlbmNlcy_SAe4BaHR0cHM6Ly93d3cubWFya3RlY2hwb3N0LmNvbS8yMDIzLzA3LzIxL2RvLXlvdS1yZWFsbHktbmVlZC1yZWluZm9yY2VtZW50LWxlYXJuaW5nLXJsLWluLXJsaGYtYS1uZXctc3RhbmZvcmQtcmVzZWFyY2gtcHJvcG9zZXMtZHBvLWRpcmVjdC1wcmVmZXJlbmNlLW9wdGltaXphdGlvbi1hLXNpbXBsZS10cmFpbmluZy1wYXJhZGlnbS1mb3ItdHJhaW5pbmctbGFuZ3VhZ2UtbW9kZWxzLWZyb20tcHJlZmVyZW5jZXMvP2FtcA?oc=5,https://da.gd/Ta5g
