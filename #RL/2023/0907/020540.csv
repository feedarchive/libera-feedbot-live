feed,title,long_url,short_url
ArXiv,Active flow control for three-dimensional cylinders through deep reinforcement learning,https://arxiv.org/abs/2309.02462v1,
ArXiv,Deep Reinforcement Learning from Hierarchical Weak Preference Feedback,https://arxiv.org/abs/2309.02632v1,
ArXiv,Marketing Budget Allocation with Offline Constrained Deep Reinforcement Learning,https://arxiv.org/abs/2309.02669v1,
ArXiv,RLSynC: Offline-Online Reinforcement Learning for Synthon Completion,https://arxiv.org/abs/2309.02671v1,
ArXiv,Addressing Imperfect Symmetry: a Novel Symmetry-Learning Actor-Critic Extension,https://arxiv.org/abs/2309.02711v1,
ArXiv,Reinforcement Learning of Action and Query Policies with LTL Instructions under Uncertain Event Detector,https://arxiv.org/abs/2309.02722v1,
ArXiv,Near-continuous time Reinforcement Learning for continuous state-action spaces,https://arxiv.org/abs/2309.02815v1,
ArXiv,On Reducing Undesirable Behavior in Deep Reinforcement Learning Models,https://arxiv.org/abs/2309.02869v1,
ArXiv,Reinforcement Learning Based Gasoline Blending Optimization: Achieving More Efficient Nonlinear Online Blending of Fuels,https://arxiv.org/abs/2309.02929v1,
ArXiv,Natural and Robust Walking using Reinforcement Learning without Demonstrations in High-Dimensional Musculoskeletal Models,https://arxiv.org/abs/2309.02976v1,
ArXiv,Multi-log grasping using reinforcement learning and virtual visual servoing,https://arxiv.org/abs/2309.02997v1,
ArXiv,ORL-AUDITOR: Dataset Auditing in Offline Deep Reinforcement Learning,https://arxiv.org/abs/2309.03081v1,
ArXiv,Learning to Recharge: UAV Coverage Path Planning through Deep Reinforcement Learning,https://arxiv.org/abs/2309.03157v1,
ArXiv,Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning,https://arxiv.org/abs/2302.02662v3,
