feed,title,long_url,short_url
ArXiv,Building Persona Consistent Dialogue Agents with Offline Reinforcement Learning,https://arxiv.org/abs/2310.10735v1,
ArXiv,Robust Multi-Agent Reinforcement Learning via Adversarial Regularization: Theoretical Foundation and Stable Algorithms,https://arxiv.org/abs/2310.10810v1,
ArXiv,Uncertainty-aware transfer across tasks using hybrid model-based successor feature reinforcement learning,https://arxiv.org/abs/2310.10818v1,
ArXiv,Joint Optimization of Traffic Signal Control and Vehicle Routing in Signalized Road Networks using Multi-Agent Deep Reinforcement Learning,https://arxiv.org/abs/2310.10856v1,
ArXiv,Reaching the Limit in Autonomous Racing: Optimal Control versus Reinforcement Learning,https://arxiv.org/abs/2310.10943v1,
ArXiv,Cooperative Dispatch of Microgrids Community Using Risk-Sensitive Reinforcement Learning with Monotonously Improved Performance,https://arxiv.org/abs/2310.10997v1,
ArXiv,SMACv2: An Improved Benchmark for Cooperative Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2212.07489v2,
ArXiv,Towards Minimax Optimality of Model-based Robust Reinforcement Learning,https://arxiv.org/abs/2302.05372v2,
ArXiv,A Human-Centered Safe Robot Reinforcement Learning Framework with Interactive Behaviors,https://arxiv.org/abs/2302.13137v3,
ArXiv,Optimizing Memory Mapping Using Deep Reinforcement Learning,https://arxiv.org/abs/2305.07440v2,
ArXiv,Iteratively Refined Behavior Regularization for Offline Reinforcement Learning,https://arxiv.org/abs/2306.05726v2,
ArXiv,Fighting Uncertainty with Gradients: Offline Reinforcement Learning via Diffusion Score Matching,https://arxiv.org/abs/2306.14079v2,
ArXiv,Q-Transformer: Scalable Offline Reinforcement Learning via Autoregressive Q-Functions,https://arxiv.org/abs/2309.10150v2,
ArXiv,"ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models",https://arxiv.org/abs/2310.10505v2,
