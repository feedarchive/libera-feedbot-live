feed,title,long_url,short_url
ArXiv,Data-Driven LQR using Reinforcement Learning and Quadratic Neural Networks,https://arxiv.org/abs/2311.10235v1,
ArXiv,"From ""Thumbs Up"" to ""10 out of 10"": Reconsidering Scalar Feedback in Interactive Reinforcement Learning",https://arxiv.org/abs/2311.10284v1,
ArXiv,Imagination-augmented Hierarchical Reinforcement Learning for Safe and Interactive Autonomous Driving in Urban Environments,https://arxiv.org/abs/2311.10309v1,
ArXiv,EduGym: An Environment Suite for Reinforcement Learning Education,https://arxiv.org/abs/2311.10590v1,
ArXiv,Concave Utility Reinforcement Learning with Zero-Constraint Violations,https://arxiv.org/abs/2109.05439v3,
ArXiv,Comparing Deep Reinforcement Learning Algorithms in Two-Echelon Supply Chains,https://arxiv.org/abs/2204.09603v3,
ArXiv,Model-Based Reinforcement Learning with Isolated Imaginations,https://arxiv.org/abs/2303.14889v2,
ArXiv,Rates of Convergence in Certain Native Spaces of Approximations used in Reinforcement Learning,https://arxiv.org/abs/2309.07383v4,
ArXiv,Boosting Offline Reinforcement Learning for Autonomous Driving with Hierarchical Latent Skills,https://arxiv.org/abs/2309.13614v2,
ArXiv,Digital Twin Accelerated Deep Reinforcement Learning for Online Admission Control of Network Slicing,https://arxiv.org/abs/2310.09299v2,
ArXiv,"Closed Drafting as a Case Study for First-Principle Interpretability, Memory, and Generalizability in Deep Reinforcement Learning",https://arxiv.org/abs/2310.20654v3,
ArXiv,Joint User Pairing and Beamforming Design of Multi-STAR-RISs-Aided NOMA in the Indoor Environment via Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2311.08708v2,
ArXiv,JaxMARL: Multi-Agent RL Environments in JAX,https://arxiv.org/abs/2311.10090v2,
