feed,title,long_url,short_url
ArXiv,Bridging Imitation and Online Reinforcement Learning: An Optimistic Tale,https://arxiv.org/abs/2303.11369v1,
ArXiv,Bridging Transient and Steady-State Performance in Voltage Control: A Reinforcement Learning Approach with Safe Gradient Flow,https://arxiv.org/abs/2303.11417v1,
ArXiv,Style Miner: Find Significant and Stable Explanatory Factors in Time Series with Constrained Reinforcement Learning,https://arxiv.org/abs/2303.11716v1,
ArXiv,SACPlanner: Real-World Collision Avoidance with a Soft Actor Critic Local Planner and Polar State Representations,https://arxiv.org/abs/2303.11801v1,
ArXiv,Multi-agent Reinforcement Learning for Regional Signal control in Large-scale Grid Traffic network,https://arxiv.org/abs/2303.11899v1,
ArXiv,Strategic Trading in Quantitative Markets through Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2303.11959v1,
ArXiv,Stateless actor-critic for instance segmentation with high-level priors,https://arxiv.org/abs/2107.02600v2,
ArXiv,Joint Differentiable Optimization and Verification for Certified Reinforcement Learning,https://arxiv.org/abs/2201.12243v2,
ArXiv,Ask-AC: An Initiative Advisor-in-the-Loop Actor-Critic Framework,https://arxiv.org/abs/2207.01955v3,
ArXiv,Multiagent Reinforcement Learning for Autonomous Routing and Pickup Problem with Adaptation to Variable Demand,https://arxiv.org/abs/2211.14983v2,
ArXiv,Risk-Sensitive Reinforcement Learning with Exponential Criteria,https://arxiv.org/abs/2212.09010v2,
