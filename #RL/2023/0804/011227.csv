feed,title,long_url,short_url
ArXiv,Follow the Soldiers with Optimized Single-Shot Multibox Detection and Reinforcement Learning,https://arxiv.org/abs/2308.01389v1,
ArXiv,Investigating Reinforcement Learning for Communication Strategies in a Task-Initiative Setting,https://arxiv.org/abs/2308.01479v1,
ArXiv,Quantum Multi-Agent Reinforcement Learning for Autonomous Mobility Cooperation,https://arxiv.org/abs/2308.01519v1,
ArXiv,Avoidance Navigation Based on Offline Pre-Training Reinforcement Learning,https://arxiv.org/abs/2308.01551v1,
ArXiv,Improving Wind Resistance Performance of Cascaded PID Controlled Quadcopters using Residual Reinforcement Learning,https://arxiv.org/abs/2308.01648v1,
ArXiv,MARLIM: Multi-Agent Reinforcement Learning for Inventory Management,https://arxiv.org/abs/2308.01649v1,
ArXiv,End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear MPC,https://arxiv.org/abs/2308.01674v1,
ArXiv,Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to Sequence approach,https://arxiv.org/abs/2308.01797v1,
ArXiv,Auto-COP: Adaptation Generation in Context-Oriented Programming using Reinforcement Learning Options,https://arxiv.org/abs/2103.06757v2,
ArXiv,Relational Experience Replay: Continual Learning by Adaptively Tuning Task-wise Relationship,https://arxiv.org/abs/2112.15402v3,
ArXiv,Prevalence of Code Smells in Reinforcement Learning Projects,https://arxiv.org/abs/2303.10236v2,
