feed,title,long_url,short_url
ArXiv,A Deep Reinforcement Learning Approach for Improving Age of Information in Mission-Critical IoT,https://arxiv.org/abs/2311.13861v1,
ArXiv,L(M)V-IQL: Multiple Intention Inverse Reinforcement Learning for Animal Behavior Characterization,https://arxiv.org/abs/2311.13870v1,
ArXiv,Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach,https://arxiv.org/abs/2311.13884v1,
ArXiv,A DRL solution to help reduce the cost in waiting time of securing a traffic light for cyclists,https://arxiv.org/abs/2311.13905v1,
ArXiv,AlphaFold Distillation for Protein Design,https://arxiv.org/abs/2210.03488v2,
ArXiv,Structured State Space Models for In-Context Reinforcement Learning,https://arxiv.org/abs/2303.03982v3,
ArXiv,Reducing Idleness in Financial Cloud Services via Multi-objective Evolutionary Reinforcement Learning based Load Balancer,https://arxiv.org/abs/2305.03463v2,
ArXiv,Query-Policy Misalignment in Preference-Based Reinforcement Learning,https://arxiv.org/abs/2305.17400v2,
ArXiv,PEAR: Primitive enabled Adaptive Relabeling for boosting Hierarchical Reinforcement Learning,https://arxiv.org/abs/2306.06394v4,
ArXiv,Designing and evaluating an online reinforcement learning agent for physical exercise recommendations in N-of-1 trials,https://arxiv.org/abs/2309.14156v2,
ArXiv,Imitation Bootstrapped Reinforcement Learning,https://arxiv.org/abs/2311.02198v3,
ArXiv,Approximation of Convex Envelope Using Reinforcement Learning,https://arxiv.org/abs/2311.14421v1,
ArXiv,FAMAC: A Federated Assisted Modified Actor-Critic Framework for Secured Energy Saving in 5G and Beyond Networks,https://arxiv.org/abs/2311.14509v1,
ArXiv,On optimal tracking portfolio in incomplete markets: The classical control and the reinforcement learning approaches,https://arxiv.org/abs/2311.14318v1,
