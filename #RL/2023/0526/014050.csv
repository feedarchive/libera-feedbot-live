feed,title,long_url,short_url
ArXiv,SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning,https://arxiv.org/abs/2305.15486v1,
ArXiv,Regret-Optimal Model-Free Reinforcement Learning for Discounted MDPs with Short Burn-In Time,https://arxiv.org/abs/2305.15546v1,
ArXiv,Deep Reinforcement Learning with Plasticity Injection,https://arxiv.org/abs/2305.15555v1,
ArXiv,"Control invariant set enhanced safe reinforcement learning: improved sampling efficiency, guaranteed stability and robustness",https://arxiv.org/abs/2305.15602v1,
ArXiv,Matrix Estimation for Offline Reinforcement Learning with Low-Rank Structure,https://arxiv.org/abs/2305.15621v1,
ArXiv,PROTO: Iterative Policy Regularized Offline-to-Online Reinforcement Learning,https://arxiv.org/abs/2305.15669v1,
ArXiv,The Benefits of Being Distributional: Small-Loss Bounds for Reinforcement Learning,https://arxiv.org/abs/2305.15703v1,
ArXiv,Reinforcement Learning based optimal control with a probabilistic risk constraint,https://arxiv.org/abs/2305.15755v1,
ArXiv,Lucy-SKG: Learning to Play Rocket League Efficiently Using Deep Reinforcement Learning,https://arxiv.org/abs/2305.15801v1,
ArXiv,Market Making with Deep Reinforcement Learning from Limit Order Books,https://arxiv.org/abs/2305.15821v1,
ArXiv,DeepFreight: Integrating Deep Reinforcement Learning and Mixed Integer Programming for Multi-transfer Truck Freight Delivery,https://arxiv.org/abs/2103.03450v2,
ArXiv,A Small Gain Analysis of Single Timescale Actor Critic,https://arxiv.org/abs/2203.02591v4,
ArXiv,Q-learning Decision Transformer: Leveraging Dynamic Programming for Conditional Sequence Modelling in Offline RL,https://arxiv.org/abs/2209.03993v4,
ArXiv,Mastering the Unsupervised Reinforcement Learning Benchmark from Pixels,https://arxiv.org/abs/2209.12016v2,
ArXiv,Understanding the Complexity Gains of Single-Task RL with a Curriculum,https://arxiv.org/abs/2212.12809v2,
ArXiv,DIFFER: Decomposing Individual Reward for Fair Experience Replay in Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2301.10574v2,
ArXiv,Near-Minimax-Optimal Risk-Sensitive Reinforcement Learning with CVaR,https://arxiv.org/abs/2302.03201v2,
ArXiv,Approximating Energy Market Clearing and Bidding With Model-Based Reinforcement Learning,https://arxiv.org/abs/2303.01772v2,
ArXiv,Bandit-Based Policy Invariant Explicit Shaping for Incorporating External Advice in Reinforcement Learning,https://arxiv.org/abs/2304.07163v2,
ArXiv,Massively Scalable Inverse Reinforcement Learning in Google Maps,https://arxiv.org/abs/2305.11290v2,
ArXiv,Collaborative World Models: An Online-Offline Transfer RL Approach,https://arxiv.org/abs/2305.15260v2,
ArXiv,Augmented Memory: Capitalizing on Experience Replay to Accelerate De Novo Molecular Design,https://arxiv.org/abs/2305.16160v1,
