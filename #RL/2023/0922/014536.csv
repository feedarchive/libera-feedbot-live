feed,title,long_url,short_url
ArXiv,Hierarchical reinforcement learning with natural language subgoals,https://arxiv.org/abs/2309.11564v1,
ArXiv,Improve the efficiency of deep reinforcement learning through semantic exploration guided by natural language,https://arxiv.org/abs/2309.11753v1,
ArXiv,Learning to Recover for Safe Reinforcement Learning,https://arxiv.org/abs/2309.11907v1,
ArXiv,Representation Abstractions as Incentives for Reinforcement Learning Agents: A Robotic Grasping Case Study,https://arxiv.org/abs/2309.11984v1,
ArXiv,UAV Swarm Deployment and Trajectory for 3D Area Coverage via Reinforcement Learning,https://arxiv.org/abs/2309.11992v1,
ArXiv,Safe Hierarchical Reinforcement Learning for CubeSat Task Scheduling Based on Energy Consumption,https://arxiv.org/abs/2309.12004v1,
ArXiv,Optimizing V2V Unicast Communication Transmission with Reinforcement Learning and Vehicle Clustering,https://arxiv.org/abs/2309.12052v1,
ArXiv,State Augmented Constrained Reinforcement Learning: Overcoming the Limitations of Learning with Rewards,https://arxiv.org/abs/2102.11941v2,
ArXiv,A Survey on Transformers in Reinforcement Learning,https://arxiv.org/abs/2301.03044v3,
ArXiv,Semantic-aware Transmission Scheduling: a Monotonicity-driven Deep Reinforcement Learning Approach,https://arxiv.org/abs/2305.13706v2,
ArXiv,Actor-Critic Model Predictive Control,https://arxiv.org/abs/2306.09852v3,
ArXiv,$\lambda$-AC: Learning latent decision-aware models for reinforcement learning in continuous state-spaces,https://arxiv.org/abs/2306.17366v2,
ArXiv,Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning,https://arxiv.org/abs/2309.11489v2,
