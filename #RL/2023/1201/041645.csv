feed,title,long_url,short_url
ArXiv,Advancing Attack-Resilient Scheduling of Integrated Energy Systems with Demand Response via Deep Reinforcement Learning,https://arxiv.org/abs/2311.17941v1,
ArXiv,Self-Driving Telescopes: Autonomous Scheduling of Astronomical Observation Campaigns with Offline Reinforcement Learning,https://arxiv.org/abs/2311.18094v1,
ArXiv,SCOPE-RL: A Python Library for Offline Reinforcement Learning and Off-Policy Evaluation,https://arxiv.org/abs/2311.18206v1,
ArXiv,LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language Models,https://arxiv.org/abs/2311.18232v1,
ArXiv,Deep Reinforcement Learning Based Optimal Energy Management of Multi-energy Microgrids with Uncertainties,https://arxiv.org/abs/2311.18327v1,
ArXiv,Data-efficient Deep Reinforcement Learning for Vehicle Trajectory Control,https://arxiv.org/abs/2311.18393v1,
ArXiv,Optimizing ZX-Diagrams with Deep Reinforcement Learning,https://arxiv.org/abs/2311.18588v1,
ArXiv,Handling Cost and Constraints with Off-Policy Deep Reinforcement Learning,https://arxiv.org/abs/2311.18684v1,
ArXiv,Predictable Reinforcement Learning Dynamics through Entropy Rate Minimization,https://arxiv.org/abs/2311.18703v1,
ArXiv,Two-step reinforcement learning for model-free redesign of nonlinear optimal regulator,https://arxiv.org/abs/2103.03808v4,
ArXiv,PyDCM: Custom Data Center Models with Reinforcement Learning for Sustainability,https://arxiv.org/abs/2310.03906v7,
ArXiv,On Double Descent in Reinforcement Learning with LSTD and Random Features,https://arxiv.org/abs/2310.05518v3,
ArXiv,A Simple Open-Loop Baseline for Reinforcement Learning Locomotion Tasks,https://arxiv.org/abs/2310.05808v2,
ArXiv,Controlgym: Large-Scale Safety-Critical Control Environments for Benchmarking Reinforcement Learning Algorithms,https://arxiv.org/abs/2311.18736v1,
ArXiv,Efficient Model-Based Concave Utility Reinforcement Learning through Greedy Mirror Descent,https://arxiv.org/abs/2311.18346v1,
