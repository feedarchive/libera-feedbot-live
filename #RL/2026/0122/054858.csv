feed,title,long_url,short_url
ArXiv,On the Generalization Gap in LLM Planning: Tests and Verifier-Reward RL,https://arxiv.org/abs/2601.14456,
ArXiv,Beyond Error-Based Optimization: Experience-Driven Symbolic Regression with Goal-Conditioned Reinforcement Learning,https://arxiv.org/abs/2601.14693,
ArXiv,CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation,https://arxiv.org/abs/2601.14695,
ArXiv,DARA: Few-shot Budget Allocation in Online Advertising via In-Context Decision Making with RL-Finetuned LLMs,https://arxiv.org/abs/2601.14711,
ArXiv,PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning,https://arxiv.org/abs/2601.14716,
ArXiv,ReinPath: A Multimodal Reinforcement Learning Approach for Pathology,https://arxiv.org/abs/2601.14757,
ArXiv,Language-Coupled Reinforcement Learning for Multilingual Retrieval-Augmented Generation,https://arxiv.org/abs/2601.14896,
ArXiv,Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control,https://arxiv.org/abs/2601.15015,
ArXiv,A Curriculum-Based Deep Reinforcement Learning Framework for the Electric Vehicle Routing Problem,https://arxiv.org/abs/2601.15038,
ArXiv,Memory Retention Is Not Enough to Master Memory Tasks in Reinforcement Learning,https://arxiv.org/abs/2601.15086,
ArXiv,Vehicle Routing with Finite Time Horizon using Deep Reinforcement Learning with Improved Network Embedding,https://arxiv.org/abs/2601.15131,
ArXiv,CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning,https://arxiv.org/abs/2601.15141,
ArXiv,"Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data",https://arxiv.org/abs/2601.15158,
