feed,title,long_url,short_url
ArXiv,Horizon Reduction as Information Loss in Offline Reinforcement Learning,https://arxiv.org/abs/2601.00831,
ArXiv,Harvesting AlphaEarth: Benchmarking the Geospatial Foundation Model for Agricultural Downstream Tasks,https://arxiv.org/abs/2601.00857,
ArXiv,SmartFlow Reinforcement Learning and Agentic AI for Bike-Sharing Optimisation,https://arxiv.org/abs/2601.00868,
ArXiv,VideoCuRL: Video Curriculum Reinforcement Learning with Orthogonal Difficulty Decomposition,https://arxiv.org/abs/2601.00887,
ArXiv,Latent Space Reinforcement Learning for Multi-Robot Exploration,https://arxiv.org/abs/2601.01139,
ArXiv,ORION: Option-Regularized Deep Reinforcement Learning for Cooperative Multi-Agent Online Navigation,https://arxiv.org/abs/2601.01155,
ArXiv,Reinforcement Learning Based Whittle Index Policy for Scheduling Wireless Sensors,https://arxiv.org/abs/2601.01179,
ArXiv,SecureCodeRL: Security-Aware Reinforcement Learning for Code Generation with Partial-Credit Rewards,https://arxiv.org/abs/2601.01184,
ArXiv,Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering,https://arxiv.org/abs/2601.01195,
ArXiv,OrchestrRL: Dynamic Compute and Network Orchestration for Disaggregated RL,https://arxiv.org/abs/2601.01209,
ArXiv,"dataRLsec: Safety, Security, and Reliability With Robust Offline Reinforcement Learning for DPAs",https://arxiv.org/abs/2601.01289,
ArXiv,SAFE-QAQ: End-to-End Slow-Thinking Audio-Text Fraud Detection via Reinforcement Learning,https://arxiv.org/abs/2601.01392,
ArXiv,Utilizing Earth Foundation Models to Enhance the Simulation Performance of Hydrological Models with AlphaEarth Embeddings,https://arxiv.org/abs/2601.01558,
ArXiv,The Two-Stage Decision-Sampling Hypothesis: Understanding the Emergence of Self-Reflection in RL-Trained LLMs,https://arxiv.org/abs/2601.01580,
ArXiv,SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines,https://arxiv.org/abs/2601.01785,
ArXiv,"Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving",https://arxiv.org/abs/2601.01800,
ArXiv,Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning,https://arxiv.org/abs/2601.01904,
ArXiv,Distorted Distributional Policy Evaluation for Offline Reinforcement Learning,https://arxiv.org/abs/2601.01917,
ArXiv,AgentVNE: LLM-Augmented Graph Reinforcement Learning for Affinity-Aware Multi-Agent Placement in Edge Agentic AI,https://arxiv.org/abs/2601.02021,
ArXiv,Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management,https://arxiv.org/abs/2601.02061,
ArXiv,Enabling Deep Reinforcement Learning Research for Energy Saving in Open RAN,https://arxiv.org/abs/2601.02240,
ArXiv,VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation,https://arxiv.org/abs/2601.02256,
ArXiv,Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes,https://arxiv.org/abs/2601.02356,
ArXiv,Reinforcement Learning for Option Hedging: Static Implied-Volatility Fit versus Shortfall-Aware Performance,https://arxiv.org/abs/2601.01709,
ArXiv,General Dynamic Goal Recognition using Goal-Conditioned and Meta Reinforcement Learning,https://arxiv.org/abs/2505.09737,
