feed,title,long_url,short_url
ArXiv,Multi-Agent Deep Reinforcement Learning Under Constrained Communications,https://arxiv.org/abs/2601.17069,
ArXiv,Scaling medical imaging report generation with multimodal reinforcement learning,https://arxiv.org/abs/2601.17151,
ArXiv,"Retell, Reward, Repeat: Reinforcement Learning for Narrative Theory-Informed Story Generation",https://arxiv.org/abs/2601.17226,
ArXiv,Latent-Space Contrastive Reinforcement Learning for Stable and Efficient LLM Reasoning,https://arxiv.org/abs/2601.17275,
ArXiv,Scaling Rough Terrain Locomotion with Automatic Curriculum Reinforcement Learning,https://arxiv.org/abs/2601.17428,
ArXiv,Towards a Declarative Agentic Layer for Intelligent Agents in MCP-Based Server Ecosystems,https://arxiv.org/abs/2601.17435,
ArXiv,Embodiment-Induced Coordination Regimes in Tabular Multi-Agent Q-Learning,https://arxiv.org/abs/2601.17454,
ArXiv,Quantum-Inspired Episode Selection for Monte Carlo Reinforcement Learning via QUBO Optimization,https://arxiv.org/abs/2601.17570,
ArXiv,Deep Intrinsic Surprise-Regularized Control (DISRC): A Biologically Inspired Mechanism for Efficient Deep Q-Learning in Sparse Environments,https://arxiv.org/abs/2601.17598,
ArXiv,Athena: Synergizing Data Prefetching and Off-Chip Prediction via Online Reinforcement Learning,https://arxiv.org/abs/2601.17615,
ArXiv,Agentic reinforcement learning empowers next-generation chemical language models for molecular design and synthesis,https://arxiv.org/abs/2601.17687,
ArXiv,SQL-Trail: Multi-Turn Reinforcement Learning with Interleaved Feedback for Text-to-SQL,https://arxiv.org/abs/2601.17699,
ArXiv,ProGraph-R1: Progress-aware Reinforcement Learning for Graph Retrieval Augmented Generation,https://arxiv.org/abs/2601.17755,
ArXiv,Aligning Medical Conversational AI through Online Reinforcement Learning with Information-Theoretic Rewards,https://arxiv.org/abs/2601.17828,
ArXiv,Scaling Effects and Uncertainty Quantification in Neural Actor Critic Algorithms,https://arxiv.org/abs/2601.17954,
ArXiv,Diffusion Model-based Reinforcement Learning for Version Age of Information Scheduling: Average and Tail-Risk-Sensitive Control,https://arxiv.org/abs/2601.18069,
ArXiv,Mitigating the OWASP Top 10 For Large Language Models Applications using Intelligent Agents,https://arxiv.org/abs/2601.18105,
ArXiv,Enhance the Safety in Reinforcement Learning by ADRC Lagrangian Methods,https://arxiv.org/abs/2601.18142,
ArXiv,FP8-RL: A Practical and Stable Low-Precision Stack for LLM Reinforcement Learning,https://arxiv.org/abs/2601.18150,
ArXiv,Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents,https://arxiv.org/abs/2601.18217,
ArXiv,ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants,https://arxiv.org/abs/2601.18225,
ArXiv,VissimRL: A Multi-Agent Reinforcement Learning Framework for Traffic Signal Control Based on Vissim,https://arxiv.org/abs/2601.18284,
ArXiv,TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment,https://arxiv.org/abs/2601.18292,
ArXiv,Reinforcement Learning with Distributed MPC for Fuel-Efficient Platoon Control with Discrete Gear Transitions,https://arxiv.org/abs/2601.18294,
ArXiv,Temp-R1: A Unified Autonomous Agent for Complex Temporal KGQA via Reverse Curriculum Reinforcement Learning,https://arxiv.org/abs/2601.18296,
ArXiv,OffSeeker: Online Reinforcement Learning Is Not All You Need for Deep Research Agents,https://arxiv.org/abs/2601.18467,
ArXiv,Just-In-Time Reinforcement Learning: Continual Learning in LLM Agents Without Gradient Updates,https://arxiv.org/abs/2601.18510,
ArXiv,From Verifiable Dot to Reward Chain: Harnessing Verifiable Reference-based Rewards for Reinforcement Learning of Open-ended Generation,https://arxiv.org/abs/2601.18533,
ArXiv,K-Myriad: Jump-starting reinforcement learning with unsupervised parallel agents,https://arxiv.org/abs/2601.18580,
ArXiv,Learning long term climate-resilient transport adaptation pathways under direct and indirect flood impacts using reinforcement learning,https://arxiv.org/abs/2601.18586,
ArXiv,Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning,https://arxiv.org/abs/2601.18626,
ArXiv,ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule,https://arxiv.org/abs/2601.18681,
ArXiv,"Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback",https://arxiv.org/abs/2601.18751,
ArXiv,Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic,https://arxiv.org/abs/2601.18783,
ArXiv,Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes,https://arxiv.org/abs/2601.18795,
ArXiv,Emergent Cooperation in Quantum Multi-Agent Reinforcement Learning Using Communication,https://arxiv.org/abs/2601.18419,
ArXiv,Deep Reinforcement Learning for Hybrid RIS Assisted MIMO Communications,https://arxiv.org/abs/2601.18453,
