feed,title,long_url,short_url
ArXiv,Improving News Recommendations through Hybrid Sentiment Modelling and Reinforcement Learning,https://arxiv.org/abs/2601.02372,
ArXiv,Base Station Deployment under EMF constrain by Deep Reinforcement learning,https://arxiv.org/abs/2601.02385,
ArXiv,Regional Resource Management for Service Provisioning in LEO Satellite Networks: A Topology Feature-Based DRL Approach,https://arxiv.org/abs/2601.02387,
ArXiv,LLM-Enhanced Reinforcement Learning for Time Series Anomaly Detection,https://arxiv.org/abs/2601.02511,
ArXiv,Textual Explanations and Their Evaluations for Reinforcement Learning Policy,https://arxiv.org/abs/2601.02514,
ArXiv,SWaRL: Safeguard Code Watermarking via Reinforcement Learning,https://arxiv.org/abs/2601.02602,
ArXiv,Prioritized Replay for RL Post-training,https://arxiv.org/abs/2601.02648,
ArXiv,Inferring Causal Graph Temporal Logic Formulas to Expedite Reinforcement Learning in Temporally Extended Tasks,https://arxiv.org/abs/2601.02666,
ArXiv,Reinforcement Learning for Follow-the-Leader Robotic Endoscopic Navigation via Synthetic Data,https://arxiv.org/abs/2601.02798,
ArXiv,Sample-Efficient Neurosymbolic Deep Reinforcement Learning,https://arxiv.org/abs/2601.02850,
ArXiv,Interpretable All-Type Audio Deepfake Detection with Audio LLMs via Frequency-Time Reinforcement Learning,https://arxiv.org/abs/2601.02983,
ArXiv,In-Context Reinforcement Learning through Bayesian Fusion of Context and Value Prior,https://arxiv.org/abs/2601.03015,
ArXiv,One Sample to Rule Them All: Extreme Data Efficiency in RL Scaling,https://arxiv.org/abs/2601.03111,
ArXiv,MemRL: Self-Evolving Agents via Runtime Reinforcement Learning on Episodic Memory,https://arxiv.org/abs/2601.03192,
ArXiv,STReasoner: Empowering LLMs for Spatio-Temporal Reasoning in Time Series via Spatial-Aware Reinforcement Learning,https://arxiv.org/abs/2601.03248,
