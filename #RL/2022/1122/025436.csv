feed,title,long_url,short_url
ArXiv,Analysis of Reinforcement Learning Schemes for Trajectory Optimization of an Aerial Radio Unit,https://arxiv.org/abs/2211.10524v1,
ArXiv,Provable Defense against Backdoor Policies in Reinforcement Learning,https://arxiv.org/abs/2211.10530v1,
ArXiv,Debiasing Meta-Gradient Reinforcement Learning by Learning the Outer Value Function,https://arxiv.org/abs/2211.10550v1,
ArXiv,Prediction-aware and Reinforcement Learning based Altruistic Cooperative Driving,https://arxiv.org/abs/2211.10585v1,
ArXiv,Evaluating the Perceived Safety of Urban City via Maximum Entropy Deep Inverse Reinforcement Learning,https://arxiv.org/abs/2211.10660v1,
ArXiv,ReInform: Selecting paths with reinforcement learning for contextualized link prediction,https://arxiv.org/abs/2211.10688v1,
ArXiv,PIC4rl-gym: a ROS2 modular framework for Robots Autonomous Navigation with Deep Reinforcement Learning,https://arxiv.org/abs/2211.10714v1,
ArXiv,Let Graph be the Go Board: Gradient-free Node Injection Attack for Graph Neural Networks via Reinforcement Learning,https://arxiv.org/abs/2211.10782v1,
ArXiv,"Non-stationary Risk-sensitive Reinforcement Learning: Near-optimal Dynamic Regret, Adaptive Detection, and Separation Design",https://arxiv.org/abs/2211.10815v1,
ArXiv,Structure-Enhanced Deep Reinforcement Learning for Optimal Transmission Scheduling,https://arxiv.org/abs/2211.10827v1,
ArXiv,Efficient Meta Reinforcement Learning for Preference-based Fast Adaptation,https://arxiv.org/abs/2211.10861v1,
ArXiv,SafeLight: A Reinforcement Learning Method toward Collision-free Traffic Signal Control,https://arxiv.org/abs/2211.10871v1,
ArXiv,Noisy Symbolic Abstractions for Deep RL: A case study with Reward Machines,https://arxiv.org/abs/2211.10902v1,
ArXiv,Learning to Search for Job Shop Scheduling via Deep Reinforcement Learning,https://arxiv.org/abs/2211.10936v1,
ArXiv,Efficient Off-Policy Q-Learning for Data-Based Discrete-Time LQR Problems,https://arxiv.org/abs/2105.07761v2,
ArXiv,Deep reinforcement learning under signal temporal logic constraints using Lagrangian relaxation,https://arxiv.org/abs/2201.08504v4,
ArXiv,Provably Efficient Primal-Dual Reinforcement Learning for CMDPs with Non-stationary Objectives and Constraints,https://arxiv.org/abs/2201.11965v4,
ArXiv,Safe Reinforcement Learning Using Black-Box Reachability Analysis,https://arxiv.org/abs/2204.07417v2,
ArXiv,An Evaluation Study of Intrinsic Motivation Techniques applied to Reinforcement Learning over Hard Exploration Environments,https://arxiv.org/abs/2205.11184v2,
ArXiv,Routing Planning for Last-Mile Deliveries Using Mobile Parcel Lockers: A Hybrid Q-Learning Network Approach,https://arxiv.org/abs/2209.04265v2,
ArXiv,Fast Lifelong Adaptive Inverse Reinforcement Learning from Demonstrations,https://arxiv.org/abs/2209.11908v3,
ArXiv,Enforcing Hard Constraints with Soft Barriers: Safe Reinforcement Learning in Unknown Stochastic Environments,https://arxiv.org/abs/2209.15090v2,
ArXiv,DHRL: A Graph-Based Approach for Long-Horizon and Sparse Hierarchical Reinforcement Learning,https://arxiv.org/abs/2210.05150v3,
ArXiv,CORL: Research-oriented Deep Offline Reinforcement Learning Library,https://arxiv.org/abs/2210.07105v2,
ArXiv,Oracles & Followers: Stackelberg Equilibria in Deep Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2210.11942v2,
ArXiv,Offline RL With Realistic Datasets: Heteroskedasticity and Support Constraints,https://arxiv.org/abs/2211.01052v2,
ArXiv,Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control Approach,https://arxiv.org/abs/2211.10298v2,
ArXiv,Revealing Robust Oil and Gas Company Macro-Strategies using Deep Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2211.11043v1,
ArXiv,Safe Reinforcement Learning using Data-Driven Predictive Control,https://arxiv.org/abs/2211.11027v1,
ArXiv,Reinforcement Learning-Enhanced Control Barrier Functions for Robot Manipulators,https://arxiv.org/abs/2211.11391v1,
ArXiv,RL Boltzmann Generators for Conformer Generation in Data-Sparse Environments,https://arxiv.org/abs/2211.10771v1,
ArXiv,Model-based Trajectory Stitching for Improved Offline Reinforcement Learning,https://arxiv.org/abs/2211.11603v1,
