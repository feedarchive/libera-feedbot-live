feed,title,long_url,short_url
ArXiv,Reward Function Optimization of a Deep Reinforcement Learning Collision Avoidance System,https://arxiv.org/abs/2212.00855v1,
ArXiv,Modeling Mobile Health Users as Reinforcement Learning Agents,https://arxiv.org/abs/2212.00863v1,
ArXiv,Decisions that Explain Themselves: A User-Centric Deep Reinforcement Learning Explanation System,https://arxiv.org/abs/2212.00888v1,
ArXiv,Karolos: An Open-Source Reinforcement Learning Framework for Robot-Task Environments,https://arxiv.org/abs/2212.00906v1,
ArXiv,STL-Based Synthesis of Feedback Controllers Using Reinforcement Learning,https://arxiv.org/abs/2212.01022v1,
ArXiv,Flow to Control: Offline Reinforcement Learning with Lossless Primitive Discovery,https://arxiv.org/abs/2212.01105v1,
ArXiv,Utilizing Prior Solutions for Reward Shaping and Composition in Entropy-Regularized Reinforcement Learning,https://arxiv.org/abs/2212.01174v1,
ArXiv,Selecting Mechanical Parameters of a Monopode Jumping System with Reinforcement Learning,https://arxiv.org/abs/2212.01303v1,
ArXiv,CT-DQN: Control-Tutored Deep Reinforcement Learning,https://arxiv.org/abs/2212.01343v1,
ArXiv,Predict-and-Critic: Accelerated End-to-End Predictive Control for Cloud Computing through Reinforcement Learning,https://arxiv.org/abs/2212.01348v1,
ArXiv,Supervised Learning and Reinforcement Learning of Feedback Models for Reactive Behaviors: Tactile Feedback Testbed,https://arxiv.org/abs/2007.00450v2,
ArXiv,HAMMER: Multi-Level Coordination of Reinforcement Learning Agents via Learned Messaging,https://arxiv.org/abs/2102.00824v2,
ArXiv,Implementing Reinforcement Learning Datacenter Congestion Control in NVIDIA NICs,https://arxiv.org/abs/2207.02295v2,
ArXiv,Probabilistic Safeguard for Reinforcement Learning Using Safety Index Guided Gaussian Process Models,https://arxiv.org/abs/2210.01041v3,
ArXiv,ACE: Cooperative Multi-agent Q-learning with Bidirectional Action-Dependency,https://arxiv.org/abs/2211.16068v2,
