feed,title,long_url,short_url
ArXiv,Hierarchical Decentralized Deep Reinforcement Learning Architecture for a Simulated Four-Legged Agent,https://arxiv.org/abs/2210.08003v1,
ArXiv,Multi-trainer Interactive Reinforcement Learning System,https://arxiv.org/abs/2210.08050v1,
ArXiv,Adaptive patch foraging in deep reinforcement learning agents,https://arxiv.org/abs/2210.08085v1,
ArXiv,Geometric Reinforcement Learning: The Case of Cartesian Space Orientation,https://arxiv.org/abs/2210.08126v1,
ArXiv,Model-Free Characterizations of the Hamilton-Jacobi-Bellman Equation and Convex Q-Learning in Continuous Time,https://arxiv.org/abs/2210.08131v1,
ArXiv,PI-QT-Opt: Predictive Information Improves Multi-Task Robotic Reinforcement Learning at Scale,https://arxiv.org/abs/2210.08217v1,
ArXiv,Near-Optimal Regret Bounds for Multi-batch Reinforcement Learning,https://arxiv.org/abs/2210.08238v1,
ArXiv,Reinforcement Learning for ConnectX,https://arxiv.org/abs/2210.08263v1,
ArXiv,A Scalable Reinforcement Learning Approach for Attack Allocation in Swarm to Swarm Engagement Problems,https://arxiv.org/abs/2210.08319v1,
ArXiv,A Policy-Guided Imitation Approach for Offline Reinforcement Learning,https://arxiv.org/abs/2210.08323v1,
ArXiv,Breaking the Sample Complexity Barrier to Regret-Optimal Model-Free Reinforcement Learning,https://arxiv.org/abs/2110.04645v2,
ArXiv,Temporal Abstraction in Reinforcement Learning with the Successor Representation,https://arxiv.org/abs/2110.05740v2,
ArXiv,Influencing Long-Term Behavior in Multiagent Reinforcement Learning,https://arxiv.org/abs/2203.03535v4,
ArXiv,Efficient Scheduling of Data Augmentation for Deep Reinforcement Learning,https://arxiv.org/abs/2206.00518v3,
ArXiv,Sample-Efficient Reinforcement Learning of Partially Observable Markov Games,https://arxiv.org/abs/2206.01315v2,
ArXiv,Receding Horizon Inverse Reinforcement Learning,https://arxiv.org/abs/2206.04477v2,
ArXiv,Mean-Semivariance Policy Optimization via Risk-Averse Reinforcement Learning,https://arxiv.org/abs/2206.07376v2,
ArXiv,Model-based RL with Optimistic Posterior Sampling: Structural Conditions and Sample Complexity,https://arxiv.org/abs/2206.07659v2,
ArXiv,When to Trust Your Simulator: Dynamics-Aware Hybrid Offline-and-Online Reinforcement Learning,https://arxiv.org/abs/2206.13464v2,
ArXiv,Generalizing Goal-Conditioned Reinforcement Learning with Variational Causal Reasoning,https://arxiv.org/abs/2207.09081v4,
ArXiv,Understanding Deep Neural Function Approximation in Reinforcement Learning via $\epsilon$-Greedy Exploration,https://arxiv.org/abs/2209.07376v2,
ArXiv,A multilevel reinforcement learning framework for PDE based control,https://arxiv.org/abs/2210.08400v1,
ArXiv,The Impact of Task Underspecification in Evaluating Deep Reinforcement Learning,https://arxiv.org/abs/2210.08607v1,
ArXiv,Data-Efficient Pipeline for Offline Reinforcement Learning with Limited Data,https://arxiv.org/abs/2210.08642v1,
