feed,title,long_url,short_url
ArXiv,Human-level Atari 200x faster,https://arxiv.org/abs/2209.07550v1,
ArXiv,Conservative Dual Policy Optimization for Efficient Model-Based Reinforcement Learning,https://arxiv.org/abs/2209.07676v1,
ArXiv,M$^2$DQN: A Robust Method for Accelerating Deep Q-learning Network,https://arxiv.org/abs/2209.07809v1,
ArXiv,Neuromuscular Reinforcement Learning to Actuate Human Limbs through FES,https://arxiv.org/abs/2209.07849v1,
ArXiv,Adaptive Natural Language Generation for Task-oriented Dialogue via Reinforcement Learning,https://arxiv.org/abs/2209.07873v1,
ArXiv,SoLo T-DIRL: Socially-Aware Dynamic Local Planner based on Trajectory-Ranked Deep Inverse Reinforcement Learning,https://arxiv.org/abs/2209.07996v1,
ArXiv,"Trustworthy Reinforcement Learning Against Intrinsic Vulnerabilities: Robustness, Safety, and Generalizability",https://arxiv.org/abs/2209.08025v1,
ArXiv,Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model,https://arxiv.org/abs/2005.12900v6,
ArXiv,Overcoming Exploration: Deep Reinforcement Learning in Complex Environments from Temporal Logic Specifications,https://arxiv.org/abs/2201.12231v3,
ArXiv,Meta-Reinforcement Learning via Language Instructions,https://arxiv.org/abs/2209.04924v2,
