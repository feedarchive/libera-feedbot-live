feed,title,long_url,short_url
ArXiv,Bridging the Gap Between Offline and Online Reinforcement Learning Evaluation Methodologies,https://arxiv.org/abs/2212.08131v1,
ArXiv,Reinforcement Learning for Agile Active Target Sensing with a UAV,https://arxiv.org/abs/2212.08214v1,
ArXiv,Multi-Agent Patrolling with Battery Constraints through Deep Reinforcement Learning,https://arxiv.org/abs/2212.08230v1,
ArXiv,Offline Robot Reinforcement Learning with Uncertainty-Guided Human Expert Sampling,https://arxiv.org/abs/2212.08232v1,
ArXiv,Offline Reinforcement Learning for Visual Navigation,https://arxiv.org/abs/2212.08244v1,
ArXiv,Partially Observable RL with B-Stability: Unified Structural Condition and Sharp Sample-Efficient Algorithms,https://arxiv.org/abs/2209.14990v2,
ArXiv,When to Update Your Model: Constrained Model-based Reinforcement Learning,https://arxiv.org/abs/2210.08349v2,
ArXiv,Provably Efficient Model-free RL in Leader-Follower MDP with Linear Function Approximation,https://arxiv.org/abs/2211.15792v2,
