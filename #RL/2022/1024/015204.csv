feed,title,long_url,short_url
ArXiv,Global Convergence of Direct Policy Search for State-Feedback $\mathcal{H}_\infty$ Robust Control: A Revisit of Nonsmooth Synthesis with Goldstein Subdifferential,https://arxiv.org/abs/2210.11577v1,
ArXiv,Model-based Lifelong Reinforcement Learning with Bayesian Exploration,https://arxiv.org/abs/2210.11579v1,
ArXiv,Horizon-Free Reinforcement Learning for Latent Markov Decision Processes,https://arxiv.org/abs/2210.11604v1,
ArXiv,PaCo: Parameter-Compositional Multi-Task Reinforcement Learning,https://arxiv.org/abs/2210.11653v1,
ArXiv,Random Actions vs Random Policies: Bootstrapping Model-Based Direct Policy Search,https://arxiv.org/abs/2210.11801v1,
ArXiv,Integrating Policy Summaries with Reward Decomposition for Explaining Reinforcement Learning Agents,https://arxiv.org/abs/2210.11825v1,
ArXiv,Counterfactual Explanations for Reinforcement Learning,https://arxiv.org/abs/2210.11846v1,
ArXiv,Deep Reinforcement Learning for Inverse Inorganic Materials Design,https://arxiv.org/abs/2210.11931v1,
ArXiv,Oracles & Followers: Stackelberg Equilibria in Deep Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2210.11942v1,
ArXiv,Adaptively Calibrated Critic Estimates for Deep Reinforcement Learning,https://arxiv.org/abs/2111.12673v2,
ArXiv,First-Order Regret in Reinforcement Learning with Linear Function Approximation: A Robust Estimation Approach,https://arxiv.org/abs/2112.03432v4,
ArXiv,Evolving Generalizable Actor-Critic Algorithms,https://arxiv.org/abs/2204.04292v2,
ArXiv,Final Iteration Convergence of Q-Learning: Switching System Approach,https://arxiv.org/abs/2205.05455v3,
ArXiv,RL with KL penalties is better viewed as Bayesian inference,https://arxiv.org/abs/2205.11275v2,
ArXiv,Value Function Decomposition for Iterative Design of Reinforcement Learning Agents,https://arxiv.org/abs/2206.13901v2,
ArXiv,Monte Carlo Augmented Actor-Critic for Sparse Reward Deep Reinforcement Learning from Suboptimal Demonstrations,https://arxiv.org/abs/2210.07432v2,
