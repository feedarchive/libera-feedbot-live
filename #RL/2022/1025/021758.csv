feed,title,long_url,short_url
ArXiv,Deep Reinforcement Learning for Stabilization of Large-scale Probabilistic Boolean Networks,https://arxiv.org/abs/2210.12229v1,
ArXiv,Group Distributionally Robust Reinforcement Learning with Hierarchical Latent Variables,https://arxiv.org/abs/2210.12262v1,
ArXiv,Implicit Offline Reinforcement Learning via Supervised Learning,https://arxiv.org/abs/2210.12272v1,
ArXiv,Continual Reinforcement Learning with Group Symmetries,https://arxiv.org/abs/2210.12301v1,
ArXiv,Attitude Control of Highly Maneuverable Aircraft Using an Improved Q-learning,https://arxiv.org/abs/2210.12317v1,
ArXiv,Probing Transfer in Deep Reinforcement Learning without Task Engineering,https://arxiv.org/abs/2210.12448v1,
ArXiv,Faster and more diverse de novo molecular optimization with double-loop reinforcement learning using augmented SMILES,https://arxiv.org/abs/2210.12458v1,
ArXiv,Cut-and-Approximate: 3D Shape Reconstruction from Planar Cross-sections with Deep Reinforcement Learning,https://arxiv.org/abs/2210.12509v1,
ArXiv,Deep Q-Learning for Nash Equilibria: Nash-DQN,https://arxiv.org/abs/1904.10554v2,
ArXiv,Refine and Imitate: Reducing Repetition and Inconsistency in Persuasion Dialogues via Reinforcement Learning and Human Demonstration,https://arxiv.org/abs/2012.15375v2,
ArXiv,Reinforcement Learning for Ridesharing: An Extended Survey,https://arxiv.org/abs/2105.01099v8,
ArXiv,Efficient (Soft) Q-Learning for Text Generation with Limited Good Data,https://arxiv.org/abs/2106.07704v4,
ArXiv,Learning a subspace of policies for online adaptation in Reinforcement Learning,https://arxiv.org/abs/2110.05169v3,
ArXiv,Global Optimality and Finite Sample Analysis of Softmax Off-Policy Actor Critic under State Distribution Mismatch,https://arxiv.org/abs/2111.02997v3,
ArXiv,A Multi-Agent Reinforcement Learning Framework for Off-Policy Evaluation in Two-sided Markets,https://arxiv.org/abs/2202.10574v3,
ArXiv,Near Instance-Optimal PAC Reinforcement Learning for Deterministic MDPs,https://arxiv.org/abs/2203.09251v3,
ArXiv,RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning,https://arxiv.org/abs/2205.12548v3,
ArXiv,RORL: Robust Offline Reinforcement Learning via Conservative Smoothing,https://arxiv.org/abs/2206.02829v3,
ArXiv,On the Statistical Efficiency of Reward-Free Exploration in Non-Linear RL,https://arxiv.org/abs/2206.10770v2,
ArXiv,Reinforcement Learning-based Joint User Scheduling and Link Configuration in Millimeter-wave Networks,https://arxiv.org/abs/2207.03526v2,
ArXiv,Joint Task Offloading and Resource Optimization in NOMA-based Vehicular Edge Computing: A Game-Theoretic DRL Approach,https://arxiv.org/abs/2209.12749v2,
ArXiv,A Comprehensive Survey of Data Augmentation in Visual Reinforcement Learning,https://arxiv.org/abs/2210.04561v2,
ArXiv,DHRL: A Graph-Based Approach for Long-Horizon and Sparse Hierarchical Reinforcement Learning,https://arxiv.org/abs/2210.05150v2,
ArXiv,CEIP: Combining Explicit and Implicit Priors for Reinforcement Learning with Demonstrations,https://arxiv.org/abs/2210.09496v2,
ArXiv,MetaEMS: A Meta Reinforcement Learning-based Control Framework for Building Energy Management System,https://arxiv.org/abs/2210.12590v1,
ArXiv,Local Connection Reinforcement Learning Method for Efficient Control of Robotic Peg-in-Hole Assembly,https://arxiv.org/abs/2210.13255v1,
ArXiv,ADLight: A Universal Approach of Traffic Signal Control with Augmented Data Using Reinforcement Learning,https://arxiv.org/abs/2210.13378v1,
ArXiv,Reinforcement Learning Algorithm for Mixed Mean Field Control Games,https://arxiv.org/abs/2205.02330v2,
