feed,title,long_url,short_url
ArXiv,Quantum-Inspired DRL Approach with LSTM and OU Noise for Cut Order Planning Optimization,https://arxiv.org/abs/2508.16611,
ArXiv,WST: Weak-to-Strong Knowledge Transfer via Reinforcement Learning,https://arxiv.org/abs/2508.16741,
ArXiv,Assess and Prompt: A Generative RL Framework for Improving Engagement in Online Mental Health Communities,https://arxiv.org/abs/2508.16788,
ArXiv,Dream to Chat: Model-based Reinforcement Learning on Dialogues with User Belief Modeling,https://arxiv.org/abs/2508.16876,
ArXiv,Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning,https://arxiv.org/abs/2508.16949,
ArXiv,KL-Regularised Q-Learning: A Token-level Action-Value perspective on Online RLHF,https://arxiv.org/abs/2508.17000,
ArXiv,Reinforcement Learning enhanced Online Adaptive Clinical Decision Support via Digital Twin powered Policy and Treatment Effect optimized Reward,https://arxiv.org/abs/2508.17212,
ArXiv,Federated Reinforcement Learning for Runtime Optimization of AI Applications in Smart Eyewears,https://arxiv.org/abs/2508.17262,
ArXiv,Rectified Robust Policy Optimization for Model-Uncertain Constrained Reinforcement Learning without Strong Duality,https://arxiv.org/abs/2508.17448,
ArXiv,ReviBranch: Deep Reinforcement Learning for Branch-and-Bound with Revived Trajectories,https://arxiv.org/abs/2508.17452,
ArXiv,ChartMaster: Advancing Chart-to-Code Generation with Real-World Charts and Chart Similarity Reinforcement Learning,https://arxiv.org/abs/2508.17608,
ArXiv,EMPOWER: Evolutionary Medical Prompt Optimization With Reinforcement Learning,https://arxiv.org/abs/2508.17703,
ArXiv,Multi-layer Abstraction for Nested Generation of Options (MANGO) in Hierarchical Reinforcement Learning,https://arxiv.org/abs/2508.17751,
ArXiv,Group Expectation Policy Optimization for Stable Heterogeneous Reinforcement Learning in LLMs,https://arxiv.org/abs/2508.17850,
ArXiv,Visual-CoG: Stage-Aware Reinforcement Learning with Chain of Guidance for Text-to-Image Generation,https://arxiv.org/abs/2508.18032,
