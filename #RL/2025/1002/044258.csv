feed,title,long_url,short_url
ArXiv,ToolBrain: A Flexible Reinforcement Learning Framework for Agentic Tools,https://arxiv.org/abs/2510.00023,
ArXiv,Reinforcement Learning-Based Prompt Template Stealing for Text-to-Image Models,https://arxiv.org/abs/2510.00046,
ArXiv,Geo-R1: Unlocking VLM Geospatial Reasoning with Cross-View Reinforcement Learning,https://arxiv.org/abs/2510.00072,
ArXiv,Which Rewards Matter? Reward Selection for Reinforcement Learning under Limited Feedback,https://arxiv.org/abs/2510.00144,
ArXiv,Directed-MAML: Meta Reinforcement Learning Algorithm with Task-directed Approximation,https://arxiv.org/abs/2510.00212,
ArXiv,MAGIC-MASK: Multi-Agent Guided Inter-Agent Collaboration with Mask-Based Explainability for Reinforcement Learning,https://arxiv.org/abs/2510.00274,
ArXiv,Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning,https://arxiv.org/abs/2510.00329,
ArXiv,DiSA-IQL: Offline Reinforcement Learning for Robust Soft Robot Control under Distribution Shifts,https://arxiv.org/abs/2510.00358,
ArXiv,Integrating Offline Pre-Training with Online Fine-Tuning: A Reinforcement Learning Approach for Robot Social Navigation,https://arxiv.org/abs/2510.00466,
ArXiv,Expandable Decision-Making States for Multi-Agent Deep Reinforcement Learning in Soccer Tactical Analysis,https://arxiv.org/abs/2510.00480,
ArXiv,On Predictability of Reinforcement Learning Dynamics for Large Language Models,https://arxiv.org/abs/2510.00553,
ArXiv,TD-JEPA: Latent-predictive Representations for Zero-Shot Reinforcement Learning,https://arxiv.org/abs/2510.00739,
ArXiv,Guiding Evolutionary Molecular Design: Adding Reinforcement Learning for Mutation Selection,https://arxiv.org/abs/2510.00802,
ArXiv,Stabilizing Policy Gradients for Sample-Efficient Reinforcement Learning in LLM Reasoning,https://arxiv.org/abs/2510.00819,
ArXiv,Erase to Improve: Erasable Reinforcement Learning for Search-Augmented LLMs,https://arxiv.org/abs/2510.00861,
ArXiv,Rectifying Regression in Reinforcement Learning,https://arxiv.org/abs/2510.00885,
ArXiv,Reinforcement Learning with Verifiable yet Noisy Rewards under Imperfect Verifiers,https://arxiv.org/abs/2510.00915,
ArXiv,QUASAR: Quantum Assembly Code Generation Using Tool-Augmented LLMs via Agentic RL,https://arxiv.org/abs/2510.00967,
ArXiv,Research on the Integration of Embodied Intelligence and Reinforcement Learning in Textual Domains,https://arxiv.org/abs/2510.01076,
ArXiv,Multi-Actor Multi-Critic Deep Deterministic Reinforcement Learning with a Novel Q-Ensemble Method,https://arxiv.org/abs/2510.01083,
ArXiv,Eliciting Chain-of-Thought Reasoning for Time Series Analysis using Reinforcement Learning,https://arxiv.org/abs/2510.01116,
ArXiv,A Practitioner's Guide to Multi-turn Agentic Reinforcement Learning,https://arxiv.org/abs/2510.01132,
ArXiv,Prosperity before Collapse: How Far Can Off-Policy RL Reach with Stale Data on LLMs?,https://arxiv.org/abs/2510.01161,
ArXiv,BroRL: Scaling Reinforcement Learning via Broadened Exploration,https://arxiv.org/abs/2510.01180,
ArXiv,Reinforcement Learning with Discrete Diffusion Policies for Combinatorial Action Spaces,https://arxiv.org/abs/2509.22963,
