feed,title,long_url,short_url
ArXiv,Q-Learning-Based Time-Critical Data Aggregation Scheduling in IoT,https://arxiv.org/abs/2511.17531,
ArXiv,Enhancing Robustness of Offline Reinforcement Learning Under Data Corruption via Sharpness-Aware Minimization,https://arxiv.org/abs/2511.17568,
ArXiv,Boosting Reinforcement Learning in 3D Visuospatial Tasks Through Human-Informed Curriculum Design,https://arxiv.org/abs/2511.17595,
ArXiv,Non-stationary and Varying-discounting Markov Decision Processes for Reinforcement Learning,https://arxiv.org/abs/2511.17598,
ArXiv,Can we use LLMs to bootstrap reinforcement learning? -- A case study in digital health behavior change,https://arxiv.org/abs/2511.17630,
ArXiv,Dialogue Diplomats: An End-to-End Multi-Agent Reinforcement Learning System for Automated Conflict Resolution and Consensus Building,https://arxiv.org/abs/2511.17654,
ArXiv,Physical Reinforcement Learning,https://arxiv.org/abs/2511.17789,
ArXiv,"Transformers with RL or SFT Provably Learn Sparse Boolean Functions, But Differently",https://arxiv.org/abs/2511.17852,
ArXiv,Training Emergent Joint Associations: A Reinforcement Learning Approach to Creative Thinking in Language Models,https://arxiv.org/abs/2511.17876,
ArXiv,PA-FAS: Towards Interpretable and Generalizable Multimodal Face Anti-Spoofing via Path-Augmented Reinforcement Learning,https://arxiv.org/abs/2511.17927,
ArXiv,A Reinforcement Learning Framework for Resource Allocation in Uplink Carrier Aggregation in the Presence of Self Interference,https://arxiv.org/abs/2511.17931,
ArXiv,SPINE: Token-Selective Test-Time Reinforcement Learning with Entropy-Band Regularization,https://arxiv.org/abs/2511.17938,
ArXiv,Reward Engineering for Spatial Epidemic Simulations: A Reinforcement Learning Platform for Individual Behavioral Learning,https://arxiv.org/abs/2511.18000,
ArXiv,A New Error Temporal Difference Algorithm for Deep Reinforcement Learning in Microgrid Optimization,https://arxiv.org/abs/2511.18093,
ArXiv,MOMA-AC: A preference-driven actor-critic framework for continuous multi-objective multi-agent reinforcement learning,https://arxiv.org/abs/2511.18181,
ArXiv,A Novel and Practical Universal Adversarial Perturbations against Deep Reinforcement Learning based Intrusion Detection Systems,https://arxiv.org/abs/2511.18223,
ArXiv,Carbon-Aware Intrusion Detection: A Comparative Study of Supervised and Unsupervised DRL for Sustainable IoT Edge Gateways,https://arxiv.org/abs/2511.18240,
ArXiv,Dreaming Falcon: Physics-Informed Model-Based Reinforcement Learning for Quadcopters,https://arxiv.org/abs/2511.18243,
ArXiv,Tail Distribution of Regret in Optimistic Reinforcement Learning,https://arxiv.org/abs/2511.18247,
ArXiv,Natural Emergent Misalignment from Reward Hacking in Production RL,https://arxiv.org/abs/2511.18397,
ArXiv,Reinforcement Learning for Self-Healing Material Systems,https://arxiv.org/abs/2511.18728,
ArXiv,Periodic Asynchrony: An Effective Method for Accelerating On-Policy Reinforcement Learning,https://arxiv.org/abs/2511.18871,
ArXiv,Accelerating Reinforcement Learning via Error-Related Human Brain Signals,https://arxiv.org/abs/2511.18878,
ArXiv,VADE: Variance-Aware Dynamic Sampling via Online Sample-Level Difficulty Estimation for Multimodal RL,https://arxiv.org/abs/2511.18902,
ArXiv,FastForward Pruning: Efficient LLM Pruning via Single-Step Reinforcement Learning,https://arxiv.org/abs/2511.18977,
ArXiv,Energy-Efficient Routing Protocol in Vehicular Opportunistic Networks: A Dynamic Cluster-based Routing Using Deep Reinforcement Learning,https://arxiv.org/abs/2511.19026,
ArXiv,ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay,https://arxiv.org/abs/2511.19033,
ArXiv,VIL2C: Value-of-Information Aware Low-Latency Communication for Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2511.19146,
ArXiv,First-order Sobolev Reinforcement Learning,https://arxiv.org/abs/2511.19165,
ArXiv,Leveraging LLMs for reward function design in reinforcement learning control tasks,https://arxiv.org/abs/2511.19355,
ArXiv,LLM-Driven Stationarity-Aware Expert Demonstrations for Multi-Agent Reinforcement Learning in Mobile Systems,https://arxiv.org/abs/2511.19368,
ArXiv,DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research,https://arxiv.org/abs/2511.19399,
ArXiv,SLMFix: Leveraging Small Language Models for Error Fixing with Reinforcement Learning,https://arxiv.org/abs/2511.19422,
ArXiv,"On a Reinforcement Learning Methodology for Epidemic Control, with application to COVID-19",https://arxiv.org/abs/2511.18035,
ArXiv,Reinforcement Learning for Portfolio Optimization with a Financial Goal and Defined Time Horizons,https://arxiv.org/abs/2511.18076,
ArXiv,Advancing Multi-Agent RAG Systems with Minimalist Reinforcement Learning,https://arxiv.org/abs/2505.17086,
ArXiv,"MARL-CC: A Mathematical Framework forMulti-Agent Reinforcement Learning in ConnectedAutonomous Vehicles: Addressing Nonlinearity,Partial Observability, and Credit Assignment forOptimal Control",https://arxiv.org/abs/2511.17653,
