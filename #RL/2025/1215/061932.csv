feed,title,long_url,short_url
ArXiv,TECM*: A Data-Driven Assessment to Reinforcement Learning Methods and Application to Heparin Treatment Strategy for Surgical Sepsis,https://arxiv.org/abs/2512.10973,
ArXiv,"Benchmarking RL-Enhanced Spatial Indices Against Traditional, Advanced, and Learned Counterparts",https://arxiv.org/abs/2512.11161,
ArXiv,Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning,https://arxiv.org/abs/2512.11179,
ArXiv,Multi-Objective Reinforcement Learning for Large-Scale Mixed Traffic Control,https://arxiv.org/abs/2512.11247,
ArXiv,When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents,https://arxiv.org/abs/2512.11277,
ArXiv,RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training,https://arxiv.org/abs/2512.11306,
ArXiv,DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning,https://arxiv.org/abs/2512.11342,
ArXiv,Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes,https://arxiv.org/abs/2512.11463,
ArXiv,"From ""Thumbs Up"" to ""10 out of 10"": Reconsidering Scalar Feedback in Interactive Reinforcement Learning",https://arxiv.org/abs/2311.10284,
ArXiv,Annotation-Free Reinforcement Learning Query Rewriting via Verifiable Search Reward,https://arxiv.org/abs/2507.23242,
