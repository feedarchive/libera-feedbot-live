feed,title,long_url,short_url
ArXiv,Human Implicit Preference-Based Policy Fine-tuning for Multi-Agent Reinforcement Learning in USV Swarm,https://arxiv.org/abs/2503.03796,
ArXiv,Seldonian Reinforcement Learning for Ad Hoc Teamwork,https://arxiv.org/abs/2503.03885,
ArXiv,Dexterous Hand Manipulation via Efficient Imitation-Bootstrapped Online Reinforcement Learning,https://arxiv.org/abs/2503.04014,
ArXiv,Can We Optimize Deep RL Policy Weights as Trajectory Modeling?,https://arxiv.org/abs/2503.04074,
ArXiv,SED2AM: Solving Multi-Trip Time-Dependent Vehicle Routing Problem using Deep Reinforcement Learning,https://arxiv.org/abs/2503.04085,
ArXiv,MTS: A Deep Reinforcement Learning Portfolio Management Framework with Time-Awareness and Short-Selling,https://arxiv.org/abs/2503.04143,
ArXiv,Quantum-Inspired Reinforcement Learning in the Presence of Epistemic Ambivalence,https://arxiv.org/abs/2503.04219,
ArXiv,Knowledge Retention for Continual Model-Based Reinforcement Learning,https://arxiv.org/abs/2503.04256,
ArXiv,Guidelines for Applying RL and MARL in Cybersecurity Applications,https://arxiv.org/abs/2503.04262,
ArXiv,Frequency Hopping Synchronization by Reinforcement Learning for Satellite Communication System,https://arxiv.org/abs/2503.04266,
ArXiv,Towards Autonomous Reinforcement Learning for Real-World Robotic Manipulation with Large Language Models,https://arxiv.org/abs/2503.04280,
ArXiv,Multi-Agent Inverse Q-Learning from Demonstrations,https://arxiv.org/abs/2503.04679,
ArXiv,L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning,https://arxiv.org/abs/2503.04697,
ArXiv,Quantum reinforcement learning in continuous action space,https://arxiv.org/abs/2012.10711,
ArXiv,Hedging with Sparse Reward Reinforcement Learning,https://arxiv.org/abs/2503.04218,
