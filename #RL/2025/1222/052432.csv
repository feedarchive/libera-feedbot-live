feed,title,long_url,short_url
ArXiv,Turn-PPO: Turn-Level Advantage Estimation with PPO for Improved Multi-Turn RL in Agentic LLMs,https://arxiv.org/abs/2512.17008,
ArXiv,GB-DQN: Gradient Boosted DQN Models for Non-stationary Reinforcement Learning,https://arxiv.org/abs/2512.17034,
ArXiv,UniRel-R1: RL-tuned LLM Reasoning for Knowledge Graph Relational Question Answering,https://arxiv.org/abs/2512.17043,
ArXiv,"Learning to Plan, Planning to Learn: Adaptive Hierarchical RL-MPC for Sample-Efficient Decision Making",https://arxiv.org/abs/2512.17091,
ArXiv,Reinforcement Learning for Self-Improving Agent with Skill Library,https://arxiv.org/abs/2512.17102,
ArXiv,Cooperative Energy Scheduling of Multi-Microgrids Based on Risk-Sensitive Reinforcement Learning,https://arxiv.org/abs/2512.17246,
ArXiv,Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2512.17444,
ArXiv,About Time: Model-free Reinforcement Learning with Timed Reward Machines,https://arxiv.org/abs/2512.17637,
ArXiv,NeuRehab: A Reinforcement Learning and Spiking Neural Network-Based Rehab Automation Framework,https://arxiv.org/abs/2512.17841,
ArXiv,HydroGym: A Reinforcement Learning Platform for Fluid Dynamics,https://arxiv.org/abs/2512.17534,
ArXiv,Enhancing Blind Face Restoration through Online Reinforcement Learning,https://arxiv.org/abs/2509.23339,
ArXiv,Deep Reinforcement Learning-Aided Strategies for Big Data Offloading in Vehicular Networks,https://arxiv.org/abs/2512.17133,
