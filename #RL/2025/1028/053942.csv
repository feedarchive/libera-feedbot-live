feed,title,long_url,short_url
ArXiv,Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review,https://arxiv.org/abs/2510.21758,
ArXiv,Computational Hardness of Reinforcement Learning with Partial $q^{\pi}$-Realizability,https://arxiv.org/abs/2510.21888,
ArXiv,Is Temporal Difference Learning the Gold Standard for Stitching in RL?,https://arxiv.org/abs/2510.21995,
ArXiv,Do You Trust the Process?: Modeling Institutional Trust for Community Adoption of Reinforcement Learning Policies,https://arxiv.org/abs/2510.22017,
ArXiv,Online Optimization for Offline Safe Reinforcement Learning,https://arxiv.org/abs/2510.22027,
ArXiv,Agentic Reinforcement Learning for Real-World Code Repair,https://arxiv.org/abs/2510.22075,
ArXiv,EasyUUV: An LLM-Enhanced Universal and Lightweight Sim-to-Real Reinforcement Learning Framework for UUV Attitude Control,https://arxiv.org/abs/2510.22126,
ArXiv,CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models via Reinforcement Learning,https://arxiv.org/abs/2510.22282,
ArXiv,BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles,https://arxiv.org/abs/2510.22370,
ArXiv,Transitive RL: Value Learning via Divide and Conquer,https://arxiv.org/abs/2510.22512,
ArXiv,Ant-inspired Walling Strategies for Scalable Swarm Separation: Reinforcement Learning Approaches Based on Finite State Machines,https://arxiv.org/abs/2510.22524,
ArXiv,FlowCritic: Bridging Value Estimation with Flow Matching in Reinforcement Learning,https://arxiv.org/abs/2510.22686,
ArXiv,RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets,https://arxiv.org/abs/2510.22699,
ArXiv,ATLAS: Actor-Critic Task-Completion with Look-ahead Action Simulation,https://arxiv.org/abs/2510.22732,
ArXiv,Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM,https://arxiv.org/abs/2510.22740,
ArXiv,HRM-Agent: Training a recurrent reasoning model in dynamic environments using reinforcement learning,https://arxiv.org/abs/2510.22832,
ArXiv,Lyapunov Function-guided Reinforcement Learning for Flight Control,https://arxiv.org/abs/2510.22840,
ArXiv,Guardian: Decoupling Exploration from Safety in Reinforcement Learning,https://arxiv.org/abs/2510.22859,
ArXiv,RL-AUX: Reinforcement Learning for Auxiliary Task Generation,https://arxiv.org/abs/2510.22940,
ArXiv,Towards Stable and Effective Reinforcement Learning for Mixture-of-Experts,https://arxiv.org/abs/2510.23027,
ArXiv,Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated Reinforcement Learning,https://arxiv.org/abs/2510.23038,
ArXiv,AirFed: Federated Graph-Enhanced Multi-Agent Reinforcement Learning for Multi-UAV Cooperative Mobile Edge Computing,https://arxiv.org/abs/2510.23053,
ArXiv,Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach,https://arxiv.org/abs/2510.23216,
ArXiv,CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach,https://arxiv.org/abs/2510.23304,
ArXiv,Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon,https://arxiv.org/abs/2510.23329,
ArXiv,The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N Sampling via max@k Optimisation,https://arxiv.org/abs/2510.23393,
ArXiv,VideoTG-R1: Boosting Video Temporal Grounding via Curriculum Reinforcement Learning on Reflected Boundary Annotations,https://arxiv.org/abs/2510.23397,
ArXiv,An Information-Theoretic Analysis of Out-of-Distribution Generalization in Meta-Learning with Applications to Meta-RL,https://arxiv.org/abs/2510.23448,
ArXiv,"Video-Thinker: Sparking ""Thinking with Videos"" via Reinforcement Learning",https://arxiv.org/abs/2510.23473,
ArXiv,Learning to Reason Efficiently with Discounted Reinforcement Learning,https://arxiv.org/abs/2510.23486,
ArXiv,Reinforcement learning-guided optimization of critical current in high-temperature superconductors,https://arxiv.org/abs/2510.22424,
ArXiv,Learnable Behavior Control: Breaking Atari Human World Records via Sample-Efficient Behavior Selection,https://arxiv.org/abs/2305.05239,
ArXiv,"First SFT, Second RL, Third UPT: Continual Improving Multi-Modal LLM Reasoning via Unsupervised Post-Training",https://arxiv.org/abs/2505.22453,
