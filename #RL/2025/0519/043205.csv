feed,title,long_url,short_url
ArXiv,Deep Symbolic Optimization: Reinforcement Learning for Symbolic Mathematics,https://arxiv.org/abs/2505.10762,
ArXiv,Developing and Integrating Trust Modeling into Multi-Objective Reinforcement Learning for Intelligent Agricultural Management,https://arxiv.org/abs/2505.10803,
ArXiv,Enhancing Secrecy Energy Efficiency in RIS-Aided Aerial Mobile Edge Computing Networks: A Deep Reinforcement Learning Approach,https://arxiv.org/abs/2505.10815,
ArXiv,Learning When to Think: Shaping Adaptive Reasoning in R1-Style Models via Multi-Stage RL,https://arxiv.org/abs/2505.10832,
ArXiv,Improving the Data-efficiency of Reinforcement Learning by Warm-starting with LLM,https://arxiv.org/abs/2505.10861,
ArXiv,Prior-Guided Diffusion Planning for Offline Reinforcement Learning,https://arxiv.org/abs/2505.10881,
ArXiv,Certifying Stability of Reinforcement Learning Policies using Generalized Lyapunov Functions,https://arxiv.org/abs/2505.10947,
ArXiv,DRL-Based Injection Molding Process Parameter Optimization for Adaptive and Profitable Production,https://arxiv.org/abs/2505.10988,
ArXiv,ReaCritic: Large Reasoning Transformer-based DRL Critic-model Scaling For Heterogeneous Networks,https://arxiv.org/abs/2505.10992,
ArXiv,Lifelong reinforcement learning for health-aware fast charging of lithium-ion batteries,https://arxiv.org/abs/2505.11061,
ArXiv,Scalability of Reinforcement Learning Methods for Dispatching in Semiconductor Frontend Fabs: A Comparison of Open-Source Models with Real Industry Datasets,https://arxiv.org/abs/2505.11135,
ArXiv,Reinforcement Learning for AMR Charging Decisions: The Impact of Reward and Action Space Design,https://arxiv.org/abs/2505.11136,
ArXiv,Parkour in the Wild: Learning a General and Extensible Agile Locomotion Policy Using Multi-expert Distillation and RL Fine-tuning,https://arxiv.org/abs/2505.11164,
ArXiv,GLOVA: Global and Local Variation-Aware Analog Circuit Design with Risk-Sensitive Reinforcement Learning,https://arxiv.org/abs/2505.11208,
ArXiv,Sample Efficient Reinforcement Learning via Large Vision Language Model Distillation,https://arxiv.org/abs/2505.11221,
ArXiv,Is PRM Necessary? Problem-Solving RL Implicitly Induces PRM Capability in LLMs,https://arxiv.org/abs/2505.11227,
ArXiv,"Meta-World+: An Improved, Standardized, RL Benchmark",https://arxiv.org/abs/2505.11289,
ArXiv,Reinforcement Learning Closures for Underresolved Partial Differential Equations using Synthetic Data,https://arxiv.org/abs/2505.11308,
ArXiv,Explaining Strategic Decisions in Multi-Agent Reinforcement Learning for Aerial Combat Tactics,https://arxiv.org/abs/2505.11311,
ArXiv,Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner,https://arxiv.org/abs/2505.11404,
ArXiv,Signal attenuation enables scalable decentralized multi-agent reinforcement learning over networks,https://arxiv.org/abs/2505.11461,
ArXiv,Improving Assembly Code Performance with Large Language Models via Reinforcement Learning,https://arxiv.org/abs/2505.11480,
