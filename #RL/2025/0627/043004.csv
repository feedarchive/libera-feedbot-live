feed,title,long_url,short_url
ArXiv,Multi-Objective Reinforcement Learning for Cognitive Radar Resource Management,https://arxiv.org/abs/2506.20853,
ArXiv,Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance,https://arxiv.org/abs/2506.20883,
ArXiv,Optimal Single-Policy Sample Complexity and Transient Coverage for Average-Reward Offline RL,https://arxiv.org/abs/2506.20904,
ArXiv,Explainable AI for Radar Resource Management: Modified LIME in Deep Reinforcement Learning,https://arxiv.org/abs/2506.20916,
ArXiv,RL-Selector: Reinforcement Learning-Guided Data Selection via Redundancy Assessment,https://arxiv.org/abs/2506.21037,
ArXiv,Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical Reinforcement Learning,https://arxiv.org/abs/2506.21039,
ArXiv,GoIRL: Graph-Oriented Inverse Reinforcement Learning for Multimodal Trajectory Prediction,https://arxiv.org/abs/2506.21121,
ArXiv,Robust Policy Switching for Antifragile Reinforcement Learning for UAV Deconfliction in Adversarial Environments,https://arxiv.org/abs/2506.21127,
ArXiv,Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV Deconfliction under Observation-Space Attacks,https://arxiv.org/abs/2506.21129,
ArXiv,Diverse Mini-Batch Selection in Reinforcement Learning for Efficient Chemical Exploration in de novo Drug Design,https://arxiv.org/abs/2506.21158,
ArXiv,Bridging Offline and Online Reinforcement Learning for LLMs,https://arxiv.org/abs/2506.21495,
ArXiv,Quantum Reinforcement Learning Trading Agent for Sector Rotation in the Taiwan Stock Market,https://arxiv.org/abs/2506.20930,
ArXiv,Continual Learning as Computationally Constrained Reinforcement Learning,https://arxiv.org/abs/2307.04345,
