feed,title,long_url,short_url
ArXiv,Reinforcement Learning of Flexible Policies for Symbolic Instructions with Adjustable Mapping Specifications,https://arxiv.org/abs/2501.18848,
ArXiv,RLS3: RL-Based Synthetic Sample Selection to Enhance Spatial Reasoning in Vision-Language Models for Indoor Autonomous Perception,https://arxiv.org/abs/2501.18880,
ArXiv,Towards Physiologically Sensible Predictions via the Rule-based Reinforcement Learning Layer,https://arxiv.org/abs/2501.19055,
ArXiv,Optimizing Job Allocation using Reinforcement Learning with Graph Neural Networks,https://arxiv.org/abs/2501.19063,
ArXiv,Reinforcement Learning on Reconfigurable Hardware: Overcoming Material Variability in Laser Material Processing,https://arxiv.org/abs/2501.19102,
ArXiv,A Theoretical Justification for Asymmetric Actor-Critic Algorithms,https://arxiv.org/abs/2501.19116,
ArXiv,Shaping Sparse Rewards in Reinforcement Learning: A Semi-supervised Approach,https://arxiv.org/abs/2501.19128,
ArXiv,Decorrelated Soft Actor-Critic for Efficient Deep Reinforcement Learning,https://arxiv.org/abs/2501.19133,
ArXiv,SHARPIE: A Modular Framework for Reinforcement Learning and Human-AI Interaction Experiments,https://arxiv.org/abs/2501.19245,
ArXiv,Objective Metrics for Human-Subjects Evaluation in Explainable Reinforcement Learning,https://arxiv.org/abs/2501.19256,
ArXiv,Vintix: Action Model via In-Context Reinforcement Learning,https://arxiv.org/abs/2501.19400,
