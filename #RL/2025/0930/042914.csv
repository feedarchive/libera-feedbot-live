feed,title,long_url,short_url
ArXiv,Beyond English-Centric Training: How Reinforcement Learning Improves Cross-Lingual Reasoning in LLMs,https://arxiv.org/abs/2509.23657,
ArXiv,Bridging Discrete and Continuous RL: Stable Deterministic Policy Gradient with Martingale Characterization,https://arxiv.org/abs/2509.23711,
ArXiv,Poivre: Self-Refining Visual Pointing with Reinforcement Learning,https://arxiv.org/abs/2509.23746,
ArXiv,An Investigation of Batch Normalization in Off-Policy Actor-Critic Algorithms,https://arxiv.org/abs/2509.23750,
ArXiv,Knowledge-Level Consistency Reinforcement Learning: Dual-Fact Alignment for Long-Form Factuality,https://arxiv.org/abs/2509.23765,
ArXiv,CaRe-BN: Precise Moving Statistics for Stabilizing Spiking Neural Networks in Reinforcement Learning,https://arxiv.org/abs/2509.23791,
ArXiv,STAIR: Addressing Stage Misalignment through Temporal-Aligned Preference Reinforcement Learning,https://arxiv.org/abs/2509.23802,
ArXiv,Adversarial Diffusion for Robust Reinforcement Learning,https://arxiv.org/abs/2509.23846,
ArXiv,SPELL: Self-Play Reinforcement Learning for evolving Long-Context Language Models,https://arxiv.org/abs/2509.23863,
ArXiv,Efficient Multi-turn RL for GUI Agents via Decoupled Training and Adaptive Data Curation,https://arxiv.org/abs/2509.23866,
ArXiv,Rethinking Reward Miscalibration of GRPO in Agentic RL,https://arxiv.org/abs/2509.23870,
ArXiv,Integrated Communication and Control for Energy-Efficient UAV Swarms: A Multi-Agent Reinforcement Learning Approach,https://arxiv.org/abs/2509.23905,
ArXiv,EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling,https://arxiv.org/abs/2509.23909,
ArXiv,Taming Masked Diffusion Language Models via Consistency Trajectory Reinforcement Learning with Fewer Decoding Step,https://arxiv.org/abs/2509.23924,
ArXiv,Reinforcement Learning with Inverse Rewards for World Model Post-training,https://arxiv.org/abs/2509.23958,
ArXiv,Conditional Advantage Estimation for Reinforcement Learning in Large Reasoning Models,https://arxiv.org/abs/2509.23962,
ArXiv,Curriculum-Guided Reinforcement Learning for Synthesizing Gas-Efficient Financial Derivatives Contracts,https://arxiv.org/abs/2509.23976,
ArXiv,FrameMind: Frame-Interleaved Chain-of-Thought for Video Reasoning via Reinforcement Learning,https://arxiv.org/abs/2509.24008,
ArXiv,Optimism as Risk-Seeking in Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2509.24047,
ArXiv,Collaborative Device-Cloud LLM Inference through Reinforcement Learning,https://arxiv.org/abs/2509.24050,
ArXiv,In-Context Compositional Q-Learning for Offline Reinforcement Learning,https://arxiv.org/abs/2509.24067,
ArXiv,Multi-Agent Guided Policy Search for Non-Cooperative Dynamic Games,https://arxiv.org/abs/2509.24226,
ArXiv,Risk-Sensitive RL for Alleviating Exploration Dilemmas in Large Language Models,https://arxiv.org/abs/2509.24261,
ArXiv,Adversarial Reinforcement Learning Framework for ESP Cheater Simulation,https://arxiv.org/abs/2509.24274,
ArXiv,Asynchronous Policy Gradient Aggregation for Efficient Distributed Reinforcement Learning,https://arxiv.org/abs/2509.24305,
ArXiv,Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning,https://arxiv.org/abs/2509.24313,
ArXiv,Evolution Strategies at Scale: LLM Fine-Tuning Beyond Reinforcement Learning,https://arxiv.org/abs/2509.24372,
ArXiv,Unlocking the Potential of Soft Actor-Critic for Imitation Learning,https://arxiv.org/abs/2509.24539,
ArXiv,Deep Reinforcement Learning in Action: Real-Time Control of Vortex-Induced Vibrations,https://arxiv.org/abs/2509.24556,
ArXiv,Discrete Variational Autoencoding via Policy Search,https://arxiv.org/abs/2509.24716,
ArXiv,Robust Policy Expansion for Offline-to-Online RL under Diverse Data Corruption,https://arxiv.org/abs/2509.24748,
ArXiv,JuggleRL: Mastering Ball Juggling with a Quadrotor via Deep Reinforcement Learning,https://arxiv.org/abs/2509.24892,
ArXiv,MARLIN: Multi-Agent Reinforcement Learning with Murmuration Intelligence and LLM Guidance for Reservoir Management,https://arxiv.org/abs/2509.25034,
ArXiv,Advantage Weighted Matching: Aligning RL with Pretraining in Diffusion Models,https://arxiv.org/abs/2509.25050,
ArXiv,BRIDGE - Building Reinforcement-Learning Depth-to-Image Data Generation Engine for Monocular Depth Estimation,https://arxiv.org/abs/2509.25077,
ArXiv,HeDA: An Intelligent Agent System for Heatwave Risk Discovery through Automated Knowledge Graph Construction and Multi-layer Risk Propagation Analysis,https://arxiv.org/abs/2509.25112,
ArXiv,From $f(x)$ and $g(x)$ to $f(g(x))$: LLMs Learn New Skills in RL by Composing Old Ones,https://arxiv.org/abs/2509.25123,
ArXiv,The Era of Real-World Human Interaction: RL from User Conversations,https://arxiv.org/abs/2509.25137,
ArXiv,XQC: Well-conditioned Optimization Accelerates Deep Reinforcement Learning,https://arxiv.org/abs/2509.25174,
ArXiv,SIRI: Scaling Iterative Reinforcement Learning with Interleaved Compression,https://arxiv.org/abs/2509.25176,
ArXiv,Intelligent Optimization of Wireless Access Point Deployment for Communication-Based Train Control Systems Using Deep Reinforcement Learning,https://arxiv.org/abs/2509.24819,
ArXiv,BOW: Reinforcement Learning for Bottlenecked Next Word Prediction,https://arxiv.org/abs/2506.13502,
ArXiv,Communication-aware Wide-Area Damping Control using Risk-Constrained Reinforcement Learning,https://arxiv.org/abs/2509.23620,
ArXiv,Continuous-Time Reinforcement Learning for Asset-Liability Management,https://arxiv.org/abs/2509.23280,
ArXiv,AlphaSAGE: Structure-Aware Alpha Mining via GFlowNets for Robust Exploration,https://arxiv.org/abs/2509.25055,
