feed,title,long_url,short_url
ArXiv,DORA: Object Affordance-Guided Reinforcement Learning for Dexterous Robotic Manipulation,https://arxiv.org/abs/2505.14819,
ArXiv,Sample and Computationally Efficient Continuous-Time Reinforcement Learning with General Function Approximation,https://arxiv.org/abs/2505.14821,
ArXiv,Reinforcement Learning from User Feedback,https://arxiv.org/abs/2505.14946,
ArXiv,HAVA: Hybrid Approach to Value-Alignment through Reward Weighing for Reinforcement Learning,https://arxiv.org/abs/2505.15011,
ArXiv,RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning,https://arxiv.org/abs/2505.15034,
ArXiv,RLBenchNet: The Right Network for the Right Reinforcement Learning Task,https://arxiv.org/abs/2505.15040,
ArXiv,DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data,https://arxiv.org/abs/2505.15074,
ArXiv,An Empirical Study on Reinforcement Learning for Reasoning-Search Interleaved LLM Agents,https://arxiv.org/abs/2505.15117,
ArXiv,Global Convergence for Average Reward Constrained MDPs with Primal-Dual Actor Critic Algorithm,https://arxiv.org/abs/2505.15138,
ArXiv,Filtering Learning Histories Enhances In-Context Reinforcement Learning,https://arxiv.org/abs/2505.15143,
ArXiv,AvatarShield: Visual Reinforcement Learning for Human-Centric Video Forgery Detection,https://arxiv.org/abs/2505.15173,
ArXiv,Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems,https://arxiv.org/abs/2505.15201,
ArXiv,GCNT: Graph-Based Transformer Policies for Morphology-Agnostic Reinforcement Learning,https://arxiv.org/abs/2505.15211,
ArXiv,LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models,https://arxiv.org/abs/2505.15293,
ArXiv,Multiple Weaks Win Single Strong: Large Language Models Ensemble Weak Reinforcement Learning Agents into a Supreme One,https://arxiv.org/abs/2505.15306,
ArXiv,Hadamax Encoding: Elevating Performance in Model-Free Atari,https://arxiv.org/abs/2505.15345,
ArXiv,Chain-of-Focus: Adaptive Visual Search and Zooming for Multimodal Reasoning via RL,https://arxiv.org/abs/2505.15436,
ArXiv,ViaRL: Adaptive Temporal Grounding via Visual Iterated Amplification Reinforcement Learning,https://arxiv.org/abs/2505.15447,
ArXiv,A Temporal Difference Method for Stochastic Continuous Dynamics,https://arxiv.org/abs/2505.15544,
ArXiv,From Problem-Solving to Teaching Problem-Solving: Aligning LLMs with Pedagogy using Reinforcement Learning,https://arxiv.org/abs/2505.15607,
ArXiv,Average Reward Reinforcement Learning for Omega-Regular and Mean-Payoff Objectives,https://arxiv.org/abs/2505.15693,
ArXiv,ConvSearch-R1: Enhancing Query Reformulation for Conversational Search with Reasoning via Reinforcement Learning,https://arxiv.org/abs/2505.15776,
ArXiv,VARD: Efficient and Dense Fine-Tuning for Diffusion Models with Value-based RL,https://arxiv.org/abs/2505.15791,
ArXiv,HCRMP: A LLM-Hinted Contextual Reinforcement Learning Framework for Autonomous Driving,https://arxiv.org/abs/2505.15793,
ArXiv,Reverse Engineering Human Preferences with Reinforcement Learning,https://arxiv.org/abs/2505.15795,
