feed,title,long_url,short_url
ArXiv,MobileRL: Online Agentic Reinforcement Learning for Mobile GUI Agents,https://arxiv.org/abs/2509.18119,
ArXiv,NurseSchedRL: Attention-Guided Reinforcement Learning for Nurse-Patient Assignment,https://arxiv.org/abs/2509.18125,
ArXiv,A deep reinforcement learning platform for antibiotic discovery,https://arxiv.org/abs/2509.18153,
ArXiv,Exploiting Tree Structure for Credit Assignment in RL Training of LLMs,https://arxiv.org/abs/2509.18314,
ArXiv,Towards Provable Emergence of In-Context Reinforcement Learning,https://arxiv.org/abs/2509.18389,
ArXiv,Diffusion Policies with Offline and Inverse Reinforcement Learning for Promoting Physical Activity in Older Adults Using Wearable Sensors,https://arxiv.org/abs/2509.18433,
ArXiv,Robotic Skill Diversification via Active Mutation of Reward Functions in Reinforcement Learning During a Liquid Pouring Task,https://arxiv.org/abs/2509.18463,
ArXiv,RL-augmented Adaptive Model Predictive Control for Bipedal Locomotion over Challenging Terrain,https://arxiv.org/abs/2509.18466,
ArXiv,APRIL: Active Partial Rollouts in Reinforcement Learning to tame long-tail generation,https://arxiv.org/abs/2509.18521,
ArXiv,Accelerating Network Slice Placement with Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2509.18545,
ArXiv,Explore the Reinforcement Learning for the LLM based ASR and TTS system,https://arxiv.org/abs/2509.18569,
ArXiv,OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation,https://arxiv.org/abs/2509.18600,
ArXiv,End-to-End Crop Row Navigation via LiDAR-Based Deep Reinforcement Learning,https://arxiv.org/abs/2509.18608,
ArXiv,LLM-Enhanced Self-Evolving Reinforcement Learning for Multi-Step E-Commerce Payment Fraud Risk Detection,https://arxiv.org/abs/2509.18719,
ArXiv,MECap-R1: Emotion-aware Policy with Reinforcement Learning for Multimodal Emotion Captioning,https://arxiv.org/abs/2509.18729,
ArXiv,Tackling GNARLy Problems: Graph Neural Algorithmic Reasoning Reimagined through Reinforcement Learning,https://arxiv.org/abs/2509.18930,
ArXiv,TD3-Sched: Learning to Orchestrate Container-based Cloud-Edge Resources via Distributed Reinforcement Learning,https://arxiv.org/abs/2509.18957,
ArXiv,Central Limit Theorems for Asynchronous Averaged Q-Learning,https://arxiv.org/abs/2509.18964,
ArXiv,Reduced-Order Model-Guided Reinforcement Learning for Demonstration-Free Humanoid Locomotion,https://arxiv.org/abs/2509.19023,
ArXiv,World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation,https://arxiv.org/abs/2509.19080,
ArXiv,PipelineRL: Faster On-policy Reinforcement Learning for Long Sequence Generatio,https://arxiv.org/abs/2509.19128,
ArXiv,Efficient Reinforcement Learning by Reducing Forgetting with Elephant Activation Functions,https://arxiv.org/abs/2509.19159,
ArXiv,Online Process Reward Leanring for Agentic Reinforcement Learning,https://arxiv.org/abs/2509.19199,
ArXiv,Reinforcement Learning on Pre-Training Data,https://arxiv.org/abs/2509.19249,
ArXiv,Residual Off-Policy RL for Finetuning Behavior Cloning Policies,https://arxiv.org/abs/2509.19301,
ArXiv,On the Convergence of Policy Mirror Descent with Temporal Difference Evaluation,https://arxiv.org/abs/2509.18822,
ArXiv,PIGDreamer: Privileged Information Guided World Models for Safe Partially Observable Reinforcement Learning,https://arxiv.org/abs/2508.02159,
ArXiv,Deep Reinforcement Learning for Dynamic Sensing and Communications,https://arxiv.org/abs/2509.19130,
