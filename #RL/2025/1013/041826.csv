feed,title,long_url,short_url
ArXiv,Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting,https://arxiv.org/abs/2510.08696,
ArXiv,Reinforcement Learning-Based Optimization of CT Acquisition and Reconstruction Parameters Through Virtual Imaging Trials,https://arxiv.org/abs/2510.08763,
ArXiv,Zero-Shot Policy Transfer in Reinforcement Learning using Buckingham's Pi Theorem,https://arxiv.org/abs/2510.08768,
ArXiv,Prioritizing Latency with Profit: A DRL-Based Admission Control for 5G Network Slices,https://arxiv.org/abs/2510.08769,
ArXiv,Guiding Exploration in Reinforcement Learning Through LLM-Augmented Observations,https://arxiv.org/abs/2510.08779,
ArXiv,Reinforcement Learning-Driven Edge Management for Reliable Multi-view 3D Reconstruction,https://arxiv.org/abs/2510.08839,
ArXiv,CDE: Concept-Driven Exploration for Reinforcement Learning,https://arxiv.org/abs/2510.08851,
ArXiv,Model-Based Lookahead Reinforcement Learning for in-hand manipulation,https://arxiv.org/abs/2510.08884,
ArXiv,Pinpointing crucial steps: Attribution-based Credit Assignment for Verifiable Reinforcement Learning,https://arxiv.org/abs/2510.08899,
ArXiv,Diagnosing and Mitigating System Bias in Self-Rewarding RL,https://arxiv.org/abs/2510.08977,
ArXiv,HERO: Hardware-Efficient RL-based Optimization Framework for NeRF Quantization,https://arxiv.org/abs/2510.09010,
ArXiv,Slim Scheduler: A Runtime-Aware RL and Scheduler System for Efficient CNN Inference,https://arxiv.org/abs/2510.09018,
ArXiv,Robust Driving Control for Autonomous Vehicles: An Intelligent General-sum Constrained Adversarial Reinforcement Learning Approach,https://arxiv.org/abs/2510.09041,
ArXiv,Agentic-KGR: Co-evolutionary Knowledge Graph Construction through Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2510.09156,
ArXiv,Hierarchical Semantic RL: Tackling the Problem of Dynamic Action Space for RL-based Recommendations,https://arxiv.org/abs/2510.09167,
ArXiv,FM-IRL: Flow-Matching for Reward Modeling and Policy Regularization in Reinforcement Learning,https://arxiv.org/abs/2510.09222,
ArXiv,Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning,https://arxiv.org/abs/2510.09254,
ArXiv,Detecting Data Contamination from Reinforcement Learning Post-training for Large Language Models,https://arxiv.org/abs/2510.09259,
ArXiv,Spotlight on Token Perception for Multimodal Reinforcement Learning,https://arxiv.org/abs/2510.09285,
ArXiv,Application of Deep Reinforcement Learning to At-the-Money S&P 500 Options Hedging,https://arxiv.org/abs/2510.09247,
ArXiv,A Method to Improve the Performance of Reinforcement Learning Based on the Y Operator for a Class of Stochastic Differential Equation-Based Child-Mother Systems,https://arxiv.org/abs/2311.04014,
