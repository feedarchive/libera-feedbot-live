feed,title,long_url,short_url
ArXiv,A critical assessment of reinforcement learning methods for microswimmer navigation in complex flows,https://arxiv.org/abs/2505.05525,
ArXiv,On Corruption-Robustness in Performative Reinforcement Learning,https://arxiv.org/abs/2505.05609,
ArXiv,Physics-informed Temporal Difference Metric Learning for Robot Motion Planning,https://arxiv.org/abs/2505.05691,
ArXiv,Pretraining a Shared Q-Network for Data-Efficient Offline Reinforcement Learning,https://arxiv.org/abs/2505.05701,
ArXiv,Offline Multi-agent Reinforcement Learning via Score Decomposition,https://arxiv.org/abs/2505.05968,
ArXiv,Universal Approximation Theorem for Deep Q-Learning via FBSDE System,https://arxiv.org/abs/2505.06023,
ArXiv,Efficient Information Updates in Compute-First Networking via Reinforcement Learning with Joint AoI and VoI,https://arxiv.org/abs/2505.06025,
ArXiv,TREND: Tri-teaching for Robust Preference-based Reinforcement Learning with Demonstrations,https://arxiv.org/abs/2505.06079,
ArXiv,Interaction-Aware Parameter Privacy-Preserving Data Sharing in Coupled Systems via Particle Filter Reinforcement Learning,https://arxiv.org/abs/2505.06122,
ArXiv,A Large Language Model-Enhanced Q-learning for Capacitated Vehicle Routing Problem with Time Windows,https://arxiv.org/abs/2505.06178,
ArXiv,Multi-User Beamforming with Deep Reinforcement Learning in Sensing-Aided Communication,https://arxiv.org/abs/2505.05956,
