feed,title,long_url,short_url
ArXiv,Financial Decision Making using Reinforcement Learning with Dirichlet Priors and Quantum-Inspired Genetic Optimization,https://arxiv.org/abs/2509.00095,
ArXiv,Know When to Explore: Difficulty-Aware Certainty as a Guide for LLM Reinforcement Learning,https://arxiv.org/abs/2509.00125,
ArXiv,First Order Model-Based RL through Decoupled Backpropagation,https://arxiv.org/abs/2509.00215,
ArXiv,Learning to Shard: RL for Co-optimizing the Parallelism Degrees and Per-operator Sharding Dimensions in Distributed LLM Inference,https://arxiv.org/abs/2509.00217,
ArXiv,LLM-Driven Policy Diffusion: Enhancing Generalization in Offline Reinforcement Learning,https://arxiv.org/abs/2509.00347,
ArXiv,ERank: Fusing Supervised Fine-Tuning and Reinforcement Learning for Effective and Efficient Text Reranking,https://arxiv.org/abs/2509.00520,
ArXiv,Reinforcement Learning of Dolly-In Filming Using a Ground-Based Robot,https://arxiv.org/abs/2509.00564,
ArXiv,Self-Exploring Language Models for Explainable Link Forecasting on Temporal Graphs via Reinforcement Learning,https://arxiv.org/abs/2509.00975,
ArXiv,Reinforcement Learning Driven Generalizable Feature Representation for Cross-User Activity Recognition,https://arxiv.org/abs/2509.01031,
ArXiv,VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use,https://arxiv.org/abs/2509.01055,
ArXiv,Speaking at the Right Level: Literacy-Controlled Counterspeech Generation with RAG-RL,https://arxiv.org/abs/2509.01058,
ArXiv,RealMat: Realistic Materials with Diffusion and Reinforcement Learning,https://arxiv.org/abs/2509.01134,
ArXiv,Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge Networks,https://arxiv.org/abs/2509.01257,
ArXiv,Building surrogate models using trajectories of agents trained by Reinforcement Learning,https://arxiv.org/abs/2509.01285,
ArXiv,Towards High Data Efficiency in Reinforcement Learning with Verifiable Reward,https://arxiv.org/abs/2509.01321,
ArXiv,The Geometry of Nonlinear Reinforcement Learning,https://arxiv.org/abs/2509.01432,
ArXiv,A Hybrid Input based Deep Reinforcement Learning for Lane Change Decision-Making of Autonomous Vehicle,https://arxiv.org/abs/2509.01611,
ArXiv,Reinforcement Learning for Machine Learning Engineering Agents,https://arxiv.org/abs/2509.01684,
ArXiv,Succeed or Learn Slowly: Sample Efficient Off-Policy Reinforcement Learning for Mobile App Control,https://arxiv.org/abs/2509.01720,
ArXiv,Non-conflicting Energy Minimization in Reinforcement Learning based Robot Control,https://arxiv.org/abs/2509.01765,
ArXiv,Goal-Conditioned Reinforcement Learning for Data-Driven Maritime Navigation,https://arxiv.org/abs/2509.01838,
ArXiv,Deep Reinforcement Learning for Real-Time Drone Routing in Post-Disaster Road Assessment Without Domain Knowledge,https://arxiv.org/abs/2509.01886,
ArXiv,SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning,https://arxiv.org/abs/2509.02479,
ArXiv,Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR,https://arxiv.org/abs/2509.02522,
ArXiv,Is RL fine-tuning harder than regression? A PDE learning approach for diffusion models,https://arxiv.org/abs/2509.02528,
ArXiv,UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning,https://arxiv.org/abs/2509.02544,
ArXiv,The Landscape of Agentic Reinforcement Learning for LLMs: A Survey,https://arxiv.org/abs/2509.02547,
ArXiv,"It's-A-Me, Quantum Mario: Scalable Quantum Reinforcement Learning with Multi-Chip Ensembles",https://arxiv.org/abs/2509.00713,
ArXiv,Q-Learning--Driven Adaptive Rewiring for Cooperative Control in Heterogeneous Networks,https://arxiv.org/abs/2509.01057,
ArXiv,"Reinforcement learning for graph theory, Parallelizing Wagner's approach",https://arxiv.org/abs/2509.01607,
ArXiv,Hypothesis Network Planned Exploration for Rapid Meta-Reinforcement Learning Adaptation,https://arxiv.org/abs/2311.03701,
ArXiv,A Flexible Framework for Incorporating Patient Preferences Into Q-Learning,https://arxiv.org/abs/2307.12022,
