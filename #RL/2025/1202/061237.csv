feed,title,long_url,short_url
ArXiv,Perturbation-mitigated USV Navigation with Distributionally Robust Reinforcement Learning,https://arxiv.org/abs/2512.00030,
ArXiv,Causal Reinforcement Learning based Agent-Patient Interaction with Clinical Domain Knowledge,https://arxiv.org/abs/2512.00048,
ArXiv,Socially aware navigation for mobile robots: a survey on deep reinforcement learning approaches,https://arxiv.org/abs/2512.00049,
ArXiv,Reinforcement Learning from Implicit Neural Feedback for Human-Aligned Robot Control,https://arxiv.org/abs/2512.00050,
ArXiv,SpeedAug: Policy Acceleration via Tempo-Enriched Policy and RL Fine-Tuning,https://arxiv.org/abs/2512.00062,
ArXiv,InF-ATPG: Intelligent FFR-Driven ATPG with Advanced Circuit Representation Guided Reinforcement Learning,https://arxiv.org/abs/2512.00079,
ArXiv,NetDeTox: Adversarial and Efficient Evasion of Hardware-Security GNNs via RL-LLM Orchestration,https://arxiv.org/abs/2512.00119,
ArXiv,A Hierarchical Hybrid AI Approach: Integrating Deep Reinforcement Learning and Scripted Agents in Combat Simulations,https://arxiv.org/abs/2512.00249,
ArXiv,Gradient Inversion in Federated Reinforcement Learning,https://arxiv.org/abs/2512.00303,
ArXiv,RL-Struct: A Lightweight Reinforcement Learning Framework for Reliable Structured Output in LLMs,https://arxiv.org/abs/2512.00319,
ArXiv,Echo-N1: Affective RL Frontier,https://arxiv.org/abs/2512.00344,
ArXiv,Provable Memory Efficient Self-Play Algorithm for Model-free Reinforcement Learning,https://arxiv.org/abs/2512.00351,
ArXiv,Sample-Efficient Tabular Self-Play for Offline Robust Reinforcement Learning,https://arxiv.org/abs/2512.00352,
ArXiv,An Empirical Study on the Effectiveness of Incorporating Offline RL As Online RL Subroutines,https://arxiv.org/abs/2512.00383,
ArXiv,Hardware-Software Collaborative Computing of Photonic Spiking Reinforcement Learning for Robotic Continuous Control,https://arxiv.org/abs/2512.00427,
ArXiv,Algorithmic Guarantees for Distilling Supervised and Offline RL Datasets,https://arxiv.org/abs/2512.00536,
ArXiv,DQ4FairIM: Fairness-aware Influence Maximization using Deep Reinforcement Learning,https://arxiv.org/abs/2512.00545,
ArXiv,List Replicable Reinforcement Learning,https://arxiv.org/abs/2512.00553,
ArXiv,Partially Equivariant Reinforcement Learning in Symmetry-Breaking Environments,https://arxiv.org/abs/2512.00915,
ArXiv,Goal-Driven Reward by Video Diffusion Models for Reinforcement Learning,https://arxiv.org/abs/2512.00961,
ArXiv,Optimizing Generative Ranking Relevance via Reinforcement Learning in Xiaohongshu Search,https://arxiv.org/abs/2512.00968,
ArXiv,AltNet: Addressing the Plasticity-Stability Dilemma in Reinforcement Learning,https://arxiv.org/abs/2512.01034,
ArXiv,Shielded Controller Units for RL with Operational Constraints Applied to Remote Microgrids,https://arxiv.org/abs/2512.01046,
ArXiv,Automating the Refinement of Reinforcement Learning Specifications,https://arxiv.org/abs/2512.01047,
ArXiv,Accelerating Inference of Masked Image Generators via Reinforcement Learning,https://arxiv.org/abs/2512.01094,
ArXiv,Real-World Reinforcement Learning of Active Perception Behaviors,https://arxiv.org/abs/2512.01188,
ArXiv,Kardia-R1: Unleashing LLMs to Reason toward Understanding and Empathy for Emotional Support via Rubric-as-Judge Reinforcement Learning,https://arxiv.org/abs/2512.01282,
ArXiv,CuES: A Curiosity-driven and Environment-grounded Synthesis Framework for Agentic RL,https://arxiv.org/abs/2512.01311,
ArXiv,Extending NGU to Multi-Agent RL: A Preliminary Study,https://arxiv.org/abs/2512.01321,
ArXiv,Discovering Self-Protective Falling Policy for Humanoid Robot via Deep Reinforcement Learning,https://arxiv.org/abs/2512.01336,
ArXiv,Stabilizing Reinforcement Learning with LLMs: Formulation and Practices,https://arxiv.org/abs/2512.01374,
ArXiv,Multi-Path Collaborative Reasoning via Reinforcement Learning,https://arxiv.org/abs/2512.01485,
ArXiv,End-to-end Deep Reinforcement Learning for Stochastic Multi-objective Optimization in C-VRPTW,https://arxiv.org/abs/2512.01518,
ArXiv,CLIP-RL: Aligning Language and Policy Representations for Task Transfer in Reinforcement Learning,https://arxiv.org/abs/2512.01616,
ArXiv,How Does RL Post-training Induce Skill Composition? A Case Study on Countdown,https://arxiv.org/abs/2512.01775,
ArXiv,GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation,https://arxiv.org/abs/2512.01801,
ArXiv,Beyond SFT: Reinforcement Learning for Safer Large Reasoning Models with Better Reasoning Ability,https://arxiv.org/abs/2512.01848,
ArXiv,From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning,https://arxiv.org/abs/2512.01970,
ArXiv,Forecasting in Offline Reinforcement Learning for Non-stationary Environments,https://arxiv.org/abs/2512.01987,
ArXiv,A Diffusion Model Framework for Maximum Entropy Reinforcement Learning,https://arxiv.org/abs/2512.02019,
ArXiv,Optimizing Information Asset Investment Strategies in the Exploratory Phase of the Oil and Gas Industry: A Reinforcement Learning Approach,https://arxiv.org/abs/2512.00243,
ArXiv,Formal Verification of Noisy Quantum Reinforcement Learning Policies,https://arxiv.org/abs/2512.01502,
ArXiv,Arbitrary Entropy Policy Optimization Breaks The Exploration Bottleneck of Reinforcement Learning,https://arxiv.org/abs/2510.08141,
