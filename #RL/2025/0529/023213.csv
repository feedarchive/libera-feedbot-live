feed,title,long_url,short_url
ArXiv,Language Model Distillation: A Temporal Difference Imitation Learning Perspective,https://arxiv.org/abs/2505.20335,
ArXiv,SeRL: Self-Play Reinforcement Learning for Large Language Models with Limited Data,https://arxiv.org/abs/2505.20347,
ArXiv,The challenge of hidden gifts in multi-agent reinforcement learning,https://arxiv.org/abs/2505.20579,
ArXiv,Gait-Conditioned Reinforcement Learning with Multi-Phase Curriculum for Humanoid Locomotion,https://arxiv.org/abs/2505.20619,
ArXiv,Multi-level Certified Defense Against Poisoning Attacks in Offline Reinforcement Learning,https://arxiv.org/abs/2505.20621,
ArXiv,LLM-Guided Reinforcement Learning: Addressing Training Bottlenecks through Policy Modulation,https://arxiv.org/abs/2505.20671,
ArXiv,Accelerating RL for LLM Reasoning with Optimal Advantage Regression,https://arxiv.org/abs/2505.20686,
ArXiv,SPA-RL: Reinforcing LLM Agents via Stepwise Progress Attribution,https://arxiv.org/abs/2505.20732,
ArXiv,Interactive OT Gym: A Reinforcement Learning-Based Interactive Optical tweezer (OT)-Driven Microrobotics Simulation Platform,https://arxiv.org/abs/2505.20751,
ArXiv,TACO: Think-Answer Consistency for Optimized Long-Chain Reasoning and Efficient Data Learning via Reinforcement Learning in LVLMs,https://arxiv.org/abs/2505.20777,
ArXiv,Rendering-Aware Reinforcement Learning for Vector Graphics Generation,https://arxiv.org/abs/2505.20793,
ArXiv,Reinforcement Learning-based Sequential Route Recommendation for System-Optimal Traffic Assignment,https://arxiv.org/abs/2505.20889,
ArXiv,Large Language Model-enhanced Reinforcement Learning for Low-Altitude Economy Networking,https://arxiv.org/abs/2505.21045,
ArXiv,Why Distillation can Outperform Zero-RL: The Role of Flexible Reasoning,https://arxiv.org/abs/2505.21067,
ArXiv,TAT-R1: Terminology-Aware Translation with Reinforcement Learning and Word Alignment,https://arxiv.org/abs/2505.21172,
ArXiv,Walk Before You Run! Concise LLM Reasoning via Reinforcement Learning,https://arxiv.org/abs/2505.21178,
ArXiv,Breaking the Performance Ceiling in Complex Reinforcement Learning requires Inference Strategies,https://arxiv.org/abs/2505.21236,
