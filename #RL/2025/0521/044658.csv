feed,title,long_url,short_url
ArXiv,An agentic system with reinforcement-learned subsystem improvements for parsing form-like documents,https://arxiv.org/abs/2505.13504,
ArXiv,Distributional Soft Actor-Critic with Harmonic Gradient for Safe and Efficient Autonomous Driving in Multi-lane Scenarios,https://arxiv.org/abs/2505.13532,
ArXiv,Origin-Destination Pattern Effects on Large-Scale Mixed Traffic Control via Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2505.13543,
ArXiv,TD-GRPC: Temporal Difference Learning with Group Relative Policy Constraint for Humanoid Locomotion,https://arxiv.org/abs/2505.13549,
ArXiv,4Hammer: a board-game reinforcement learning environment for the hour long time frame,https://arxiv.org/abs/2505.13638,
ArXiv,RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs,https://arxiv.org/abs/2505.13697,
ArXiv,Policy-Driven World Model Adaptation for Robust Offline Model-based Reinforcement Learning,https://arxiv.org/abs/2505.13709,
ArXiv,Benchmarking MOEAs for solving continuous multi-objective RL problems,https://arxiv.org/abs/2505.13726,
ArXiv,Augmenting Online RL with Offline Data is All You Need: A Unified Hybrid RL Algorithm Design and Analysis,https://arxiv.org/abs/2505.13768,
ArXiv,Time Reversal Symmetry for Efficient Robotic Manipulations in Deep Reinforcement Learning,https://arxiv.org/abs/2505.13925,
ArXiv,RLVR-World: Training World Models with Reinforcement Learning,https://arxiv.org/abs/2505.13934,
ArXiv,Toward Effective Reinforcement Learning Fine-Tuning for Medical VQA in Vision-Language Models,https://arxiv.org/abs/2505.13973,
ArXiv,Process vs. Outcome Reward: Which is Better for Agentic RAG Reinforcement Learning,https://arxiv.org/abs/2505.14069,
ArXiv,FlowQ: Energy-Guided Flow Policies for Offline Reinforcement Learning,https://arxiv.org/abs/2505.14139,
ArXiv,RL of Thoughts: Navigating LLM Reasoning with Inference-time Reinforcement Learning,https://arxiv.org/abs/2505.14140,
ArXiv,s3: You Don't Need That Much Data to Train a Search Agent via RL,https://arxiv.org/abs/2505.14146,
ArXiv,SHARP: Synthesizing High-quality Aligned Reasoning Problems for Large Reasoning Models Reinforcement Learning,https://arxiv.org/abs/2505.14147,
ArXiv,Embedded Mean Field Reinforcement Learning for Perimeter-defense Game,https://arxiv.org/abs/2505.14209,
ArXiv,Reinforcement Learning vs. Distillation: Understanding Accuracy and Capability in LLM Reasoning,https://arxiv.org/abs/2505.14216,
ArXiv,UniVG-R1: Reasoning Guided Universal Visual Grounding with Reinforcement Learning,https://arxiv.org/abs/2505.14231,
ArXiv,"DeepEyes: Incentivizing ""Thinking with Images"" via Reinforcement Learning",https://arxiv.org/abs/2505.14362,
ArXiv,PRL: Prompts from Reinforcement Learning,https://arxiv.org/abs/2505.14412,
ArXiv,Semantically-driven Deep Reinforcement Learning for Inspection Path Planning,https://arxiv.org/abs/2505.14443,
ArXiv,Interpretable Reinforcement Learning for Load Balancing using Kolmogorov-Arnold Networks,https://arxiv.org/abs/2505.14459,
ArXiv,VisualQuality-R1: Reasoning-Induced Image Quality Assessment via Reinforcement Learning to Rank,https://arxiv.org/abs/2505.14460,
ArXiv,Personalised Insulin Adjustment with Reinforcement Learning: An In-Silico Validation for People with Diabetes on Intensive Insulin Treatment,https://arxiv.org/abs/2505.14477,
ArXiv,NavBench: A Unified Robotics Benchmark for Reinforcement Learning-Based Autonomous Navigation,https://arxiv.org/abs/2505.14526,
ArXiv,Energy-Efficient Deep Reinforcement Learning with Spiking Transformers,https://arxiv.org/abs/2505.14533,
ArXiv,Multi-agent Reinforcement Learning vs. Fixed-Time Control for Traffic Signal Optimization: A Simulation Study,https://arxiv.org/abs/2505.14544,
ArXiv,Bellman operator convergence enhancements in reinforcement learning algorithms,https://arxiv.org/abs/2505.14564,
ArXiv,Context Reasoner: Incentivizing Reasoning Capability for Contextualized Privacy and Safety Compliance via Reinforcement Learning,https://arxiv.org/abs/2505.14585,
ArXiv,TinyV: Reducing False Negatives in Verification Improves RL for LLM Reasoning,https://arxiv.org/abs/2505.14625,
ArXiv,Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning,https://arxiv.org/abs/2505.14677,
ArXiv,Performance Optimization of Energy-Harvesting Underlay Cognitive Radio Networks Using Reinforcement Learning,https://arxiv.org/abs/2505.14581,
