feed,title,long_url,short_url
ArXiv,DRL-Based Resource Allocation for Energy-Efficient IRS-Assisted UAV Spectrum Sharing Systems,https://arxiv.org/abs/2510.17877,
ArXiv,"Rewarding the Journey, Not Just the Destination: A Composite Path and Answer Self-Scoring Reward Mechanism for Test-Time Reinforcement Learning",https://arxiv.org/abs/2510.17923,
ArXiv,UniRL-Zero: Reinforcement Learning on Unified Models with Joint Language Model and Diffusion Model Experts,https://arxiv.org/abs/2510.17937,
ArXiv,OPTAGENT: Optimizing Multi-Agent LLM Interactions Through Verbal Reinforcement Learning for Enhanced Reasoning,https://arxiv.org/abs/2510.18032,
ArXiv,R2L: Reliable Reinforcement Learning: Guaranteed Return & Reliable Policies in Reinforcement Learning,https://arxiv.org/abs/2510.18074,
ArXiv,Provably Optimal Reinforcement Learning under Safety Filtering,https://arxiv.org/abs/2510.18082,
ArXiv,RL-Driven Security-Aware Resource Allocation Framework for UAV-Assisted O-RAN,https://arxiv.org/abs/2510.18084,
ArXiv,ACTG-ARL: Differentially Private Conditional Text Generation with RL-Boosted Control,https://arxiv.org/abs/2510.18232,
ArXiv,From Competition to Synergy: Unlocking Reinforcement Learning for Subject-Driven Image Generation,https://arxiv.org/abs/2510.18263,
ArXiv,MENTOR: A Reinforcement Learning Framework for Model Enhancement via Teacher-Optimized Rewards in Small Models,https://arxiv.org/abs/2510.18383,
ArXiv,AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library,https://arxiv.org/abs/2510.18428,
ArXiv,Learning to Navigate Under Imperfect Perception: Conformalised Segmentation for Safe Reinforcement Learning,https://arxiv.org/abs/2510.18485,
ArXiv,Efficient Model-Based Reinforcement Learning for Robot Control via Online Learning,https://arxiv.org/abs/2510.18518,
ArXiv,Deep Q-Learning Assisted Bandwidth Reservation for Multi-Operator Time-Sensitive Vehicular Networking,https://arxiv.org/abs/2510.18553,
ArXiv,Reinforcement Learning with Imperfect Transition Predictions: A Bellman-Jensen Approach,https://arxiv.org/abs/2510.18687,
ArXiv,Preference-based Reinforcement Learning beyond Pairwise Comparisons: Benefits of Multiple Options,https://arxiv.org/abs/2510.18713,
ArXiv,Verifiable Accuracy and Abstention Rewards in Curriculum RL to Alleviate Lost-in-Conversation,https://arxiv.org/abs/2510.18731,
ArXiv,WebSeer: Training Deeper Search Agents through Reinforcement Learning with Self-Reflection,https://arxiv.org/abs/2510.18798,
ArXiv,Towards Faithful and Controllable Personalization via Critique-Post-Edit Reinforcement Learning,https://arxiv.org/abs/2510.18849,
ArXiv,Every Step Evolves: Scaling Reinforcement Learning for Trillion-Scale Thinking Model,https://arxiv.org/abs/2510.18855,
ArXiv,EffiReasonTrans: RL-Optimized Reasoning for Code Translation,https://arxiv.org/abs/2510.18863,
ArXiv,Lyapunov-Aware Quantum-Inspired Reinforcement Learning for Continuous-Time Vehicle Control: A Feasibility Study,https://arxiv.org/abs/2510.18852,
