feed,title,long_url,short_url
ArXiv,SFT or RL? An Early Investigation into Training R1-Like Reasoning Large Vision-Language Models,https://arxiv.org/abs/2504.11468,
ArXiv,Cross-cultural Deployment of Autonomous Vehicles Using Data-light Inverse Reinforcement Learning,https://arxiv.org/abs/2504.11506,
ArXiv,Position Paper: Rethinking Privacy in RL for Sequential Decision-making in the Age of LLMs,https://arxiv.org/abs/2504.11511,
ArXiv,ReTool: Reinforcement Learning for Strategic Tool Use in LLMs,https://arxiv.org/abs/2504.11536,
ArXiv,Dueling Deep Reinforcement Learning for Financial Time Series,https://arxiv.org/abs/2504.11601,
ArXiv,A Graph-Based Reinforcement Learning Approach with Frontier Potential Based Reward for Safe Cluttered Environment Exploration,https://arxiv.org/abs/2504.11907,
ArXiv,VIPO: Value Function Inconsistency Penalized Offline Reinforcement Learning,https://arxiv.org/abs/2504.11944,
ArXiv,R-Meshfusion: Reinforcement Learning Powered Sparse-View Mesh Reconstruction with Diffusion Priors,https://arxiv.org/abs/2504.11946,
ArXiv,Evolutionary Reinforcement Learning for Interpretable Decision-Making in Supply Chain Management,https://arxiv.org/abs/2504.12023,
ArXiv,d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning,https://arxiv.org/abs/2504.12216,
ArXiv,Control of Rayleigh-B\'enard Convection: Effectiveness of Reinforcement Learning in the Turbulent Regime,https://arxiv.org/abs/2504.12000,
ArXiv,H2O+: An Improved Framework for Hybrid Offline-and-Online RL with Dynamics Gaps,https://arxiv.org/abs/2309.12716,
