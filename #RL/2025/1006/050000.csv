feed,title,long_url,short_url
ArXiv,From Pixels to Factors: Learning Independently Controllable State Variables for Reinforcement Learning,https://arxiv.org/abs/2510.02484,
ArXiv,Improved Robustness of Deep Reinforcement Learning for Control of Time-Varying Systems by Bounded Extremum Seeking,https://arxiv.org/abs/2510.02490,
ArXiv,Oracle-RLAIF: An Improved Fine-Tuning Framework for Multi-modal Video Models through Reinforcement Learning from Ranking Feedback,https://arxiv.org/abs/2510.02561,
ArXiv,A Benchmark Study of Deep Reinforcement Learning Algorithms for the Container Stowage Planning Problem,https://arxiv.org/abs/2510.02589,
ArXiv,Use the Online Network If You Can: Towards Fast and Stable Reinforcement Learning,https://arxiv.org/abs/2510.02590,
ArXiv,Smart-GRPO: Smartly Sampling Noise for Efficient RL of Flow-Matching Models,https://arxiv.org/abs/2510.02654,
ArXiv,RAMAC: Multimodal Risk-Aware Offline Reinforcement Learning and the Role of Behavior Regularization,https://arxiv.org/abs/2510.02695,
ArXiv,A Control-Barrier-Function-Based Algorithm for Policy Adaptation in Reinforcement Learning,https://arxiv.org/abs/2510.02720,
ArXiv,Consolidating Reinforcement Learning for Multimodal Discrete Diffusion Models,https://arxiv.org/abs/2510.02880,
ArXiv,"RoiRL: Efficient, Self-Supervised Reasoning with Offline Iterative Reinforcement Learning",https://arxiv.org/abs/2510.02892,
ArXiv,Ergodic Risk Measures: Towards a Risk-Aware Foundation for Continual Reinforcement Learning,https://arxiv.org/abs/2510.02945,
ArXiv,Distributional Inverse Reinforcement Learning,https://arxiv.org/abs/2510.03013,
ArXiv,Comparative Analysis of Parameterized Action Actor-Critic Reinforcement Learning Algorithms for Web Search Match Plan Generation,https://arxiv.org/abs/2510.03064,
ArXiv,A Unified Deep Reinforcement Learning Approach for Close Enough Traveling Salesman Problem,https://arxiv.org/abs/2510.03065,
ArXiv,Q-Learning with Shift-Aware Upper Confidence Bound in Non-Stationary Reinforcement Learning,https://arxiv.org/abs/2510.03181,
ArXiv,To Distill or Decide? Understanding the Algorithmic Trade-off in Partially Observable Reinforcement Learning,https://arxiv.org/abs/2510.03207,
ArXiv,Low-probability Tokens Sustain Exploration in Reinforcement Learning with Verifiable Reward,https://arxiv.org/abs/2510.03222,
ArXiv,A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation,https://arxiv.org/abs/2311.15238,
