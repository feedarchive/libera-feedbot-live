feed,title,long_url,short_url
ArXiv,Meta Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN,https://arxiv.org/abs/2512.13715,
ArXiv,Time-Constrained Recommendations: Reinforcement Learning Strategies for E-Commerce,https://arxiv.org/abs/2512.13726,
ArXiv,RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing,https://arxiv.org/abs/2512.13727,
ArXiv,Explainable reinforcement learning from human feedback to improve alignment,https://arxiv.org/abs/2512.13837,
ArXiv,SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning,https://arxiv.org/abs/2512.13874,
ArXiv,Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model,https://arxiv.org/abs/2512.14031,
ArXiv,Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning,https://arxiv.org/abs/2512.14057,
ArXiv,RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees,https://arxiv.org/abs/2512.14069,
ArXiv,Understanding and Improving Hyperbolic Deep Reinforcement Learning,https://arxiv.org/abs/2512.14202,
ArXiv,Context-Picker: Dynamic context selection using multi-stage reinforcement learning,https://arxiv.org/abs/2512.14465,
ArXiv,Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes,https://arxiv.org/abs/2512.14617,
ArXiv,Group-Theoretic Reinforcement Learning of Dynamical Decoupling Sequences,https://arxiv.org/abs/2512.13890,
ArXiv,Hierarchical Deep Reinforcement Learning for Robust Access in Cognitive IoT Networks under Smart Jamming Attacks,https://arxiv.org/abs/2512.14013,
ArXiv,Hybrid Cognitive IoT with Cooperative Caching and SWIPT-EH: A Hierarchical Reinforcement Learning Framework,https://arxiv.org/abs/2512.14488,
