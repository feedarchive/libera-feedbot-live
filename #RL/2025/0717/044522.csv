feed,title,long_url,short_url
ArXiv,Reinforcement Learning from Adversarial Preferences in Tabular MDPs,https://arxiv.org/abs/2507.11706,
ArXiv,A Deep Reinforcement Learning Method for Multi-objective Transmission Switching,https://arxiv.org/abs/2507.11726,
ArXiv,"MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory",https://arxiv.org/abs/2507.11821,
ArXiv,DualReward: A Dynamic Reinforcement Learning Framework for Cloze Tests Distractor Generation,https://arxiv.org/abs/2507.11875,
ArXiv,From Generative to Episodic: Sample-Efficient Replicable Reinforcement Learning,https://arxiv.org/abs/2507.11926,
ArXiv,Kevin: Multi-Turn RL for Generating CUDA Kernels,https://arxiv.org/abs/2507.11948,
ArXiv,Online Training and Pruning of Deep Reinforcement Learning Networks,https://arxiv.org/abs/2507.11975,
ArXiv,Towards Ultra-Reliable 6G in-X Subnetworks: Dynamic Link Adaptation by Deep Reinforcement Learning,https://arxiv.org/abs/2507.12031,
ArXiv,Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning,https://arxiv.org/abs/2507.12215,
ArXiv,Improving Reinforcement Learning Sample-Efficiency using Local Approximation,https://arxiv.org/abs/2507.12383,
ArXiv,BenchRL-QAS: Benchmarking reinforcement learning algorithms for quantum architecture search,https://arxiv.org/abs/2507.12189,
