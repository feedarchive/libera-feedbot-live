feed,title,long_url,short_url
ArXiv,Zero-Shot LLMs in Human-in-the-Loop RL: Replacing Human Feedback for Reward Shaping,https://arxiv.org/abs/2503.22723,
ArXiv,Predictive Traffic Rule Compliance using Reinforcement Learning,https://arxiv.org/abs/2503.22925,
ArXiv,Late Breaking Results: Breaking Symmetry- Unconventional Placement of Analog Circuits using Multi-Level Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2503.22958,
ArXiv,Novel Closed Loop Control Mechanism for Zero Touch Networks using BiLSTM and Q-Learning,https://arxiv.org/abs/2503.23000,
ArXiv,RL2Grid: Benchmarking Reinforcement Learning in Power Grid Operations,https://arxiv.org/abs/2503.23101,
ArXiv,Reasoning-SQL: Reinforcement Learning with SQL Tailored Partial Rewards for Reasoning-Enhanced Text-to-SQL,https://arxiv.org/abs/2503.23157,
ArXiv,Efficient Twin Migration in Vehicular Metaverses: Multi-Agent Split Deep Reinforcement Learning with Spatio-Temporal Trajectory Generation,https://arxiv.org/abs/2503.23290,
ArXiv,SalesRLAgent: A Reinforcement Learning Approach for Real-Time Sales Conversion Prediction and Optimization,https://arxiv.org/abs/2503.23303,
ArXiv,ToRL: Scaling Tool-Integrated RL,https://arxiv.org/abs/2503.23383,
ArXiv,Reinforcement Learning-based Token Pruning in Vision Transformers: A Markov Game Approach,https://arxiv.org/abs/2503.23459,
ArXiv,Handling Delay in Real-Time Reinforcement Learning,https://arxiv.org/abs/2503.23478,
ArXiv,An Organizationally-Oriented Approach to Enhancing Explainability and Control in Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2503.23615,
ArXiv,A Constrained Multi-Agent Reinforcement Learning Approach to Autonomous Traffic Signal Control,https://arxiv.org/abs/2503.23626,
ArXiv,A Survey of Reinforcement Learning-Based Motion Planning for Autonomous Driving: Lessons Learned from a Driving Task Perspective,https://arxiv.org/abs/2503.23650,
ArXiv,Dynamic Operating System Scheduling Using Double DQN: A Reinforcement Learning Approach to Task Optimization,https://arxiv.org/abs/2503.23659,
ArXiv,Multi-Agent Deep Reinforcement Learning for Optimized Multi-UAV Coverage and Power-Efficient UE Connectivity,https://arxiv.org/abs/2503.23669,
ArXiv,Accelerating High-Efficiency Organic Photovoltaic Discovery via Pretrained Graph Neural Networks and Generative Reinforcement Learning,https://arxiv.org/abs/2503.23766,
ArXiv,Expanding RL with Verifiable Rewards Across Diverse Domains,https://arxiv.org/abs/2503.23829,
ArXiv,MAER-Nav: Bidirectional Motion Learning Through Mirror-Augmented Experience Replay for Robot Navigation,https://arxiv.org/abs/2503.23908,
ArXiv,A Reactive Framework for Whole-Body Motion Planning of Mobile Manipulators Combining Reinforcement Learning and SDF-Constrained Quadratic Programmi,https://arxiv.org/abs/2503.23975,
ArXiv,A Complete Epistemic Temporal Logic for Intelligent Agent,https://arxiv.org/abs/2503.24078,
ArXiv,Level the Level: Balancing Game Levels for Asymmetric Player Archetypes With Reinforcement Learning,https://arxiv.org/abs/2503.24099,
ArXiv,Reinforcement Learning for Safe Autonomous Two Device Navigation of Cerebral Vessels in Mechanical Thrombectomy,https://arxiv.org/abs/2503.24140,
ArXiv,Ride-Sourcing Vehicle Rebalancing with Service Accessibility Guarantees via Constrained Mean-Field Reinforcement Learning,https://arxiv.org/abs/2503.24183,
ArXiv,Rec-R1: Bridging Generative Large Language Models and User-Centric Recommendation Systems via Reinforcement Learning,https://arxiv.org/abs/2503.24289,
ArXiv,Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement Learning on the Base Model,https://arxiv.org/abs/2503.24290,
ArXiv,Fair Dynamic Spectrum Access via Fully Decentralized Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2503.24296,
ArXiv,Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1,https://arxiv.org/abs/2503.24376,
ArXiv,Reinforcement Learning for Active Matter,https://arxiv.org/abs/2503.23308,
ArXiv,Model Selection for Inverse Reinforcement Learning via Structural Risk Minimization,https://arxiv.org/abs/2312.16566,
ArXiv,DeepLTL: Learning to Efficiently Satisfy Complex LTL Specifications for Multi-Task RL,https://arxiv.org/abs/2410.04631,
