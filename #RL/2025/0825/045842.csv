feed,title,long_url,short_url
ArXiv,Pareto Actor-Critic for Communication and Computation Co-Optimization in Non-Cooperative Federated Learning Services,https://arxiv.org/abs/2508.16037,
ArXiv,Joint Cache Placement and Routing in Satellite-Terrestrial Edge Computing Network: A GNN-Enabled DRL Approach,https://arxiv.org/abs/2508.16184,
ArXiv,Double Check My Desired Return: Transformer with Target Alignment for Offline Reinforcement Learning,https://arxiv.org/abs/2508.16420,
ArXiv,OPERA: A Reinforcement Learning--Enhanced Orchestrated Planner-Executor Architecture for Reasoning-Oriented Multi-Hop Retrieval,https://arxiv.org/abs/2508.16438,
ArXiv,Integrated Noise and Safety Management in UAM via A Unified Reinforcement Learning Framework,https://arxiv.org/abs/2508.16440,
ArXiv,Reinforcement Learning-based Control via Y-wise Affine Neural Networks (YANNs),https://arxiv.org/abs/2508.16474,
ArXiv,On Zero-Shot Reinforcement Learning,https://arxiv.org/abs/2508.16496,
ArXiv,Guiding Diffusion Models with Reinforcement Learning for Stable Molecule Generation,https://arxiv.org/abs/2508.16521,
ArXiv,RL Is Neither a Panacea Nor a Mirage: Understanding Supervised vs. Reinforcement Learning Fine-Tuning for LLMs,https://arxiv.org/abs/2508.16546,
ArXiv,Hierarchical Decision-Making for Autonomous Navigation: Integrating Deep Reinforcement Learning and Fuzzy Logic in Four-Wheel Independent Steering and Driving Systems,https://arxiv.org/abs/2508.16574,
ArXiv,A deep reinforcement learning agent trained for interval timing exhibits similarities to biological systems,https://arxiv.org/abs/2508.15784,
ArXiv,Optimal Dynamic Regret by Transformers for Non-Stationary Reinforcement Learning,https://arxiv.org/abs/2508.16027,
