feed,title,long_url,short_url
ArXiv,Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach,https://arxiv.org/abs/2507.14249,
ArXiv,Deep RL Dual Sourcing Inventory Management with Supply and Capacity Risk Awareness,https://arxiv.org/abs/2507.14446,
ArXiv,Federated Reinforcement Learning in Heterogeneous Environments,https://arxiv.org/abs/2507.14487,
ArXiv,Kernel Based Maximum Entropy Inverse Reinforcement Learning for Mean-Field Games,https://arxiv.org/abs/2507.14529,
ArXiv,Learning to Communicate in Multi-Agent Reinforcement Learning for Autonomous Cyber Defence,https://arxiv.org/abs/2507.14658,
ArXiv,Balancing Expressivity and Robustness: Constrained Rational Activations for Reinforcement Learning,https://arxiv.org/abs/2507.14736,
ArXiv,Skill Learning via Policy Diversity Yields Identifiable Representations for Reinforcement Learning,https://arxiv.org/abs/2507.14748,
ArXiv,Omni-Think: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards,https://arxiv.org/abs/2507.14783,
ArXiv,Hierarchical Multi-Agent Reinforcement Learning with Control Barrier Functions for Safety-Critical Autonomous Systems,https://arxiv.org/abs/2507.14850,
ArXiv,AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents,https://arxiv.org/abs/2507.14897,
ArXiv,CoMoCAVs: Cohesive Decision-Guided Motion Planning for Connected and Autonomous Vehicles with Multi-Policy Reinforcement Learning,https://arxiv.org/abs/2507.14903,
ArXiv,AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning,https://arxiv.org/abs/2507.14987,
ArXiv,LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading,https://arxiv.org/abs/2507.14995,
ArXiv,Reinforcement Learning for Flow-Matching Policies,https://arxiv.org/abs/2507.15073,
ArXiv,Frame-level Temporal Difference Learning for Partial Deepfake Speech Detection,https://arxiv.org/abs/2507.15101,
ArXiv,Code Clone Detection via an AlphaFold-Inspired Framework,https://arxiv.org/abs/2507.15226,
ArXiv,Mixture of Autoencoder Experts Guidance using Unlabeled and Incomplete Data for Exploration in Reinforcement Learning,https://arxiv.org/abs/2507.15287,
ArXiv,One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms,https://arxiv.org/abs/2507.15351,
ArXiv,The Emergence of Deep Reinforcement Learning for Path Planning,https://arxiv.org/abs/2507.15469,
ArXiv,Off-Policy Corrected Reward Modeling for Reinforcement Learning from Human Feedback,https://arxiv.org/abs/2507.15507,
ArXiv,Learning to Extract Rational Evidence via Reinforcement Learning for Retrieval-Augmented Generation,https://arxiv.org/abs/2507.15586,
ArXiv,Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario,https://arxiv.org/abs/2507.15587,
ArXiv,Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning,https://arxiv.org/abs/2507.15788,
ArXiv,Statistical and Algorithmic Foundations of Reinforcement Learning,https://arxiv.org/abs/2507.14444,
ArXiv,Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies,https://arxiv.org/abs/2507.14901,
ArXiv,Maximum Causal Entropy IRL in Mean-Field Games and GNEP Framework for Forward RL,https://arxiv.org/abs/2401.06566,
ArXiv,AlphaDPO: Adaptive Reward Margin for Direct Preference Optimization,https://arxiv.org/abs/2410.10148,
ArXiv,DMOSpeech 2: Reinforcement Learning for Duration Prediction in Metric-Optimized Speech Synthesis,https://arxiv.org/abs/2507.14988,
