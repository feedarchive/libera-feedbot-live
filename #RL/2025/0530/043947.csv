feed,title,long_url,short_url
ArXiv,When Does Neuroevolution Outcompete Reinforcement Learning in Transfer Learning Tasks?,https://arxiv.org/abs/2505.22696,
ArXiv,"Decomposing Elements of Problem Solving: What ""Math"" Does RL Teach?",https://arxiv.org/abs/2505.22756,
ArXiv,Scaling Offline RL via Efficient and Expressive Shortcut Models,https://arxiv.org/abs/2505.22866,
ArXiv,cadrille: Multi-modal CAD Reconstruction with Online Reinforcement Learning,https://arxiv.org/abs/2505.22914,
ArXiv,Enhancing Study-Level Inference from Clinical Trial Papers via RL-based Numeric Reasoning,https://arxiv.org/abs/2505.22928,
ArXiv,WorkForceAgent-R1: Incentivizing Reasoning Capability in LLM-based Web Agents via Reinforcement Learning,https://arxiv.org/abs/2505.22942,
ArXiv,Hybrid Cross-domain Robust Reinforcement Learning,https://arxiv.org/abs/2505.23003,
ArXiv,Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics Data,https://arxiv.org/abs/2505.23062,
ArXiv,Infi-MMR: Curriculum-based Unlocking Multimodal Reasoning via Phased Reinforcement Learning in Multimodal Small Language Models,https://arxiv.org/abs/2505.23091,
ArXiv,CURVE: CLIP-Utilized Reinforcement Learning for Visual Image Enhancement via Simple Image Processing,https://arxiv.org/abs/2505.23102,
ArXiv,DIP-R1: Deep Inspection and Perception with RL Looking Through and Understanding Complex Scenes,https://arxiv.org/abs/2505.23179,
ArXiv,Grower-in-the-Loop Interactive Reinforcement Learning for Greenhouse Climate Control,https://arxiv.org/abs/2505.23355,
ArXiv,UniRL: Self-Improving Unified Multimodal Models via Supervised and Reinforcement Learning,https://arxiv.org/abs/2505.23380,
ArXiv,Afterburner: Reinforcement Learning Facilitates Self-Improving Code Efficiency Optimization,https://arxiv.org/abs/2505.23387,
ArXiv,Normalizing Flows are Capable Models for RL,https://arxiv.org/abs/2505.23527,
ArXiv,Segment Policy Optimization: Effective Segment-Level Credit Assignment in RL for Large Language Models,https://arxiv.org/abs/2505.23564,
ArXiv,On-Policy RL with Optimal Reward Baseline,https://arxiv.org/abs/2505.23585,
ArXiv,Jigsaw-R1: A Study of Rule-based Visual Reinforcement Learning with Jigsaw Puzzles,https://arxiv.org/abs/2505.23590,
ArXiv,Fortune: Formula-Driven Reinforcement Learning for Symbolic Table Reasoning in Language Models,https://arxiv.org/abs/2505.23667,
ArXiv,Grounded Reinforcement Learning for Visual Reasoning,https://arxiv.org/abs/2505.23678,
ArXiv,AMOR: Adaptive Character Control through Multi-Objective Reinforcement Learning,https://arxiv.org/abs/2505.23708,
ArXiv,DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural Language and Reinforcement Learning,https://arxiv.org/abs/2505.23754,
ArXiv,Learning to Charge More: A Theoretical Study of Collusion by Q-Learning Agents,https://arxiv.org/abs/2505.22909,
ArXiv,Text-to-Decision Agent: Offline Meta-Reinforcement Learning from Natural Language Supervision,https://arxiv.org/abs/2504.15046,
ArXiv,Pessimism Principle Can Be Effective: Towards a Framework for Zero-Shot Transfer Reinforcement Learning,https://arxiv.org/abs/2505.18447,
