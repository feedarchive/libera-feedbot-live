feed,title,long_url,short_url
ArXiv,A Model-Based Approach for Improving Reinforcement Learning Efficiency Leveraging Expert Observations,https://arxiv.org/abs/2402.18836,
ArXiv,How to Train your Antivirus: RL-based Hardening through the Problem-Space,https://arxiv.org/abs/2402.19027,
ArXiv,RL-GPT: Integrating Reinforcement Learning and Code-as-policy,https://arxiv.org/abs/2402.19299,
ArXiv,Understanding Iterative Combinatorial Auction Designs via Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2402.19420,
ArXiv,ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL,https://arxiv.org/abs/2402.19446,
ArXiv,When Demonstrations Meet Generative World Models: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning,https://arxiv.org/abs/2302.07457,
ArXiv,Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing,https://arxiv.org/abs/2308.08705,
ArXiv,Improving Generalization in Reinforcement Learning Training Regimes for Social Robot Navigation,https://arxiv.org/abs/2308.14947,
ArXiv,SMORE: Score Models for Offline Goal-Conditioned Reinforcement Learning,https://arxiv.org/abs/2311.02013,
ArXiv,Safe Reinforcement Learning in a Simulated Robotic Arm,https://arxiv.org/abs/2312.09468,
