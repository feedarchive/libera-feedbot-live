feed,title,long_url,short_url
ArXiv,Detecting Continuous Integration Skip : A Reinforcement Learning-based Approach,https://arxiv.org/abs/2405.09657,
ArXiv,"Combining RL and IL using a dynamic, performance-based modulation over learning signals and its application to local planning",https://arxiv.org/abs/2405.09760,
ArXiv,Optimizing Search and Rescue UAV Connectivity in Challenging Terrain through Multi Q-Learning,https://arxiv.org/abs/2405.10042,
ArXiv,A Design Trajectory Map of Human-AI Collaborative Reinforcement Learning Systems: Survey and Taxonomy,https://arxiv.org/abs/2405.10214,
ArXiv,Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning,https://arxiv.org/abs/2405.10292,
ArXiv,Stochastic Q-learning for Large Discrete Action Spaces,https://arxiv.org/abs/2405.10310,
ArXiv,Fast Two-Time-Scale Stochastic Gradient Method with Applications in Reinforcement Learning,https://arxiv.org/abs/2405.09660,
ArXiv,Goal-conditioned Offline Reinforcement Learning through State Space Partitioning,https://arxiv.org/abs/2303.09367,
ArXiv,PACE: Improving Prompt with Actor-Critic Editing for Large Language Model,https://arxiv.org/abs/2308.10088,
ArXiv,Multi-Robot Cooperative Socially-Aware Navigation Using Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2309.15234,
ArXiv,"ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models",https://arxiv.org/abs/2310.10505,
ArXiv,GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with Learned Models,https://arxiv.org/abs/2310.20025,
