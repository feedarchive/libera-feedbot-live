feed,title,long_url,short_url
ArXiv,A Benchmark Study of Deep-RL Methods for Maximum Coverage Problems over Graphs,https://arxiv.org/abs/2406.14697,
ArXiv,A General Control-Theoretic Approach for Reinforcement Learning: Theory and Algorithms,https://arxiv.org/abs/2406.14753,
ArXiv,Multi-Task Lane-Free Driving Strategy for Connected and Automated Vehicles: A Multi-Agent Deep Reinforcement Learning Approach,https://arxiv.org/abs/2406.14766,
ArXiv,Learning to Select Goals in Automated Planning with Deep-Q Learning,https://arxiv.org/abs/2406.14779,
ArXiv,Towards Dynamic Resource Allocation and Client Scheduling in Hierarchical Federated Learning: A Two-Phase Deep Reinforcement Learning Approach,https://arxiv.org/abs/2406.14910,
ArXiv,Learning Autonomous Race Driving with Action Mapping Reinforcement Learning,https://arxiv.org/abs/2406.14934,
ArXiv,An Idiosyncrasy of Time-discretization in Reinforcement Learning,https://arxiv.org/abs/2406.14951,
ArXiv,SiT: Symmetry-Invariant Transformers for Generalisation in Reinforcement Learning,https://arxiv.org/abs/2406.15025,
ArXiv,KnobTree: Intelligent Database Parameter Configuration via Explainable Reinforcement Learning,https://arxiv.org/abs/2406.15073,
ArXiv,Towards General Negotiation Strategies with End-to-End Reinforcement Learning,https://arxiv.org/abs/2406.15096,
ArXiv,KalMamba: Towards Efficient Probabilistic State Space Models for RL under Uncertainty,https://arxiv.org/abs/2406.15131,
ArXiv,Open Problem: Order Optimal Regret Bounds for Kernel-Based Reinforcement Learning,https://arxiv.org/abs/2406.15250,
ArXiv,MRHER: Model-based Relay Hindsight Experience Replay for Sequential Object Manipulation Tasks with Sparse Rewards,https://arxiv.org/abs/2306.16061,
ArXiv,SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores,https://arxiv.org/abs/2306.16688,
ArXiv,RL4CO: an Extensive Reinforcement Learning for Combinatorial Optimization Benchmark,https://arxiv.org/abs/2306.17100,
