feed,title,long_url,short_url
ArXiv,Finite-Sample Analysis of the Monte Carlo Exploring Starts Algorithm for Reinforcement Learning,https://arxiv.org/abs/2410.02994,
ArXiv,Hybrid Classical/RL Local Planner for Ground Robot Navigation,https://arxiv.org/abs/2410.03066,
ArXiv,Spatial-aware decision-making with ring attractors in reinforcement learning systems,https://arxiv.org/abs/2410.03119,
ArXiv,Hybrid Centralized-Distributed Resource Allocation Based on Deep Reinforcement Learning for Cooperative D2D Communications,https://arxiv.org/abs/2410.03177,
ArXiv,Data-Efficient Massive Tool Retrieval: A Reinforcement Learning Approach for Query-Tool Alignment with Language Models,https://arxiv.org/abs/2410.03212,
ArXiv,Mitigating Adversarial Perturbations for Deep Reinforcement Learning via Vector Quantization,https://arxiv.org/abs/2410.03376,
ArXiv,Deep Reinforcement Learning for Delay-Optimized Task Offloading in Vehicular Fog Computin,https://arxiv.org/abs/2410.03472,
ArXiv,GAP-RL: Grasps As Points for RL Towards Dynamic Object Grasping,https://arxiv.org/abs/2410.03509,
ArXiv,Training on more Reachable Tasks for Generalisation in Reinforcement Learning,https://arxiv.org/abs/2410.03565,
ArXiv,Open-World Reinforcement Learning over Long Short-Term Imagination,https://arxiv.org/abs/2410.03618,
ArXiv,Federated Ensemble-Directed Offline Reinforcement Learning,https://arxiv.org/abs/2305.03097,
ArXiv,Synergizing Quality-Diversity with Descriptor-Conditioned Reinforcement Learning,https://arxiv.org/abs/2401.08632,
