feed,title,long_url,short_url
ArXiv,PufferLib: Making Reinforcement Learning Libraries and Environments Play Nice,https://arxiv.org/abs/2406.12905,
ArXiv,Oralytics Reinforcement Learning Algorithm,https://arxiv.org/abs/2406.13127,
ArXiv,Act Better by Timing: A timing-Aware Reinforcement Learning for Autonomous Driving,https://arxiv.org/abs/2406.13223,
ArXiv,Design Optimization of NOMA Aided Multi-STAR-RIS for Indoor Environments: A Convex Approximation Imitated Reinforcement Learning Approach,https://arxiv.org/abs/2406.13280,
ArXiv,Learning the Approach During the Short-loading Cycle Using Reinforcement Learning,https://arxiv.org/abs/2406.13366,
ArXiv,Efficient Offline Reinforcement Learning: The Critic is Critical,https://arxiv.org/abs/2406.13376,
ArXiv,Tactile Aware Dynamic Obstacle Avoidance in Crowded Environment with Deep Reinforcement Learning,https://arxiv.org/abs/2406.13434,
ArXiv,Reinforcement Learning to improve delta robot throws for sorting scrap metal,https://arxiv.org/abs/2406.13453,
ArXiv,Trapezoidal Gradient Descent for Effective Reinforcement Learning in Spiking Networks,https://arxiv.org/abs/2406.13568,
ArXiv,Reinforcement Learning for Infinite-Horizon Average-Reward MDPs with Multinomial Logistic Function Approximation,https://arxiv.org/abs/2406.13633,
ArXiv,Reinforcement Learning-Based Model Matching to Reduce the Sim-Real Gap in COBRA,https://arxiv.org/abs/2406.13700,
ArXiv,SRL-VIC: A Variable Stiffness-Based Safe Reinforcement Learning for Contact-Rich Robotic Tasks,https://arxiv.org/abs/2406.13744,
ArXiv,Global Human-guided Counterfactual Explanations for Molecular Properties via Reinforcement Learning,https://arxiv.org/abs/2406.13869,
ArXiv,Equivariant Offline Reinforcement Learning,https://arxiv.org/abs/2406.13961,
ArXiv,Bayesian Inverse Reinforcement Learning for Non-Markovian Rewards,https://arxiv.org/abs/2406.13991,
ArXiv,Robust Cooperative Multi-Agent Reinforcement Learning:A Mean-Field Type Game Perspective,https://arxiv.org/abs/2406.13992,
ArXiv,Constrained Meta Agnostic Reinforcement Learning,https://arxiv.org/abs/2406.14047,
ArXiv,Urban-Focused Multi-Task Offline Reinforcement Learning with Contrastive Data Sharing,https://arxiv.org/abs/2406.14054,
ArXiv,Optimizing Novelty of Top-k Recommendations using Large Language Models and Reinforcement Learning,https://arxiv.org/abs/2406.14169,
ArXiv,REVEAL-IT: REinforcement learning with Visibility of Evolving Agent poLicy for InTerpretability,https://arxiv.org/abs/2406.14214,
ArXiv,Defending Against Sophisticated Poisoning Attacks with RL-based Aggregation in Federated Learning,https://arxiv.org/abs/2406.14217,
ArXiv,Revealing the learning process in reinforcement learning agents through attention-oriented metrics,https://arxiv.org/abs/2406.14324,
ArXiv,Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue,https://arxiv.org/abs/2406.14457,
ArXiv,RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold,https://arxiv.org/abs/2406.14532,
ArXiv,MacroHFT: Memory Augmented Context-aware Reinforcement Learning On High Frequency Trading,https://arxiv.org/abs/2406.14537,
ArXiv,Reinforcement Learning for Corporate Bond Trading: A Sell Side Perspective,https://arxiv.org/abs/2406.12983,
ArXiv,"A DRL Approach for RIS-Assisted Full-Duplex UL and DL Transmission: Beamforming, Phase Shift and Power Optimization",https://arxiv.org/abs/2212.13854,
ArXiv,RLHFPoison: Reward Poisoning Attack for Reinforcement Learning with Human Feedback in Large Language Models,https://arxiv.org/abs/2311.09641,
ArXiv,Aligning Human Intent from Imperfect Demonstrations with Confidence-based Inverse soft-Q Learning,https://arxiv.org/abs/2312.11194,
