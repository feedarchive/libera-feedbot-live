feed,title,long_url,short_url
ArXiv,The Impact of Quantization and Pruning on Deep Reinforcement Learning Models,https://arxiv.org/abs/2407.04803,
ArXiv,Simplifying Deep Temporal Difference Learning,https://arxiv.org/abs/2407.04811,
ArXiv,Question Answering with Texts and Tables through Deep Reinforcement Learning,https://arxiv.org/abs/2407.04858,
ArXiv,Augmented Bayesian Policy Search,https://arxiv.org/abs/2407.04864,
ArXiv,Multi-agent Off-policy Actor-Critic Reinforcement Learning for Partially Observable Environments,https://arxiv.org/abs/2407.04974,
ArXiv,A Novel Bifurcation Method for Observation Perturbation Attacks on Reinforcement Learning Agents: Load Altering Attacks on a Cyber Physical Power System,https://arxiv.org/abs/2407.05182,
ArXiv,Cost-Efficient Computation Offloading in SAGIN: A Deep Reinforcement Learning and Perception-Aided Approach,https://arxiv.org/abs/2407.05571,
ArXiv,$\mathrm{E^{2}CFD}$: Towards Effective and Efficient Cost Function Design for Safe Reinforcement Learning via Large Language Model,https://arxiv.org/abs/2407.05580,
ArXiv,Multi-agent Reinforcement Learning-based Network Intrusion Detection System,https://arxiv.org/abs/2407.05766,
ArXiv,Structural Generalization in Autonomous Cyber Incident Response with Message-Passing Neural Networks and Reinforcement Learning,https://arxiv.org/abs/2407.05775,
ArXiv,FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging,https://arxiv.org/abs/2407.05800,
ArXiv,Graph Anomaly Detection with Noisy Labels by Reinforcement Learning,https://arxiv.org/abs/2407.05934,
ArXiv,iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement,https://arxiv.org/abs/2407.06025,
ArXiv,Stranger Danger! Identifying and Avoiding Unpredictable Pedestrians in RL-based Social Robot Navigation,https://arxiv.org/abs/2407.06056,
ArXiv,Periodic agent-state based Q-learning for POMDPs,https://arxiv.org/abs/2407.06121,
ArXiv,Hierarchical Decoupling Capacitor Optimization for Power Distribution Network of 2.5D ICs with Co-Analysis of Frequency and Time Domains Based on Deep Reinforcement Learning,https://arxiv.org/abs/2407.04737,
ArXiv,ASRRL-TTS: Agile Speaker Representation Reinforcement Learning for Text-to-Speech Speaker Adaptation,https://arxiv.org/abs/2407.05421,
ArXiv,Cooperative Hierarchical Deep Reinforcement Learning based Joint Sleep and Power Control in RIS-aided Energy-Efficient RAN,https://arxiv.org/abs/2304.13226,
ArXiv,Physics-Regulated Deep Reinforcement Learning: Invariant Embeddings,https://arxiv.org/abs/2305.16614,
ArXiv,Lifelike Agility and Play in Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models,https://arxiv.org/abs/2308.15143,
ArXiv,"Mind the Model, Not the Agent: The Primacy Bias in Model-based RL",https://arxiv.org/abs/2310.15017,
ArXiv,Synergistic Formulaic Alpha Generation for Quantitative Trading based on Reinforcement Learning,https://arxiv.org/abs/2401.02710,
ArXiv,A Reinforcement Learning Approach for Wildfire Tracking with UAV Swarms,https://arxiv.org/abs/2407.05473,
