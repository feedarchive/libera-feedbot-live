feed,title,long_url,short_url
ArXiv,"Reinforcement Learning from Human Feedback: Whose Culture, Whose Values, Whose Perspectives?",https://arxiv.org/abs/2407.17482,
ArXiv,Meta-Reinforcement Learning for Universal Quadrupedal Locomotion Control,https://arxiv.org/abs/2407.17502,
ArXiv,RL-augmented MPC Framework for Agile and Robust Bipedal Footstep Locomotion Planning and Control,https://arxiv.org/abs/2407.17683,
ArXiv,Advanced deep-reinforcement-learning methods for flow control: group-invariant and positional-encoding networks improve learning speed and quality,https://arxiv.org/abs/2407.17822,
ArXiv,Multi-Agent Deep Reinforcement Learning for Resilience Optimization in 5G RAN,https://arxiv.org/abs/2407.18066,
ArXiv,Principal-Agent Reinforcement Learning,https://arxiv.org/abs/2407.18074,
ArXiv,MapTune: Advancing ASIC Technology Mapping via Reinforcement Learning Guided Library Tuning,https://arxiv.org/abs/2407.18110,
ArXiv,Maximum Entropy On-Policy Actor-Critic via Entropy Advantage Estimation,https://arxiv.org/abs/2407.18143,
ArXiv,Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning,https://arxiv.org/abs/2407.18202,
ArXiv,Q-Pensieve: Boosting Sample Efficiency of Multi-Objective RL Through Memory Sharing of Q-Snapshots,https://arxiv.org/abs/2212.03117,
ArXiv,Harnessing DRL for URLLC in Open RAN: A Trade-off Exploration,https://arxiv.org/abs/2407.17598,
