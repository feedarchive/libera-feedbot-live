feed,title,long_url,short_url
ArXiv,LLM-Augmented Symbolic Reinforcement Learning with Landmark-Based Task Decomposition,https://arxiv.org/abs/2410.01929,
ArXiv,"Don't flatten, tokenize! Unlocking the key to SoftMoE's efficacy in deep RL",https://arxiv.org/abs/2410.01930,
ArXiv,ComaDICE: Offline Cooperative Multi-Agent Reinforcement Learning with Stationary Distribution Shift Regularization,https://arxiv.org/abs/2410.01954,
ArXiv,Realizable Continuous-Space Shields for Safe Reinforcement Learning,https://arxiv.org/abs/2410.02038,
ArXiv,RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning,https://arxiv.org/abs/2410.02089,
ArXiv,Doubly Optimal Policy Evaluation for Reinforcement Learning,https://arxiv.org/abs/2410.02226,
ArXiv,C-MORL: Multi-Objective Reinforcement Learning through Efficient Discovery of Pareto Front,https://arxiv.org/abs/2410.02236,
ArXiv,End-to-end Driving in High-Interaction Traffic Scenarios with Reinforcement Learning,https://arxiv.org/abs/2410.02253,
ArXiv,Federated Reinforcement Learning to Optimize Teleoperated Driving Networks,https://arxiv.org/abs/2410.02312,
ArXiv,AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models,https://arxiv.org/abs/2410.02355,
ArXiv,Cross-Embodiment Dexterous Grasping with Reinforcement Learning,https://arxiv.org/abs/2410.02479,
ArXiv,Learning Emergence of Interaction Patterns across Independent RL Agents in Multi-Agent Environments,https://arxiv.org/abs/2410.02516,
ArXiv,Semantic-Guided RL for Interpretable Feature Engineering,https://arxiv.org/abs/2410.02519,
ArXiv,Boosting Sample Efficiency and Generalization in Multi-agent Reinforcement Learning via Equivariance,https://arxiv.org/abs/2410.02581,
ArXiv,Beyond Expected Returns: A Policy Gradient Algorithm for Cumulative Prospect Theoretic Reinforcement Learning,https://arxiv.org/abs/2410.02605,
ArXiv,AlphaIntegrator: Transformer Action Search for Symbolic Integration Proofs,https://arxiv.org/abs/2410.02666,
ArXiv,MA-RLHF: Reinforcement Learning from Human Feedback with Macro Actions,https://arxiv.org/abs/2410.02743,
ArXiv,ReLIC: A Recipe for 64k Steps of In-Context Reinforcement Learning for Embodied AI,https://arxiv.org/abs/2410.02751,
ArXiv,Dual Active Learning for Reinforcement Learning from Human Feedback,https://arxiv.org/abs/2410.02504,
ArXiv,On the Statistical Efficiency of Mean-Field Reinforcement Learning with General Function Approximation,https://arxiv.org/abs/2305.11283,
ArXiv,Reinforcement Learning with Foundation Priors: Let the Embodied Agent Efficiently Learn on Its Own,https://arxiv.org/abs/2310.02635,
