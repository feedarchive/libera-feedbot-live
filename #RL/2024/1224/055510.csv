feed,title,long_url,short_url
ArXiv,Hierarchical Multi-Agent DRL Based Dynamic Cluster Reconfiguration for UAV Mobility Management,https://arxiv.org/abs/2412.16167,
ArXiv,CLIP-RLDrive: Human-Aligned Autonomous Driving via CLIP-Based Reward Shaping in Reinforcement Learning,https://arxiv.org/abs/2412.16201,
ArXiv,AdvIRL: Reinforcement Learning-Based Adversarial Attacks on 3D NeRF Models,https://arxiv.org/abs/2412.16213,
ArXiv,Bayesian Critique-Tune-Based Reinforcement Learning with Attention-Based Adaptive Pressure for Multi-Intersection Traffic Signal Control,https://arxiv.org/abs/2412.16225,
ArXiv,Optimizing Low-Speed Autonomous Driving: A Reinforcement Learning Approach to Route Stability and Maximum Speed,https://arxiv.org/abs/2412.16248,
ArXiv,Decoding fairness: a reinforcement learning perspective,https://arxiv.org/abs/2412.16249,
ArXiv,Autonomous Option Invention for Continual Hierarchical Reinforcement Learning and Planning,https://arxiv.org/abs/2412.16395,
ArXiv,Deep Reinforcement Learning Based Systems for Safety Critical Applications in Aerospace,https://arxiv.org/abs/2412.16489,
ArXiv,On Enhancing Network Throughput using Reinforcement Learning in Sliced Testbeds,https://arxiv.org/abs/2412.16673,
ArXiv,Adaptive User Interface Generation Through Reinforcement Learning: A Data-Driven Approach to Personalization and Optimization,https://arxiv.org/abs/2412.16837,
ArXiv,ACL-QL: Adaptive Conservative Level in Q-Learning for Offline Reinforcement Learning,https://arxiv.org/abs/2412.16848,
ArXiv,Online Preference-based Reinforcement Learning with Self-augmented Feedback from Large Language Model,https://arxiv.org/abs/2412.16878,
ArXiv,Environment Descriptions for Usability and Generalisation in Reinforcement Learning,https://arxiv.org/abs/2412.16970,
ArXiv,Adam on Local Time: Addressing Nonstationarity in RL with Relative Adam Timesteps,https://arxiv.org/abs/2412.17113,
ArXiv,Fairness in Reinforcement Learning with Bisimulation Metrics,https://arxiv.org/abs/2412.17123,
ArXiv,ACECode: A Reinforcement Learning Framework for Aligning Code Efficiency and Correctness in Code Language Models,https://arxiv.org/abs/2412.17264,
ArXiv,Reinforcement Learning with a Focus on Adjusting Policies to Reach Targets,https://arxiv.org/abs/2412.17344,
ArXiv,HyperQ-Opt: Q-learning for Hyperparameter Optimization,https://arxiv.org/abs/2412.17765,
ArXiv,"Mean--Variance Portfolio Selection by Continuous-Time Reinforcement Learning: Algorithms, Regret Analysis, and Empirical Study",https://arxiv.org/abs/2412.16175,
ArXiv,Human-centric Reward Optimization for Reinforcement Learning-based Automated Driving using Large Language Models,https://arxiv.org/abs/2405.04135,
ArXiv,Variational Sequential Optimal Experimental Design using Reinforcement Learning,https://arxiv.org/abs/2306.10430,
ArXiv,Multimodal Deep Reinforcement Learning for Portfolio Optimization,https://arxiv.org/abs/2412.17293,
