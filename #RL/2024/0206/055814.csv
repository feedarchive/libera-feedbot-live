feed,title,long_url,short_url
ArXiv,The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models,https://arxiv.org/abs/2402.01874,
ArXiv,Inverse Reinforcement Learning by Estimating Expertise of Demonstrators,https://arxiv.org/abs/2402.01886,
ArXiv,Value-Aided Conditional Supervised Learning for Offline RL,https://arxiv.org/abs/2402.02017,
ArXiv,A Survey of Constraint Formulations in Safe Reinforcement Learning,https://arxiv.org/abs/2402.02025,
ArXiv,Emergency Computing: An Adaptive Collaborative Inference Method Based on Hierarchical Reinforcement Learning,https://arxiv.org/abs/2402.02146,
ArXiv,Towards Optimal Adversarial Robust Q-learning with Bellman Infinity-error,https://arxiv.org/abs/2402.02165,
ArXiv,Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback,https://arxiv.org/abs/2402.02423,
ArXiv,Towards an Information Theoretic Framework of Context-Based Offline Meta-Reinforcement Learning,https://arxiv.org/abs/2402.02429,
ArXiv,DiffStitch: Boosting Offline Reinforcement Learning with Diffusion-based Trajectory Stitching,https://arxiv.org/abs/2402.02439,
ArXiv,Obstacle Avoidance Deep Reinforcement Learning-Based Trajectory Planner with Robust Low-Level Control for Robotic Manipulators,https://arxiv.org/abs/2402.02551,
ArXiv,Evading Deep Learning-Based Malware Detectors via Obfuscation: A Deep Reinforcement Learning Approach,https://arxiv.org/abs/2402.02600,
ArXiv,Accelerating Inverse Reinforcement Learning with Expert Bootstrapping,https://arxiv.org/abs/2402.02608,
ArXiv,The Virtues of Pessimism in Inverse Reinforcement Learning,https://arxiv.org/abs/2402.02616,
ArXiv,A Safe Reinforcement Learning driven Weights-varying Model Predictive Control for Autonomous Vehicle Motion Control,https://arxiv.org/abs/2402.02624,
ArXiv,Vision-Language Models Provide Promptable Representations for Reinforcement Learning,https://arxiv.org/abs/2402.02651,
ArXiv,Utility-Based Reinforcement Learning: Unifying Single-objective and Multi-objective Reinforcement Learning,https://arxiv.org/abs/2402.02665,
ArXiv,Understanding What Affects Generalization Gap in Visual Reinforcement Learning: Theory and Empirical Evidence,https://arxiv.org/abs/2402.02701,
ArXiv,Deep autoregressive density nets vs neural ensembles for model-based offline reinforcement learning,https://arxiv.org/abs/2402.02858,
ArXiv,Fine-tuning Reinforcement Learning Models is Secretly a Forgetting Mitigation Problem,https://arxiv.org/abs/2402.02868,
ArXiv,Replication of Impedance Identification Experiments on a Reinforcement-Learning-Controlled Digital Twin of Human Elbows,https://arxiv.org/abs/2402.02904,
ArXiv,Multi-Agent Reinforcement Learning for Offloading Cellular Communications with Cooperating UAVs,https://arxiv.org/abs/2402.02957,
ArXiv,Open RL Benchmark: Comprehensive Tracked Experiments for Reinforcement Learning,https://arxiv.org/abs/2402.03046,
ArXiv,Probabilistic Actor-Critic: Learning to Explore with PAC-Bayes Uncertainty,https://arxiv.org/abs/2402.03055,
ArXiv,Boosting Long-Delayed Reinforcement Learning with Auxiliary Short-Delayed Task,https://arxiv.org/abs/2402.03141,
ArXiv,A Multi-step Loss Function for Robust Learning of the Dynamics in Model-based Reinforcement Learning,https://arxiv.org/abs/2402.03146,
ArXiv,Multi-agent Reinforcement Learning for Energy Saving in Multi-Cell Massive MIMO Systems,https://arxiv.org/abs/2402.03204,
ArXiv,Learning to Abstract Visuomotor Mappings using Meta-Reinforcement Learning,https://arxiv.org/abs/2402.03072,
ArXiv,Statistically Efficient Bayesian Sequential Experiment Design via Reinforcement Learning with Cross-Entropy Estimators,https://arxiv.org/abs/2305.18435,
ArXiv,Symmetric Replay Training: Enhancing Sample Efficiency in Deep Reinforcement Learning for Combinatorial Optimization,https://arxiv.org/abs/2306.01276,
ArXiv,Deep Reinforcement Learning for Image-to-Image Translation,https://arxiv.org/abs/2309.13672,
ArXiv,Consciousness-Inspired Spatio-Temporal Abstractions for Better Generalization in Reinforcement Learning,https://arxiv.org/abs/2310.00229,
ArXiv,Diffusion Models for Reinforcement Learning: A Survey,https://arxiv.org/abs/2311.01223,
ArXiv,Anytime-Competitive Reinforcement Learning with Policy Prior,https://arxiv.org/abs/2311.01568,
ArXiv,Multi-Objective Reinforcement Learning Based on Decomposition: A Taxonomy and Framework,https://arxiv.org/abs/2311.12495,
ArXiv,Predictable Reinforcement Learning Dynamics through Entropy Rate Minimization,https://arxiv.org/abs/2311.18703,
ArXiv,Efficient Parallel Reinforcement Learning Framework using the Reactor Model,https://arxiv.org/abs/2312.04704,
