feed,title,long_url,short_url
ArXiv,Isometric Neural Machine Translation using Phoneme Count Ratio Reward-based Reinforcement Learning,https://arxiv.org/abs/2403.15469,
ArXiv,SRLM: Human-in-Loop Interactive Social Robot Navigation with Large Language Model and Deep Reinforcement Learning,https://arxiv.org/abs/2403.15648,
ArXiv,A Fairness-Oriented Reinforcement Learning Approach for the Operation and Control of Shared Micromobility Services,https://arxiv.org/abs/2403.15780,
ArXiv,Utilizing Motion Matching with Deep Reinforcement Learning for Target Location Tasks,https://arxiv.org/abs/2403.15902,
ArXiv,Deep Gaussian Covariance Network with Trajectory Sampling for Data-Efficient Policy Search,https://arxiv.org/abs/2403.15908,
ArXiv,Multi-agent transformer-accelerated RL for satisfaction of STL specifications,https://arxiv.org/abs/2403.15916,
ArXiv,Safe Reinforcement Learning for Constrained Markov Decision Processes with Stochastic Stopping Time,https://arxiv.org/abs/2403.15928,
ArXiv,Interpretable Modeling of Deep Reinforcement Learning Driven Scheduling,https://arxiv.org/abs/2403.16293,
ArXiv,Q-adaptive: A Multi-Agent Reinforcement Learning Based Routing on Dragonfly Network,https://arxiv.org/abs/2403.16301,
ArXiv,Physics-informed RL for Maximal Safety Probability Estimation,https://arxiv.org/abs/2403.16391,
ArXiv,Trajectory Planning of Robotic Manipulator in Dynamic Environment Exploiting DRL,https://arxiv.org/abs/2403.16652,
ArXiv,Deep Reinforcement Learning and Mean-Variance Strategies for Responsible Portfolio Optimization,https://arxiv.org/abs/2403.16667,
ArXiv,Enhancing Software Effort Estimation through Reinforcement Learning-based Project Management-Oriented Feature Selection,https://arxiv.org/abs/2403.16749,
ArXiv,Weak Convergence Analysis of Online Neural Actor-Critic Algorithms,https://arxiv.org/abs/2403.16825,
ArXiv,Convergence of a model-free entropy-regularized inverse reinforcement learning algorithm,https://arxiv.org/abs/2403.16829,
ArXiv,Reinforcement Learning-based Recommender Systems with Large Language Models for State Reward and Action Modeling,https://arxiv.org/abs/2403.16948,
ArXiv,CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity,https://arxiv.org/abs/1902.05605,
ArXiv,A Theoretical Understanding of Gradient Bias in Meta-Reinforcement Learning,https://arxiv.org/abs/2112.15400,
ArXiv,DRL-Based Trajectory Tracking for Motion-Related Modules in Autonomous Driving,https://arxiv.org/abs/2308.15991,
ArXiv,Causal Question Answering with Reinforcement Learning,https://arxiv.org/abs/2311.02760,
ArXiv,Tactics2D: A Reinforcement Learning Environment Library with Generative Scenarios for Driving Decision-making,https://arxiv.org/abs/2311.11058,
ArXiv,"EnduRL: Enhancing Safety, Stability, and Efficiency of Mixed Traffic Under Real-World Perturbations Via Reinforcement Learning",https://arxiv.org/abs/2311.12261,
ArXiv,Synthesis of Temporally-Robust Policies for Signal Temporal Logic Tasks using Reinforcement Learning,https://arxiv.org/abs/2312.05764,
ArXiv,Multi-agent reinforcement learning using echo-state network and its application to pedestrian dynamics,https://arxiv.org/abs/2312.11834,
