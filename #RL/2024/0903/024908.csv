feed,title,long_url,short_url
ArXiv,Online Behavior Modification for Expressive User Control of RL-Trained Robots,https://arxiv.org/abs/2408.16776,
ArXiv,AdapShare: An RL-Based Dynamic Spectrum Sharing Solution for O-RAN,https://arxiv.org/abs/2408.16842,
ArXiv,Discovery of False Data Injection Schemes on Frequency Controllers with Reinforcement Learning,https://arxiv.org/abs/2408.16958,
ArXiv,The Sample-Communication Complexity Trade-off in Federated Q-Learning,https://arxiv.org/abs/2408.16981,
ArXiv,A Tighter Convergence Proof of Reverse Experience Replay,https://arxiv.org/abs/2408.16999,
ArXiv,Efficient Camera Exposure Control for Visual Odometry via Deep Reinforcement Learning,https://arxiv.org/abs/2408.17005,
ArXiv,Traffic expertise meets residual RL: Knowledge-informed model-based residual reinforcement learning for CAV trajectory control,https://arxiv.org/abs/2408.17380,
ArXiv,Coverage Analysis of Multi-Environment Q-Learning Algorithms for Wireless Network Optimization,https://arxiv.org/abs/2408.16882,
ArXiv,Using Quantum Solved Deep Boltzmann Machines to Increase the Data Efficiency of RL Agents,https://arxiv.org/abs/2408.17240,
ArXiv,Scalable Multi-Agent Reinforcement Learning for Warehouse Logistics with Robotic and Human Co-Workers,https://arxiv.org/abs/2212.11498,
