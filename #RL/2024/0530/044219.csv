feed,title,long_url,short_url
ArXiv,Offline-Boosted Actor-Critic: Adaptively Blending Optimal Historical Behaviors in Deep Off-Policy RL,https://arxiv.org/abs/2405.18520,
ArXiv,Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination,https://arxiv.org/abs/2405.18556,
ArXiv,DTR-Bench: An in silico Environment and Benchmark Platform for Reinforcement Learning Based Dynamic Treatment Regime,https://arxiv.org/abs/2405.18610,
ArXiv,Advancing Household Robotics: Deep Interactive Reinforcement Learning for Efficient Training and Enhanced Performance,https://arxiv.org/abs/2405.18687,
ArXiv,Efficient Preference-based Reinforcement Learning via Aligned Experience Estimation,https://arxiv.org/abs/2405.18688,
ArXiv,Spectral-Risk Safe Reinforcement Learning with Convergence Guarantees,https://arxiv.org/abs/2405.18698,
ArXiv,Preferred-Action-Optimized Diffusion Policies for Offline Reinforcement Learning,https://arxiv.org/abs/2405.18729,
ArXiv,Efficient Learning in Chinese Checkers: Comparing Parameter Sharing in Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2405.18733,
ArXiv,Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies,https://arxiv.org/abs/2405.18792,
ArXiv,Adaptive Discretization-based Non-Episodic Reinforcement Learning in Metric Spaces,https://arxiv.org/abs/2405.18793,
ArXiv,Why Reinforcement Learning in Energy Systems Needs Explanations,https://arxiv.org/abs/2405.18823,
ArXiv,Proactive Load-Shaping Strategies with Privacy-Cost Trade-offs in Residential Households based on Deep Reinforcement Learning,https://arxiv.org/abs/2405.18888,
ArXiv,Optimizing Vehicular Networks with Variational Quantum Circuits-based Reinforcement Learning,https://arxiv.org/abs/2405.18984,
ArXiv,Robust Optimization in Protein Fitness Landscapes Using Reinforcement Learning in Latent Space,https://arxiv.org/abs/2405.18986,
ArXiv,Trust the Model Where It Trusts Itself -- Model-Based Actor-Critic with Uncertainty-Aware Rollout Adaption,https://arxiv.org/abs/2405.19014,
ArXiv,Efficient Exploration in Average-Reward Constrained Reinforcement Learning: Achieving Near-Optimal Regret With Posterior Sampling,https://arxiv.org/abs/2405.19017,
ArXiv,Inverse Concave-Utility Reinforcement Learning is Inverse Game Theory,https://arxiv.org/abs/2405.19024,
ArXiv,To RL or not to RL? An Algorithmic Cheat-Sheet for AI-Based Radio Resource Management,https://arxiv.org/abs/2405.19045,
ArXiv,Statistical Context Detection for Deep Lifelong Reinforcement Learning,https://arxiv.org/abs/2405.19047,
ArXiv,OMPO: A Unified Framework for RL under Policy and Dynamics Shifts,https://arxiv.org/abs/2405.19080,
ArXiv,Offline Regularised Reinforcement Learning for Large Language Models Alignment,https://arxiv.org/abs/2405.19107,
ArXiv,A Study of Plasticity Loss in On-Policy Deep Reinforcement Learning,https://arxiv.org/abs/2405.19153,
ArXiv,Diffusion-based Dynamics Models for Long-Horizon Rollout in Offline Reinforcement Learning,https://arxiv.org/abs/2405.19189,
ArXiv,Exploring the impact of traffic signal control and connected and automated vehicles on intersections safety: A deep reinforcement learning approach,https://arxiv.org/abs/2405.19236,
ArXiv,Rich-Observation Reinforcement Learning with Continuous Latent Dynamics,https://arxiv.org/abs/2405.19269,
ArXiv,Federated Q-Learning with Reference-Advantage Decomposition: Almost Optimal Regret and Logarithmic Communication Cost,https://arxiv.org/abs/2405.18795,
