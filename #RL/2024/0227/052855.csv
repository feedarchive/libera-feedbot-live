feed,title,long_url,short_url
ArXiv,Reinforcement Learning-Based Approaches for Enhancing Security and Resilience in Smart Control: A Survey on Attack and Defense Methods,https://arxiv.org/abs/2402.15617,
ArXiv,Multi-Constraint Safe RL with Objective Suppression for Safety-Critical Applications,https://arxiv.org/abs/2402.15650,
ArXiv,Discretionary Lane-Change Decision and Control via Parameterized Soft Actor-Critic for Hybrid Action Space,https://arxiv.org/abs/2402.15790,
ArXiv,Concurrent Learning of Policy and Unknown Safety Constraints in Reinforcement Learning,https://arxiv.org/abs/2402.15893,
ArXiv,Scalable Volt-VAR Optimization using RLlib-IMPALA Framework: A Reinforcement Learning Approach,https://arxiv.org/abs/2402.15932,
ArXiv,DynaMITE-RL: A Dynamic Model for Improved Temporal Meta-Reinforcement Learning,https://arxiv.org/abs/2402.15957,
ArXiv,How Can LLM Guide RL? A Value-Based Approach,https://arxiv.org/abs/2402.16181,
ArXiv,Q-FOX Learning: Breaking Tradition in Reinforcement Learning,https://arxiv.org/abs/2402.16562,
ArXiv,Program-Based Strategy Induction for Reinforcement Learning,https://arxiv.org/abs/2402.16668,
ArXiv,Think2Drive: Efficient Reinforcement Learning by Thinking in Latent World Model for Quasi-Realistic Autonomous Driving (in CARLA-v2),https://arxiv.org/abs/2402.16720,
ArXiv,Craftax: A Lightning-Fast Benchmark for Open-Ended Reinforcement Learning,https://arxiv.org/abs/2402.16801,
ArXiv,QOCO: A QoE-Oriented Computation Offloading Algorithm based on Deep Reinforcement Learning for Mobile Edge Computing,https://arxiv.org/abs/2311.02525,
ArXiv,Model-based deep reinforcement learning for accelerated learning from flow simulations,https://arxiv.org/abs/2402.16543,
ArXiv,Combining Transformer based Deep Reinforcement Learning with Black-Litterman Model for Portfolio Optimization,https://arxiv.org/abs/2402.16609,
ArXiv,Mixed Policy Gradient: off-policy reinforcement learning driven jointly by data and model,https://arxiv.org/abs/2102.11513,
ArXiv,Deep Reinforcement Learning for Decentralized Multi-Robot Exploration With Macro Actions,https://arxiv.org/abs/2110.02181,
ArXiv,Learning Dynamic Mechanisms in Unknown Environments: A Reinforcement Learning Approach,https://arxiv.org/abs/2202.12797,
ArXiv,Model-Based Reinforcement Learning for Offline Zero-Sum Markov Games,https://arxiv.org/abs/2206.04044,
ArXiv,Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data,https://arxiv.org/abs/2306.03346,
ArXiv,"RLtools: A Fast, Portable Deep Reinforcement Learning Library for Continuous Control",https://arxiv.org/abs/2306.03530,
ArXiv,Deep Reinforcement Learning with Task-Adaptive Retrieval via Hypernetwork,https://arxiv.org/abs/2306.10698,
ArXiv,Discrete Prompt Compression with Reinforcement Learning,https://arxiv.org/abs/2308.08758,
ArXiv,Contrastive Initial State Buffer for Reinforcement Learning,https://arxiv.org/abs/2309.09752,
ArXiv,Pre-training with Synthetic Data Helps Offline Reinforcement Learning,https://arxiv.org/abs/2310.00771,
ArXiv,Suppressing Overestimation in Q-Learning through Adversarial Behaviors,https://arxiv.org/abs/2310.06286,
ArXiv,Generative Flow Networks as Entropy-Regularized RL,https://arxiv.org/abs/2310.12934,
ArXiv,Optimal Control of Renewable Energy Communities subject to Network Peak Fees with Model Predictive Control and Reinforcement Learning Algorithms,https://arxiv.org/abs/2401.16321,
ArXiv,Flexible Robust Beamforming for Multibeam Satellite Downlink using Reinforcement Learning,https://arxiv.org/abs/2402.16563,
