feed,title,long_url,short_url
ArXiv,A random measure approach to reinforcement learning in continuous time,https://arxiv.org/abs/2409.17200,
ArXiv,Zeroth-Order Policy Gradient for Reinforcement Learning from Human Feedback without Reward Inference,https://arxiv.org/abs/2409.17401,
ArXiv,Spiders Based on Anxiety: How Reinforcement Learning Can Deliver Desired User Experience in Virtual Reality Personalized Arachnophobia Treatment,https://arxiv.org/abs/2409.17406,
ArXiv,Exploring Semantic Clustering in Deep Reinforcement Learning for Video Games,https://arxiv.org/abs/2409.17411,
ArXiv,Cat-and-Mouse Satellite Dynamics: Divergent Adversarial Reinforcement Learning for Contested Multi-Agent Space Operations,https://arxiv.org/abs/2409.17443,
ArXiv,Autoregressive Multi-trait Essay Scoring via Reinforcement Learning with Scoring-aware Multiple Rewards,https://arxiv.org/abs/2409.17472,
ArXiv,Hierarchical End-to-End Autonomous Driving: Integrating BEV Perception with Deep Reinforcement Learning,https://arxiv.org/abs/2409.17659,
ArXiv,Model-Free versus Model-Based Reinforcement Learning for Fixed-Wing UAV Attitude Control Under Varying Wind Conditions,https://arxiv.org/abs/2409.17896,
ArXiv,Navigation in a simplified Urban Flow through Deep Reinforcement Learning,https://arxiv.org/abs/2409.17922,
ArXiv,Role-RL: Online Long-Context Processing with Role Reinforcement Learning for Distinct LLMs in Their Optimal Roles,https://arxiv.org/abs/2409.18014,
ArXiv,Inverse Reinforcement Learning with Multiple Planning Horizons,https://arxiv.org/abs/2409.18051,
ArXiv,Adaptive Control of an Inverted Pendulum by a Reinforcement Learning-based LQR Method,https://arxiv.org/abs/2310.04436,
ArXiv,Multi-objective Reinforcement Learning with Nonlinear Preferences: Provable Approximation for Maximizing Expected Scalarized Return,https://arxiv.org/abs/2311.02544,
