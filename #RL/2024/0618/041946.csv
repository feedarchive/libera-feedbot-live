feed,title,long_url,short_url
ArXiv,Physics-Informed Critic in an Actor-Critic Reinforcement Learning for Swimming in Turbulence,https://arxiv.org/abs/2406.10242,
ArXiv,Unlock the Correlation between Supervised Fine-Tuning and Reinforcement Learning in Training Code Large Language Models,https://arxiv.org/abs/2406.10305,
ArXiv,A New Realistic Platform for Benchmarking and Performance Evaluation of DRL-Driven and Reconfigurable SFC Provisioning Solutions,https://arxiv.org/abs/2406.10356,
ArXiv,Optimal Reward Labeling: Bridging Offline Preference and Reward-Based Reinforcement Learning,https://arxiv.org/abs/2406.10445,
ArXiv,A Novel Joint DRL-Based Utility Optimization for UAV Data Services,https://arxiv.org/abs/2406.10664,
ArXiv,DIPPER: Direct Preference Optimization to Accelerate Primitive-Enabled Hierarchical Reinforcement Learning,https://arxiv.org/abs/2406.10892,
ArXiv,Design of Interacting Particle Systems for Fast and Efficient Reinforcement Learning,https://arxiv.org/abs/2406.11057,
ArXiv,The Benefits of Power Regularization in Cooperative Reinforcement Learning,https://arxiv.org/abs/2406.11240,
ArXiv,Deep-Reinforcement-Learning-Based AoI-Aware Resource Allocation for RIS-Aided IoV Networks,https://arxiv.org/abs/2406.11245,
ArXiv,Balancing Performance and Cost for Two-Hop Cooperative Communications: Stackelberg Game and Distributed Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2406.11265,
ArXiv,Reconfigurable Intelligent Surface Assisted VEC Based on Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2406.11318,
ArXiv,Adaptive Reinforcement Learning Planning: Harnessing Large Language Models for Complex Information Extraction,https://arxiv.org/abs/2406.11455,
ArXiv,Constrained Reinforcement Learning with Average Reward Objective: Model-Based and Model-Free Algorithms,https://arxiv.org/abs/2406.11481,
ArXiv,Decentralized Collaborative Pricing and Shunting for Multiple EV Charging Stations Based on Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2406.11496,
ArXiv,An Imitative Reinforcement Learning Framework for Autonomous Dogfight,https://arxiv.org/abs/2406.11562,
ArXiv,Linear Bellman Completeness Suffices for Efficient Online Reinforcement Learning with Few Actions,https://arxiv.org/abs/2406.11640,
ArXiv,The Role of Inherent Bellman Error in Offline Reinforcement Learning with Linear Function Approximation,https://arxiv.org/abs/2406.11686,
ArXiv,Optimal Transport-Assisted Risk-Sensitive Q-Learning,https://arxiv.org/abs/2406.11774,
ArXiv,Run Time Assured Reinforcement Learning for Six Degree-of-Freedom Spacecraft Inspection,https://arxiv.org/abs/2406.11795,
ArXiv,Computationally Efficient RL under Linear Bellman Completeness for Deterministic Dynamics,https://arxiv.org/abs/2406.11810,
ArXiv,Attention-Based Deep Reinforcement Learning for Qubit Allocation in Modular Quantum Architectures,https://arxiv.org/abs/2406.11452,
ArXiv,Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game,https://arxiv.org/abs/2305.12872,
ArXiv,Mildly Constrained Evaluation Policy for Offline Reinforcement Learning,https://arxiv.org/abs/2306.03680,
ArXiv,Minimax Optimal Q Learning with Nearest Neighbors,https://arxiv.org/abs/2308.01490,
ArXiv,Optimal Attack and Defense for Reinforcement Learning,https://arxiv.org/abs/2312.00198,
ArXiv,Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint,https://arxiv.org/abs/2401.06081,
ArXiv,Diffusion World Model: Future Modeling Beyond Step-by-Step Rollout for Offline Reinforcement Learning,https://arxiv.org/abs/2402.03570,
ArXiv,Improved High-Probability Bounds for the Temporal Difference Learning Algorithm via Exponential Stability,https://arxiv.org/abs/2310.14286,
