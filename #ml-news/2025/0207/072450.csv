feed,title,long_url,short_url
GN:S:PT,What is PyTorch? - MSN,https://news.google.com/rss/articles/CBMiekFVX3lxTE80WGc5cWlrWTJKNGVOQndOR2VWRzkyTjZ2azNzZTdURDV6X3dNbGZWdEhzemNuT3JWaXdnV3BULWl3ZVhjQ3V6UjN5eE14TE11QVdmSm9sQkp1VGZfNzZQcExHWURYV1RpeTN1V1FRWkJMMm4zQV9qY3ln?oc=5,https://da.gd/7kpKQ
GN:S:PT,Google AI Just Released TimesFM-2.0 (JAX and Pytorch) on Hugging Face with a Significant Boost in Accuracy and Maximum Context Length - MarkTechPost,https://news.google.com/rss/articles/CBMiggJBVV95cUxNdHZXMmo3bW1iVVRLTU50em5XZUlNcFVzOHQxc1F2R3ZNRGR3YlJSTUhlOVdVcEpRRm9OWlJja1FSbURVZElpUDJsWUtoLWlvTjhuUk92TXZxRURkazlvNnNveFZ6d25HclhTak5QTjU4c1JCSEwxVi1aZGhOZElSUDdXemZMNFZKR2JISFJySEcxT3F5TWItYzZVRVVFTlU1cURLRFY3ZHUzRmw5RTZOcnU4djdLSHhfN29ZVlR4WURjN2FFekFCZloyeDlsVW54MWVaeUlTU2V2czhWV1NqOHltbmFBaXlIQlFLYzI2SVZVSmZvcGVqeENTYlBQbGFsX2c?oc=5,https://da.gd/H7HZTo
GN:S:PT,Increasing Transformer Model Efficiency Through Attention Layer Optimization - Towards Data Science,https://news.google.com/rss/articles/CBMivgFBVV95cUxNVTE1SzhPaEJlQTg0dURGbnZwWDdUc1U3UU9yaFVfYThMd2oxMVU0ek5ETGRvQk9VMUQ4UE95eFJXN3FoZURVWDAtRzdWaGVzVGxZMnJIbDhEUm1nUWQ1ZUd2c2R1d0lacktfblNnRlROaDRDSTMxQXllOXptY1NCV05lTVYtT0xOaGdMc0hWQ05mNXhaXzJEWExVTEcyX2p4S3BRZGdQTXVtSjNTMkR6b2lUNElRSmtJVE1tWjNn?oc=5,https://da.gd/9DIX58
