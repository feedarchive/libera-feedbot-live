feed,title,long_url,short_url
GN:T:AGI,AI Safety and Alignment: Could LLMs Be Penalized for Deepfakes and Misinformation? - hackernoon,https://news.google.com/rss/articles/CBMiZ2h0dHBzOi8vaGFja2Vybm9vbi5jb20vYWktc2FmZXR5LWFuZC1hbGlnbm1lbnQtY291bGQtbGxtcy1iZS1wZW5hbGl6ZWQtZm9yLWRlZXBmYWtlcy1hbmQtbWlzaW5mb3JtYXRpb27SAQA?oc=5,https://da.gd/kdna
