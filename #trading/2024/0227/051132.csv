feed,title,long_url,short_url
ArXiv,LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting,https://arxiv.org/abs/2402.16132,
ArXiv,GARNN: An Interpretable Graph Attentive Recurrent Neural Network for Predicting Blood Glucose Levels via Multivariate Time Series,https://arxiv.org/abs/2402.16230,
ArXiv,TOTEM: TOkenized Time Series EMbeddings for General Time Series Analysis,https://arxiv.org/abs/2402.16412,
ArXiv,Generative Pretrained Hierarchical Transformer for Time Series Forecasting,https://arxiv.org/abs/2402.16516,
ArXiv,DynaConF: Dynamic Forecasting of Non-Stationary Time Series,https://arxiv.org/abs/2209.08411,
ArXiv,Label-efficient Time Series Representation Learning: A Review,https://arxiv.org/abs/2302.06433,
ArXiv,Hierarchical Forecasting at Scale,https://arxiv.org/abs/2310.12809,
ArXiv,Explainable Modeling for Wind Power Forecasting: A Glass-Box Approach with High Accuracy,https://arxiv.org/abs/2310.18629,
ArXiv,Soft Contrastive Learning for Time Series,https://arxiv.org/abs/2312.16424,
ArXiv,Learning to Embed Time Series Patches Independently,https://arxiv.org/abs/2312.16427,
ArXiv,An Interpretable and Efficient Infinite-Order Vector Autoregressive Model for High-Dimensional Time Series,https://arxiv.org/abs/2209.01172,
ArXiv,The Effects of High-frequency Anticipatory Trading: Small Informed Trader vs. Round-Tripper,https://arxiv.org/abs/2304.13985,
