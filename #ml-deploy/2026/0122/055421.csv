feed,title,long_url,short_url
ArXiv,How to Build AI Agents by Augmenting LLMs with Codified Human Expert Domain Knowledge? A Software Engineering Framework,https://arxiv.org/abs/2601.15153,
ArXiv,Call2Instruct: Automated Pipeline for Generating Q&A Datasets from Call Center Recordings for LLM Fine-Tuning,https://arxiv.org/abs/2601.14263,
ArXiv,"Guardrails for trust, safety, and ethical development and deployment of Large Language Models (LLM)",https://arxiv.org/abs/2601.14298,
ArXiv,An Optimized Decision Tree-Based Framework for Explainable IoT Anomaly Detection,https://arxiv.org/abs/2601.14305,
ArXiv,FunCineForge: A Unified Dataset Toolkit and Model for Zero-Shot Movie Dubbing in Diverse Cinematic Scenes,https://arxiv.org/abs/2601.14777,
ArXiv,A Curriculum-Based Deep Reinforcement Learning Framework for the Electric Vehicle Routing Problem,https://arxiv.org/abs/2601.15038,
ArXiv,LLM Powered Social Digital Twins: A Framework for Simulating Population Behavioral Response to Policy Interventions,https://arxiv.org/abs/2601.06111,
ArXiv,Towards AI Transparency and Accountability: A Global Framework for Exchanging Information on AI Systems,https://arxiv.org/abs/2307.13658,
ArXiv,Reflecting in the Reflection: Integrating a Socratic Questioning Framework into Automated AI-Based Question Generation,https://arxiv.org/abs/2601.14798,
ArXiv,Strategic Doctrine Language Models (sdLM): A Learning-System Framework for Doctrinal Consistency and Geopolitical Forecasting,https://arxiv.org/abs/2601.14862,
ArXiv,Fine-Grained Traceability for Transparent ML Pipelines,https://arxiv.org/abs/2601.14971,
ArXiv,"DeepFedNAS: A Unified Framework for Principled, Hardware-Aware, and Predictor-Free Federated Neural Architecture Search",https://arxiv.org/abs/2601.15127,
ArXiv,MTFlow: Time-Conditioned Flow Matching for Microtubule Segmentation in Noisy Microscopy Images,https://arxiv.org/abs/2601.14841,
