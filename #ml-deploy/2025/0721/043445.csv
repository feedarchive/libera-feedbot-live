feed,title,long_url,short_url
ArXiv,Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery,https://arxiv.org/abs/2507.13874,
ArXiv,"VerilogDB: The Largest, Highest-Quality Dataset with a Preprocessing Framework for LLM-based RTL Generation",https://arxiv.org/abs/2507.13369,
ArXiv,Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation,https://arxiv.org/abs/2507.13371,
ArXiv,When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework,https://arxiv.org/abs/2507.13659,
ArXiv,AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework,https://arxiv.org/abs/2507.13729,
ArXiv,SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification,https://arxiv.org/abs/2507.13741,
ArXiv,DUALRec: A Hybrid Sequential and Language Model Framework for Context-Aware Movie Recommendation,https://arxiv.org/abs/2507.13957,
ArXiv,Photonic Fabric Platform for AI Accelerators,https://arxiv.org/abs/2507.14000,
ArXiv,AIvaluateXR: An Evaluation Framework for on-Device AI in XR with Benchmarking Results,https://arxiv.org/abs/2502.15761,
ArXiv,An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC,https://arxiv.org/abs/2507.13736,
ArXiv,DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration,https://arxiv.org/abs/2507.14088,
ArXiv,A Collaborative Framework Integrating Large Language Model and Chemical Fragment Space: Mutual Inspiration for Lead Design,https://arxiv.org/abs/2507.13580,
ArXiv,LLaPipe: LLM-Guided Reinforcement Learning for Automated Data Preparation Pipeline Construction,https://arxiv.org/abs/2507.13712,
ArXiv,CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis,https://arxiv.org/abs/2507.14022,
ArXiv,AI-Accelerated Flow Simulation: A Robust Auto-Regressive Framework for Long-Term CFD Forecasting,https://arxiv.org/abs/2412.05657,
