feed,title,long_url,short_url
ArXiv,An Artificial Intelligence Driven Semantic Similarity-Based Pipeline for Rapid Literature,https://arxiv.org/abs/2509.15292,
ArXiv,CCrepairBench: A High-Fidelity Benchmark and Reinforcement Learning Framework for C++ Compilation Repair,https://arxiv.org/abs/2509.15690,
ArXiv,ChannelFlow-Tools: A Standardized Dataset Creation Pipeline for 3D Obstructed Channel Flows,https://arxiv.org/abs/2509.15236,
ArXiv,PRISM: Phase-enhanced Radial-based Image Signature Mapping framework for fingerprinting AI-generated images,https://arxiv.org/abs/2509.15270,
ArXiv,Efficient and Versatile Model for Multilingual Information Retrieval of Islamic Text: Development and Deployment in Real-World Scenarios,https://arxiv.org/abs/2509.15380,
ArXiv,Momentum-constrained Hybrid Heuristic Trajectory Optimization Framework with Residual-enhanced DRL for Visually Impaired Scenarios,https://arxiv.org/abs/2509.15582,
ArXiv,DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models,https://arxiv.org/abs/2509.15587,
ArXiv,TISDiSS: A Training-Time and Inference-Time Scalable Framework for Discriminative Source Separation,https://arxiv.org/abs/2509.15666,
ArXiv,DeepMech: A Machine Learning Framework for Chemical Reaction Mechanism Prediction,https://arxiv.org/abs/2509.15872,
ArXiv,MoE-CE: Enhancing Generalization for Deep Learning based Channel Estimation via a Mixture-of-Experts Framework,https://arxiv.org/abs/2509.15964,
ArXiv,Fairness-in-the-Workflow: How Machine Learning Practitioners at Big Tech Companies Approach Fairness in Recommender Systems,https://arxiv.org/abs/2505.19441,
ArXiv,ThermalGuardian: Temperature-Aware Testing of Automotive Deep Learning Frameworks,https://arxiv.org/abs/2509.15815,
ArXiv,HyP-ASO: A Hybrid Policy-based Adaptive Search Optimization Framework for Large-Scale Integer Linear Programs,https://arxiv.org/abs/2509.15828,
ArXiv,UPRPRC: Unified Pipeline for Reproducing Parallel Resources -- Corpus from the United Nations,https://arxiv.org/abs/2509.15789,
ArXiv,CARD: A Cache-Assisted Parallel Speculative Decoding Framework via Query-and-Correct Paradigm for Accelerating LLM Inference,https://arxiv.org/abs/2508.04462,
