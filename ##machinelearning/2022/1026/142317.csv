feed,title,long_url,short_url
r/ML:100+,"[P] Up to 12X faster GPU inference on Bert, T5 and other transformers with OpenAI Triton kernels",https://redd.it/ydqmjp,
