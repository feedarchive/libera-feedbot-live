feed,title,long_url,short_url
r/ML:200+,"[P] Up to 12X faster GPU inference on Bert, T5 and other transformers with OpenAI Triton kernels",https://redd.it/ydqmjp,
