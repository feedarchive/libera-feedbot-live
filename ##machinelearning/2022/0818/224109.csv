feed,title,long_url,short_url
r/ML:50+,[R] LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale - Facebook AI 2022 - Inference in LLMs with up to 175B parameters without performance degradation and making it possible to use these models on a single server with consumer GPUs!,https://redd.it/wrpg59,
