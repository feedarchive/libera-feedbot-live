feed,title,long_url,short_url
r/ML:200+,"[R] RWKV-v2-RNN : A parallelizable RNN with transformer-level LM performance, and without using attention",https://redd.it/umq908,
