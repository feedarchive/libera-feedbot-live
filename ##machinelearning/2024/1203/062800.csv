feed,title,long_url,short_url
Nvidia,TensorRT-LLM Speculative Decoding Boosts Inference Throughput by up to 3.6x,https://developer.nvidia.com/blog/tensorrt-llm-speculative-decoding-boosts-inference-throughput-by-up-to-3-6x/,https://da.gd/9NW8Q
