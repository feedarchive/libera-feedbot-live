feed,title,long_url,short_url
PwC:Trending,/microsoft/ LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression: https://github.com/microsoft/LLMLingua,https://paperswithcode.com/paper/llmlingua-2-data-distillation-for-efficient,https://da.gd/05hQs
PwC:Trending,/h-zhao1997/ Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference: https://github.com/h-zhao1997/cobra,https://paperswithcode.com/paper/cobra-extending-mamba-to-multi-modal-large,https://da.gd/gIZGXV
PwC:Trending,/hxmap/ Leveraging Enhanced Queries of Point Sets for Vectorized Map Construction: https://github.com/hxmap/mapqr,https://paperswithcode.com/paper/leveraging-enhanced-queries-of-point-sets-for,https://da.gd/83YVY
PwC:Trending,/hiyouga/ LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models: https://github.com/hiyouga/llama-efficient-tuning,https://paperswithcode.com/paper/llamafactory-unified-efficient-fine-tuning-of,https://da.gd/jU38EG
