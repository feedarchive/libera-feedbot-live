feed,title,long_url,short_url
PwC:Trending,/apple/ CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster Pre-training on Web-scale Image-Text Data: https://github.com/apple/corenet,https://paperswithcode.com/paper/catlip-clip-level-visual-recognition-accuracy,https://da.gd/dAsyx
PwC:Trending,"/ericlbuehler/ X-LoRA: Mixture of Low-Rank Adapter Experts, a Flexible Framework for Large Language Models with Applications in Protein Mechanics and Molecular Design: https://github.com/ericlbuehler/mistral.rs",https://paperswithcode.com/paper/x-lora-mixture-of-low-rank-adapter-experts-a,https://da.gd/YJ5u
PwC:Trending,"/dcharatan/ FlowMap: High-Quality Camera Poses, Intrinsics, and Depth via Gradient Descent: https://github.com/dcharatan/flowmap",https://paperswithcode.com/paper/flowmap-high-quality-camera-poses-intrinsics,https://da.gd/vVNhA
PwC:Trending,/microsoft/ Make Your LLM Fully Utilize the Context: https://github.com/microsoft/FILM,https://paperswithcode.com/paper/make-your-llm-fully-utilize-the-context,https://da.gd/dG2K
PwC:Trending,/JackAILab/ ConsistentID: Portrait Generation with Multimodal Fine-Grained Identity Preserving: https://github.com/JackAILab/ConsistentID,https://paperswithcode.com/paper/consistentid-portrait-generation-with,https://da.gd/qLrf42
PwC:Trending,/ToruOwO/ Learning Visuotactile Skills with Two Multifingered Hands: https://github.com/ToruOwO/hato,https://paperswithcode.com/paper/learning-visuotactile-skills-with-two,https://da.gd/TVN5v5
PwC:Trending,/opengvlab/ How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites: https://github.com/opengvlab/internvl,https://paperswithcode.com/paper/how-far-are-we-to-gpt-4v-closing-the-gap-to,https://da.gd/mXqgzL
PwC:Trending,/zzxslp/ List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs: https://github.com/zzxslp/som-llava,https://paperswithcode.com/paper/list-items-one-by-one-a-new-data-source-and,https://da.gd/uEr3n
