feed,title,long_url,short_url
PwC:Trending,/DepthAnything/ Depth Anything V2: https://github.com/DepthAnything/Depth-Anything-V2,https://paperswithcode.com/paper/depth-anything-v2,https://da.gd/983Ze
PwC:Trending,/deepseek-ai/ DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence: https://github.com/deepseek-ai/deepseek-coder-v2,https://paperswithcode.com/paper/deepseek-coder-v2-breaking-the-barrier-of,https://da.gd/qvCyoP
PwC:Trending,/digitalphonetics/ Meta Learning Text-to-Speech Synthesis in over 7000 Languages: https://github.com/digitalphonetics/ims-toucan,https://paperswithcode.com/paper/meta-learning-text-to-speech-synthesis-in,https://da.gd/z9KIR
PwC:Trending,"/google-deepmind/ Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?: https://github.com/google-deepmind/loft",https://paperswithcode.com/paper/can-long-context-language-models-subsume,https://da.gd/yMlNt
PwC:Trending,/caiyuanhao1998/ Structure-Aware Sparse-View X-ray 3D Reconstruction: https://github.com/caiyuanhao1998/sax-nerf,https://paperswithcode.com/paper/structure-aware-sparse-view-x-ray-3d,https://da.gd/YEu7Ee
PwC:Trending,/xinchengshuai/ A Survey of Multimodal-Guided Image Editing with Text-to-Image Diffusion Models: https://github.com/xinchengshuai/awesome-image-editing,https://paperswithcode.com/paper/a-survey-of-multimodal-guided-image-editing,https://da.gd/MaSIc
PwC:Trending,/mlfoundations/ MINT-1T: Scaling Open-Source Multimodal Data by 10x: A Multimodal Dataset with One Trillion Tokens: https://github.com/mlfoundations/mint-1t,https://paperswithcode.com/paper/mint-1t-scaling-open-source-multimodal-data,https://da.gd/oh9R7
PwC:Trending,/byungkwanlee/ TroL: Traversal of Layers for Large Language and Vision Models: https://github.com/byungkwanlee/trol,https://paperswithcode.com/paper/trol-traversal-of-layers-for-large-language,https://da.gd/8nnH
PwC:Trending,/Thinklab-SJTU/ Bench2Drive: Towards Multi-Ability Benchmarking of Closed-Loop End-To-End Autonomous Driving: https://github.com/Thinklab-SJTU/Bench2Drive,https://paperswithcode.com/paper/bench2drive-towards-multi-ability,https://da.gd/xk5zs0
