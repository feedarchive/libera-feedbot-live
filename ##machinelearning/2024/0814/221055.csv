feed,title,long_url,short_url
Nvidia,Optimizing Inference Efficiency for LLMs at Scale with NVIDIA NIM Microservices,https://developer.nvidia.com/blog/optimizing-inference-efficiency-for-llms-at-scale-with-nvidia-nim-microservices/,https://da.gd/9swFsl
Nvidia,Video: Build Live Media Applications for AI-Enabled Infrastructure with NVIDIA Holoscan for Media,https://developer.nvidia.com/blog/video-build-live-media-applications-for-ai-enabled-infrastructure-with-nvidia-holoscan-for-media/,https://da.gd/pCLwH
Nvidia,Just Released: DOCA 2.8 Software Framework,https://nvda.ws/4crxaRs#new_tab,https://da.gd/rYBWXo
Nvidia,How to Prune and Distill Llama-3.1 8B to an NVIDIA Llama-3.1-Minitron 4B Model,https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model/,https://da.gd/u6Jk4f
