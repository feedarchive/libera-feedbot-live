feed,title,long_url,short_url
PwC:Trending,/microsoft/ SliceGPT: Compress Large Language Models by Deleting Rows and Columns: https://github.com/microsoft/transformercompression,https://paperswithcode.com/paper/slicegpt-compress-large-language-models-by,https://da.gd/vamyOc
PwC:Trending,/PKU-YuanGroup/ MoE-LLaVA: Mixture of Experts for Large Vision-Language Models: https://github.com/PKU-YuanGroup/MoE-LLaVA,https://paperswithcode.com/paper/moe-llava-mixture-of-experts-for-large-vision,https://da.gd/nHdnBZ
PwC:Trending,/kareldo/ In-Context Learning for Extreme Multi-Label Classification: https://github.com/kareldo/xmc.dspy,https://paperswithcode.com/paper/in-context-learning-for-extreme-multi-label,https://da.gd/FvlY0
PwC:Trending,/flagopen/ Flexibly Scaling Large Language Models Contexts Through Extensible Tokenization: https://github.com/flagopen/flagembedding,https://paperswithcode.com/paper/flexibly-scaling-large-language-models,https://da.gd/7YVV
PwC:Trending,/zhuyiche/ LLaVA-Phi: Efficient Multi-Modal Assistant with Small Language Model: https://github.com/zhuyiche/llava-phi,https://paperswithcode.com/paper/llava-ph-efficient-multi-modal-assistant-with,https://da.gd/PfFt5
