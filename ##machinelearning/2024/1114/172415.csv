feed,title,long_url,short_url
PwC:Trending,/whaohan/ Scaling Mesh Generation via Compressive Tokenization: https://github.com/whaohan/bpt,https://paperswithcode.com/paper/scaling-mesh-generation-via-compressive,https://da.gd/n2eS
PwC:Trending,/chaofantao/ Autoregressive Models in Vision: A Survey: https://github.com/chaofantao/autoregressive-models-in-vision-survey,https://paperswithcode.com/paper/autoregressive-models-in-vision-a-survey,https://da.gd/jge9i
PwC:Trending,/ChenYutongTHU/ SplatFormer: Point Transformer for Robust 3D Gaussian Splatting: https://github.com/ChenYutongTHU/SplatFormer,https://paperswithcode.com/paper/splatformer-point-transformer-for-robust-3d,https://da.gd/BSQU2
PwC:Trending,/ekinakyurek/ The Surprising Effectiveness of Test-Time Training for Abstract Reasoning: https://github.com/ekinakyurek/marc,https://paperswithcode.com/paper/the-surprising-effectiveness-of-test-time,https://da.gd/Tt9zd
PwC:Trending,/LingmaTongyi/ Lingma SWE-GPT: An Open Development-Process-Centric Language Model for Automated Software Improvement: https://github.com/LingmaTongyi/Lingma-SWE-GPT,https://paperswithcode.com/paper/lingma-swe-gpt-an-open-development-process,https://da.gd/CqpZXM
PwC:Trending,/autodeskailab/ Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model with Compact Wavelet Encodings: https://github.com/autodeskailab/wala,https://paperswithcode.com/paper/wavelet-latent-diffusion-wala-billion,https://da.gd/mHxOfa
PwC:Trending,/microsoft/ LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation: https://github.com/microsoft/LLM2CLIP,https://paperswithcode.com/paper/llm2clip-powerful-language-model-unlock,https://da.gd/y2fldU
PwC:Trending,/AaronZ345/ TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control: https://github.com/AaronZ345/TCSinger,https://paperswithcode.com/paper/stylesinger-2-zero-shot-singing-voice,https://da.gd/VV6s
PwC:Trending,/flairnlp/ TransformerRanker: A Tool for Efficiently Finding the Best-Suited Language Models for Downstream Classification Tasks: https://github.com/flairnlp/transformer-ranker,https://paperswithcode.com/paper/transformerranker-a-tool-for-efficiently,https://da.gd/p4fhv
