feed,title,long_url,short_url
PwC:Trending,/catid/ DoRA: Weight-Decomposed Low-Rank Adaptation: https://github.com/catid/dora,https://paperswithcode.com/paper/dora-weight-decomposed-low-rank-adaptation,https://da.gd/XVQ4k
PwC:Trending,/contextualai/ Generative Representational Instruction Tuning: https://github.com/contextualai/gritlm,https://paperswithcode.com/paper/generative-representational-instruction,https://da.gd/Z7lWd
PwC:Trending,/FasterDecoding/ BitDelta: Your Fine-Tune May Only Be Worth One Bit: https://github.com/FasterDecoding/BitDelta,https://paperswithcode.com/paper/bitdelta-your-fine-tune-may-only-be-worth-one,https://da.gd/uv5RhK
PwC:Trending,/UlionTse/ MaskNet: Introducing Feature-Wise Multiplication to CTR Ranking Models by Instance-Guided Mask: https://github.com/UlionTse/mlgb/blob/main/mlgb/torch/models/ranking.py,https://paperswithcode.com/paper/masknet-introducing-feature-wise,https://da.gd/Mz0S30
PwC:Trending,/franxyao/ Data Engineering for Scaling Language Models to 128K Context: https://github.com/franxyao/long-context-data-engineering,https://paperswithcode.com/paper/data-engineering-for-scaling-language-models,https://da.gd/5ei1B
