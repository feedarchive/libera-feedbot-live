feed,title,long_url,short_url
j:MAKE,Diversifying Multi-Head Attention in the Transformer Model,https://www.mdpi.com/2504-4990/6/4/126,https://da.gd/jBZ6
