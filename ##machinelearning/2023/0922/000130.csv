feed,title,long_url,short_url
Google:Blog,Distilling step-by-step: Outperforming larger language models with less training data and smaller model sizes,http://blog.research.google/2023/09/distilling-step-by-step-outperforming.html,https://da.gd/Jn0o7D
