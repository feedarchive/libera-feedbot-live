feed,title,long_url,short_url
r/ML:50+,[D] Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU,https://redd.it/11p3a0j,
