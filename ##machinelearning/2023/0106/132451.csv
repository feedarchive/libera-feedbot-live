feed,title,long_url,short_url
PwC:Trending,/lucidrains/ Muse: Text-To-Image Generation via Masked Generative Transformers: https://github.com/lucidrains/muse-pytorch,https://paperswithcode.com/paper/muse-text-to-image-generation-via-masked,https://da.gd/S7uoV7
PwC:Trending,/TheAtticusProject/ MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement Understanding: https://github.com/TheAtticusProject/maud,https://paperswithcode.com/paper/maud-an-expert-annotated-legal-nlp-dataset,https://da.gd/ZWGdXy
PwC:Trending,/junjie18/ Cross Modal Transformer via Coordinates Encoding for 3D Object Dectection: https://github.com/junjie18/cmt,https://paperswithcode.com/paper/cross-modal-transformer-via-coordinates,https://da.gd/EGMl1S
PwC:Trending,/johnnay/ Large Language Models as Corporate Lobbyists: https://github.com/johnnay/llm-lobbyist,https://paperswithcode.com/paper/large-language-models-as-corporate-lobbyists,https://da.gd/Dw0ij
PwC:Trending,/zhangzjn/ Rethinking Mobile Block for Efficient Neural Models: https://github.com/zhangzjn/emo,https://paperswithcode.com/paper/rethinking-mobile-block-for-efficient-neural,https://da.gd/Y8KZ
PwC:Trending,/oliverrensu/ TinyMIM: An Empirical Study of Distilling MIM Pre-trained Models: https://github.com/oliverrensu/tinymim,https://paperswithcode.com/paper/tinymim-an-empirical-study-of-distilling-mim,https://da.gd/0joYE
PwC:Trending,/ToniRV/ NeRF-SLAM: Real-Time Dense Monocular SLAM with Neural Radiance Fields: https://github.com/ToniRV/NeRF-SLAM,https://paperswithcode.com/paper/nerf-slam-real-time-dense-monocular-slam-with,https://da.gd/8Mugu
PwC:Trending,/ofa-sys/ Scaling Language-Image Pre-training via Masking: https://github.com/ofa-sys/chinese-clip,https://paperswithcode.com/paper/scaling-language-image-pre-training-via,https://da.gd/MZu9X
